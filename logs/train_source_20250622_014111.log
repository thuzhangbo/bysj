2025-06-22 01:41:11,229 [INFO] Using device: cpu
2025-06-22 01:41:11,229 [INFO] 开始创建数据加载器...
2025-06-22 01:41:11,233 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 01:41:11,233 [INFO] Class allocation analysis:
2025-06-22 01:41:11,233 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 01:41:11,233 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 01:41:11,233 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 01:41:11,233 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 01:41:11,246 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 01:41:11,246 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 01:41:11,246 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 01:41:11,247 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 01:41:11,247 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 01:41:11,247 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 01:41:11,247 [INFO] Final allocation:
2025-06-22 01:41:11,247 [INFO]   Source domain: 280 samples
2025-06-22 01:41:11,247 [INFO]   Target domain: 320 samples
2025-06-22 01:41:11,248 [INFO] Source domain setup:
2025-06-22 01:41:11,248 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-22 01:41:11,248 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-22 01:41:11,248 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-22 01:41:11,248 [INFO]   Total data after allocation: 280
2025-06-22 01:41:11,248 [INFO]   Data split - Train: 224, Val: 56
2025-06-22 01:41:11,248 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-22 01:41:11,248 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-22 01:41:11,249 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 01:41:11,249 [INFO] Class allocation analysis:
2025-06-22 01:41:11,249 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 01:41:11,249 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 01:41:11,249 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 01:41:11,249 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 01:41:11,263 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 01:41:11,263 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 01:41:11,263 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 01:41:11,263 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 01:41:11,263 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 01:41:11,263 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 01:41:11,263 [INFO] Final allocation:
2025-06-22 01:41:11,263 [INFO]   Source domain: 280 samples
2025-06-22 01:41:11,263 [INFO]   Target domain: 320 samples
2025-06-22 01:41:11,265 [INFO] Target domain setup:
2025-06-22 01:41:11,265 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-22 01:41:11,265 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-22 01:41:11,265 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-22 01:41:11,265 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-22 01:41:11,265 [INFO]   Total data after allocation: 320
2025-06-22 01:41:11,265 [INFO]   Data split - Train: 256, Val: 64
2025-06-22 01:41:11,265 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-22 01:41:11,265 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-22 01:41:11,265 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-22 01:41:11,265 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-22 01:41:11,265 [INFO] 数据加载器创建完成!
2025-06-22 01:41:11,265 [INFO] 源域类别数: 4 (重叠类别)
2025-06-22 01:41:11,265 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-22 01:41:11,265 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-22 01:41:11,265 [INFO] 目标域新类别: [4, 5]
2025-06-22 01:41:11,265 [INFO] Data allocation verification:
2025-06-22 01:41:11,265 [INFO]   Source data samples: 280
2025-06-22 01:41:11,265 [INFO]   Target data samples: 320
2025-06-22 01:41:11,265 [INFO]   Overlapping samples: 0
2025-06-22 01:41:11,265 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-22 01:41:11,273 [INFO] Model initialized with 2378244 parameters
2025-06-22 01:41:11,273 [INFO] Previous best validation accuracy read from record.txt: 0.6250
2025-06-22 01:41:11,273 [INFO] Starting training...
2025-06-22 01:41:11,426 [INFO] Epoch 001 | Train Loss: 11.7323 | Val Loss: 5.0915 | Val Acc: 0.3214
2025-06-22 01:41:11,929 [INFO] New best model at epoch 1 (Val Acc: 0.3214)
2025-06-22 01:41:12,079 [INFO] Epoch 002 | Train Loss: 11.0229 | Val Loss: 16.9529 | Val Acc: 0.2679
2025-06-22 01:41:12,270 [INFO] Epoch 003 | Train Loss: 6.2259 | Val Loss: 11.5980 | Val Acc: 0.3214
2025-06-22 01:41:12,476 [INFO] Epoch 004 | Train Loss: 5.6645 | Val Loss: 7.5973 | Val Acc: 0.2500
2025-06-22 01:41:12,729 [INFO] Epoch 005 | Train Loss: 5.6061 | Val Loss: 3.7801 | Val Acc: 0.3393
2025-06-22 01:41:12,792 [INFO] New best model at epoch 5 (Val Acc: 0.3393)
2025-06-22 01:41:13,034 [INFO] Epoch 006 | Train Loss: 4.2551 | Val Loss: 3.5665 | Val Acc: 0.2679
2025-06-22 01:41:13,377 [INFO] Epoch 007 | Train Loss: 2.9374 | Val Loss: 4.4900 | Val Acc: 0.2857
2025-06-22 01:41:13,758 [INFO] Epoch 008 | Train Loss: 4.1202 | Val Loss: 3.5541 | Val Acc: 0.3214
2025-06-22 01:41:14,099 [INFO] Epoch 009 | Train Loss: 3.0615 | Val Loss: 3.9503 | Val Acc: 0.3036
2025-06-22 01:41:14,439 [INFO] Epoch 010 | Train Loss: 2.4683 | Val Loss: 1.7955 | Val Acc: 0.5179
2025-06-22 01:41:15,984 [INFO] New best model at epoch 10 (Val Acc: 0.5179)
2025-06-22 01:41:16,149 [INFO] Epoch 011 | Train Loss: 2.6728 | Val Loss: 1.7983 | Val Acc: 0.4643
2025-06-22 01:41:16,321 [INFO] Epoch 012 | Train Loss: 2.0443 | Val Loss: 4.6217 | Val Acc: 0.4107
2025-06-22 01:41:16,516 [INFO] Epoch 013 | Train Loss: 3.1435 | Val Loss: 6.0840 | Val Acc: 0.3214
2025-06-22 01:41:16,723 [INFO] Epoch 014 | Train Loss: 2.2873 | Val Loss: 3.9937 | Val Acc: 0.3750
2025-06-22 01:41:16,965 [INFO] Epoch 015 | Train Loss: 2.3453 | Val Loss: 2.7113 | Val Acc: 0.3750
2025-06-22 01:41:17,249 [INFO] Epoch 016 | Train Loss: 2.0323 | Val Loss: 2.0479 | Val Acc: 0.4107
2025-06-22 01:41:17,581 [INFO] Epoch 017 | Train Loss: 1.8709 | Val Loss: 2.6465 | Val Acc: 0.4464
2025-06-22 01:41:17,921 [INFO] Epoch 018 | Train Loss: 2.0275 | Val Loss: 2.2841 | Val Acc: 0.4107
2025-06-22 01:41:18,264 [INFO] Epoch 019 | Train Loss: 2.5934 | Val Loss: 4.5713 | Val Acc: 0.2143
2025-06-22 01:41:18,600 [INFO] Epoch 020 | Train Loss: 2.1330 | Val Loss: 3.4717 | Val Acc: 0.3036
2025-06-22 01:41:19,606 [INFO] Epoch 021 | Train Loss: 2.2455 | Val Loss: 2.7509 | Val Acc: 0.2679
2025-06-22 01:41:19,824 [INFO] Epoch 022 | Train Loss: 2.2476 | Val Loss: 2.6860 | Val Acc: 0.3214
2025-06-22 01:41:20,088 [INFO] Epoch 023 | Train Loss: 1.5211 | Val Loss: 2.8383 | Val Acc: 0.4821
2025-06-22 01:41:20,362 [INFO] Epoch 024 | Train Loss: 1.3327 | Val Loss: 3.9923 | Val Acc: 0.3750
2025-06-22 01:41:20,665 [INFO] Epoch 025 | Train Loss: 1.6232 | Val Loss: 2.5964 | Val Acc: 0.4107
2025-06-22 01:41:20,972 [INFO] Epoch 026 | Train Loss: 1.9161 | Val Loss: 4.6784 | Val Acc: 0.4464
2025-06-22 01:41:21,320 [INFO] Epoch 027 | Train Loss: 1.4283 | Val Loss: 3.3263 | Val Acc: 0.3929
2025-06-22 01:41:21,648 [INFO] Epoch 028 | Train Loss: 1.2194 | Val Loss: 3.0616 | Val Acc: 0.4286
2025-06-22 01:41:21,978 [INFO] Epoch 029 | Train Loss: 1.3521 | Val Loss: 2.6958 | Val Acc: 0.4107
2025-06-22 01:41:22,301 [INFO] Epoch 030 | Train Loss: 1.5465 | Val Loss: 2.0663 | Val Acc: 0.4107
2025-06-22 01:41:23,270 [INFO] Epoch 031 | Train Loss: 1.6224 | Val Loss: 3.2028 | Val Acc: 0.3750
2025-06-22 01:41:23,505 [INFO] Epoch 032 | Train Loss: 1.3811 | Val Loss: 3.4288 | Val Acc: 0.3571
2025-06-22 01:41:23,766 [INFO] Epoch 033 | Train Loss: 1.0734 | Val Loss: 3.0641 | Val Acc: 0.3036
2025-06-22 01:41:24,031 [INFO] Epoch 034 | Train Loss: 2.2123 | Val Loss: 3.0290 | Val Acc: 0.3036
2025-06-22 01:41:24,338 [INFO] Epoch 035 | Train Loss: 1.4996 | Val Loss: 4.1289 | Val Acc: 0.3750
2025-06-22 01:41:24,642 [INFO] Epoch 036 | Train Loss: 1.7745 | Val Loss: 3.5149 | Val Acc: 0.4643
2025-06-22 01:41:24,978 [INFO] Epoch 037 | Train Loss: 1.2992 | Val Loss: 2.5458 | Val Acc: 0.4286
2025-06-22 01:41:25,313 [INFO] Epoch 038 | Train Loss: 1.1862 | Val Loss: 2.1332 | Val Acc: 0.4464
2025-06-22 01:41:25,643 [INFO] Epoch 039 | Train Loss: 0.9075 | Val Loss: 4.7065 | Val Acc: 0.3393
2025-06-22 01:41:25,975 [INFO] Epoch 040 | Train Loss: 1.2041 | Val Loss: 4.5792 | Val Acc: 0.3571
2025-06-22 01:41:26,970 [INFO] Epoch 041 | Train Loss: 1.2075 | Val Loss: 3.3410 | Val Acc: 0.3750
2025-06-22 01:41:27,198 [INFO] Epoch 042 | Train Loss: 0.9912 | Val Loss: 3.4333 | Val Acc: 0.3750
2025-06-22 01:41:27,461 [INFO] Epoch 043 | Train Loss: 1.3972 | Val Loss: 3.2923 | Val Acc: 0.3929
2025-06-22 01:41:27,726 [INFO] Epoch 044 | Train Loss: 1.2888 | Val Loss: 3.5423 | Val Acc: 0.3929
2025-06-22 01:41:28,032 [INFO] Epoch 045 | Train Loss: 1.2675 | Val Loss: 3.1147 | Val Acc: 0.4286
2025-06-22 01:41:28,363 [INFO] Epoch 046 | Train Loss: 1.0862 | Val Loss: 4.8093 | Val Acc: 0.4286
2025-06-22 01:41:28,705 [INFO] Epoch 047 | Train Loss: 1.4856 | Val Loss: 2.7431 | Val Acc: 0.5000
2025-06-22 01:41:29,056 [INFO] Epoch 048 | Train Loss: 1.1718 | Val Loss: 2.4369 | Val Acc: 0.3750
2025-06-22 01:41:29,391 [INFO] Epoch 049 | Train Loss: 1.3453 | Val Loss: 2.7076 | Val Acc: 0.4643
2025-06-22 01:41:29,733 [INFO] Epoch 050 | Train Loss: 0.8261 | Val Loss: 4.8928 | Val Acc: 0.3571
2025-06-22 01:41:31,113 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.5179 at epoch 10)
2025-06-22 01:41:31,113 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.001/train_metrics.csv
2025-06-22 01:41:31,579 [INFO] Final training curves saved
2025-06-22 01:41:31,579 [INFO] Training completed!
2025-06-22 01:41:31,579 [INFO] Best validation accuracy: 0.5179
2025-06-22 01:41:31,579 [INFO] Best epoch: 10
2025-06-22 01:41:31,579 [INFO] Total epochs trained: 50
2025-06-22 01:41:31,580 [INFO] Starting training with parameters: (0.001, 0.1, 512, 5, 50, 0.001)
