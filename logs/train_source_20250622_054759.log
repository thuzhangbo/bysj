2025-06-22 05:47:59,881 [INFO] Using device: cpu
2025-06-22 05:47:59,881 [INFO] 开始创建数据加载器...
2025-06-22 05:47:59,884 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 05:47:59,884 [INFO] Class allocation analysis:
2025-06-22 05:47:59,884 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 05:47:59,884 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 05:47:59,884 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 05:47:59,884 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 05:47:59,898 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 05:47:59,898 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 05:47:59,898 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 05:47:59,898 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 05:47:59,898 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 05:47:59,898 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 05:47:59,898 [INFO] Final allocation:
2025-06-22 05:47:59,898 [INFO]   Source domain: 280 samples
2025-06-22 05:47:59,898 [INFO]   Target domain: 320 samples
2025-06-22 05:47:59,900 [INFO] Source domain setup:
2025-06-22 05:47:59,900 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-22 05:47:59,900 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-22 05:47:59,900 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-22 05:47:59,900 [INFO]   Total data after allocation: 280
2025-06-22 05:47:59,900 [INFO]   Data split - Train: 224, Val: 56
2025-06-22 05:47:59,900 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-22 05:47:59,900 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-22 05:47:59,901 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 05:47:59,901 [INFO] Class allocation analysis:
2025-06-22 05:47:59,901 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 05:47:59,901 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 05:47:59,901 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 05:47:59,901 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 05:47:59,914 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 05:47:59,914 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 05:47:59,915 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 05:47:59,915 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 05:47:59,915 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 05:47:59,915 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 05:47:59,915 [INFO] Final allocation:
2025-06-22 05:47:59,915 [INFO]   Source domain: 280 samples
2025-06-22 05:47:59,915 [INFO]   Target domain: 320 samples
2025-06-22 05:47:59,916 [INFO] Target domain setup:
2025-06-22 05:47:59,916 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-22 05:47:59,916 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-22 05:47:59,916 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-22 05:47:59,916 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-22 05:47:59,916 [INFO]   Total data after allocation: 320
2025-06-22 05:47:59,916 [INFO]   Data split - Train: 256, Val: 64
2025-06-22 05:47:59,916 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-22 05:47:59,916 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-22 05:47:59,916 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-22 05:47:59,916 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-22 05:47:59,917 [INFO] 数据加载器创建完成!
2025-06-22 05:47:59,917 [INFO] 源域类别数: 4 (重叠类别)
2025-06-22 05:47:59,917 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-22 05:47:59,917 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-22 05:47:59,917 [INFO] 目标域新类别: [4, 5]
2025-06-22 05:47:59,917 [INFO] Data allocation verification:
2025-06-22 05:47:59,917 [INFO]   Source data samples: 280
2025-06-22 05:47:59,917 [INFO]   Target data samples: 320
2025-06-22 05:47:59,917 [INFO]   Overlapping samples: 0
2025-06-22 05:47:59,917 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-22 05:47:59,922 [INFO] Model initialized with 1323524 parameters
2025-06-22 05:47:59,922 [INFO] Previous best validation accuracy read from record.txt: 0.6250
2025-06-22 05:47:59,922 [INFO] Starting training...
2025-06-22 05:48:00,019 [INFO] Epoch 001 | Train Loss: 15.2868 | Val Loss: 7.2729 | Val Acc: 0.3036
2025-06-22 05:48:02,782 [INFO] New best model at epoch 1 (Val Acc: 0.3036)
2025-06-22 05:48:02,940 [INFO] Epoch 002 | Train Loss: 8.1647 | Val Loss: 11.4560 | Val Acc: 0.2679
2025-06-22 05:48:03,037 [INFO] Epoch 003 | Train Loss: 6.8579 | Val Loss: 6.2181 | Val Acc: 0.4107
2025-06-22 05:48:03,060 [INFO] New best model at epoch 3 (Val Acc: 0.4107)
2025-06-22 05:48:03,168 [INFO] Epoch 004 | Train Loss: 5.9553 | Val Loss: 8.3398 | Val Acc: 0.3393
2025-06-22 05:48:03,312 [INFO] Epoch 005 | Train Loss: 6.0213 | Val Loss: 5.7801 | Val Acc: 0.3750
2025-06-22 05:48:03,437 [INFO] Epoch 006 | Train Loss: 5.6670 | Val Loss: 4.8561 | Val Acc: 0.4821
2025-06-22 05:48:03,457 [INFO] New best model at epoch 6 (Val Acc: 0.4821)
2025-06-22 05:48:03,557 [INFO] Epoch 007 | Train Loss: 4.4205 | Val Loss: 3.6574 | Val Acc: 0.2857
2025-06-22 05:48:03,680 [INFO] Epoch 008 | Train Loss: 4.1230 | Val Loss: 3.5900 | Val Acc: 0.2857
2025-06-22 05:48:03,788 [INFO] Epoch 009 | Train Loss: 4.6854 | Val Loss: 5.8819 | Val Acc: 0.2321
2025-06-22 05:48:03,888 [INFO] Epoch 010 | Train Loss: 4.9765 | Val Loss: 3.4624 | Val Acc: 0.3214
2025-06-22 05:48:04,673 [INFO] Epoch 011 | Train Loss: 4.5146 | Val Loss: 3.4025 | Val Acc: 0.3571
2025-06-22 05:48:04,782 [INFO] Epoch 012 | Train Loss: 4.4261 | Val Loss: 4.2041 | Val Acc: 0.3571
2025-06-22 05:48:04,884 [INFO] Epoch 013 | Train Loss: 3.7739 | Val Loss: 3.2260 | Val Acc: 0.3214
2025-06-22 05:48:05,016 [INFO] Epoch 014 | Train Loss: 3.2802 | Val Loss: 3.6439 | Val Acc: 0.3571
2025-06-22 05:48:05,175 [INFO] Epoch 015 | Train Loss: 3.6029 | Val Loss: 4.3444 | Val Acc: 0.3214
2025-06-22 05:48:05,272 [INFO] Epoch 016 | Train Loss: 3.1200 | Val Loss: 4.4318 | Val Acc: 0.3750
2025-06-22 05:48:05,385 [INFO] Epoch 017 | Train Loss: 3.1732 | Val Loss: 4.3428 | Val Acc: 0.3929
2025-06-22 05:48:05,482 [INFO] Epoch 018 | Train Loss: 4.0681 | Val Loss: 3.5814 | Val Acc: 0.3929
2025-06-22 05:48:05,577 [INFO] Epoch 019 | Train Loss: 3.0617 | Val Loss: 3.6356 | Val Acc: 0.3214
2025-06-22 05:48:05,699 [INFO] Epoch 020 | Train Loss: 3.1764 | Val Loss: 4.7039 | Val Acc: 0.3750
2025-06-22 05:48:06,511 [INFO] Epoch 021 | Train Loss: 3.5614 | Val Loss: 3.5460 | Val Acc: 0.3393
2025-06-22 05:48:06,613 [INFO] Epoch 022 | Train Loss: 3.4637 | Val Loss: 2.5771 | Val Acc: 0.4107
2025-06-22 05:48:06,731 [INFO] Epoch 023 | Train Loss: 3.0071 | Val Loss: 2.9112 | Val Acc: 0.3929
2025-06-22 05:48:06,826 [INFO] Epoch 024 | Train Loss: 3.0618 | Val Loss: 3.1221 | Val Acc: 0.3393
2025-06-22 05:48:06,936 [INFO] Epoch 025 | Train Loss: 1.8901 | Val Loss: 2.6550 | Val Acc: 0.3929
2025-06-22 05:48:07,044 [INFO] Epoch 026 | Train Loss: 2.2300 | Val Loss: 3.2063 | Val Acc: 0.2679
2025-06-22 05:48:07,144 [INFO] Epoch 027 | Train Loss: 3.1758 | Val Loss: 2.3419 | Val Acc: 0.3750
2025-06-22 05:48:07,240 [INFO] Epoch 028 | Train Loss: 2.8296 | Val Loss: 2.9070 | Val Acc: 0.4464
2025-06-22 05:48:07,375 [INFO] Epoch 029 | Train Loss: 2.0965 | Val Loss: 2.6066 | Val Acc: 0.4464
2025-06-22 05:48:07,472 [INFO] Epoch 030 | Train Loss: 2.5299 | Val Loss: 3.0035 | Val Acc: 0.4107
2025-06-22 05:48:08,588 [INFO] Epoch 031 | Train Loss: 2.3452 | Val Loss: 2.6778 | Val Acc: 0.3750
2025-06-22 05:48:08,689 [INFO] Epoch 032 | Train Loss: 2.5148 | Val Loss: 3.1017 | Val Acc: 0.3571
2025-06-22 05:48:08,794 [INFO] Epoch 033 | Train Loss: 2.7375 | Val Loss: 2.9476 | Val Acc: 0.4107
2025-06-22 05:48:08,890 [INFO] Epoch 034 | Train Loss: 1.8711 | Val Loss: 3.3290 | Val Acc: 0.4107
2025-06-22 05:48:08,988 [INFO] Epoch 035 | Train Loss: 1.7422 | Val Loss: 4.0804 | Val Acc: 0.3571
2025-06-22 05:48:09,111 [INFO] Epoch 036 | Train Loss: 2.3396 | Val Loss: 2.9348 | Val Acc: 0.4107
2025-06-22 05:48:09,215 [INFO] Epoch 037 | Train Loss: 1.9445 | Val Loss: 2.5891 | Val Acc: 0.3750
2025-06-22 05:48:09,316 [INFO] Epoch 038 | Train Loss: 1.5621 | Val Loss: 2.5032 | Val Acc: 0.3571
2025-06-22 05:48:09,432 [INFO] Epoch 039 | Train Loss: 1.6217 | Val Loss: 2.7295 | Val Acc: 0.3214
2025-06-22 05:48:09,529 [INFO] Epoch 040 | Train Loss: 2.4801 | Val Loss: 2.8463 | Val Acc: 0.3750
2025-06-22 05:48:10,249 [INFO] Epoch 041 | Train Loss: 1.7001 | Val Loss: 3.0769 | Val Acc: 0.4107
2025-06-22 05:48:10,353 [INFO] Epoch 042 | Train Loss: 2.6210 | Val Loss: 2.8228 | Val Acc: 0.4107
2025-06-22 05:48:10,472 [INFO] Epoch 043 | Train Loss: 2.0081 | Val Loss: 2.6423 | Val Acc: 0.3929
2025-06-22 05:48:10,568 [INFO] Epoch 044 | Train Loss: 1.4953 | Val Loss: 3.1813 | Val Acc: 0.4643
2025-06-22 05:48:10,665 [INFO] Epoch 045 | Train Loss: 2.2155 | Val Loss: 3.3467 | Val Acc: 0.3571
2025-06-22 05:48:10,802 [INFO] Epoch 046 | Train Loss: 1.7443 | Val Loss: 3.2948 | Val Acc: 0.3571
2025-06-22 05:48:10,896 [INFO] Epoch 047 | Train Loss: 1.8433 | Val Loss: 2.7497 | Val Acc: 0.4643
2025-06-22 05:48:11,011 [INFO] Epoch 048 | Train Loss: 1.6054 | Val Loss: 3.2080 | Val Acc: 0.4821
2025-06-22 05:48:11,112 [INFO] Epoch 049 | Train Loss: 1.7794 | Val Loss: 2.7027 | Val Acc: 0.4107
2025-06-22 05:48:11,224 [INFO] Epoch 050 | Train Loss: 1.4278 | Val Loss: 2.4133 | Val Acc: 0.4107
2025-06-22 05:48:13,203 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.4821 at epoch 6)
2025-06-22 05:48:13,203 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.001/train_metrics.csv
2025-06-22 05:48:13,920 [INFO] Final training curves saved
2025-06-22 05:48:13,920 [INFO] Training completed!
2025-06-22 05:48:13,921 [INFO] Best validation accuracy: 0.4821
2025-06-22 05:48:13,921 [INFO] Best epoch: 6
2025-06-22 05:48:13,921 [INFO] Total epochs trained: 50
2025-06-22 05:48:13,922 [INFO] Starting training with parameters: (0.001, 0.3, 512, 3, 50, 0.0001)
