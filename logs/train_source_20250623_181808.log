2025-06-23 18:18:08,669 [INFO] Using device: cpu
2025-06-23 18:18:08,669 [INFO] 开始创建数据加载器...
2025-06-23 18:18:08,675 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-23 18:18:08,675 [INFO] Class allocation analysis:
2025-06-23 18:18:08,675 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-23 18:18:08,675 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-23 18:18:08,675 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-23 18:18:08,675 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-23 18:18:08,689 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-23 18:18:08,690 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-23 18:18:08,690 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-23 18:18:08,690 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-23 18:18:08,690 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-23 18:18:08,690 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-23 18:18:08,690 [INFO] Final allocation:
2025-06-23 18:18:08,690 [INFO]   Source domain: 280 samples
2025-06-23 18:18:08,690 [INFO]   Target domain: 320 samples
2025-06-23 18:18:08,692 [INFO] Source domain setup:
2025-06-23 18:18:08,692 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-23 18:18:08,692 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-23 18:18:08,692 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-23 18:18:08,692 [INFO]   Total data after allocation: 280
2025-06-23 18:18:08,692 [INFO]   Data split - Train: 224, Val: 56
2025-06-23 18:18:08,692 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-23 18:18:08,692 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-23 18:18:08,694 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-23 18:18:08,694 [INFO] Class allocation analysis:
2025-06-23 18:18:08,694 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-23 18:18:08,694 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-23 18:18:08,694 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-23 18:18:08,694 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-23 18:18:08,708 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-23 18:18:08,709 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-23 18:18:08,709 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-23 18:18:08,709 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-23 18:18:08,709 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-23 18:18:08,709 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-23 18:18:08,709 [INFO] Final allocation:
2025-06-23 18:18:08,709 [INFO]   Source domain: 280 samples
2025-06-23 18:18:08,709 [INFO]   Target domain: 320 samples
2025-06-23 18:18:08,711 [INFO] Target domain setup:
2025-06-23 18:18:08,711 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-23 18:18:08,711 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-23 18:18:08,711 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-23 18:18:08,711 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-23 18:18:08,711 [INFO]   Total data after allocation: 320
2025-06-23 18:18:08,711 [INFO]   Data split - Train: 256, Val: 64
2025-06-23 18:18:08,711 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-23 18:18:08,711 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-23 18:18:08,711 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-23 18:18:08,711 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-23 18:18:08,712 [INFO] 数据加载器创建完成!
2025-06-23 18:18:08,712 [INFO] 源域类别数: 4 (重叠类别)
2025-06-23 18:18:08,712 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-23 18:18:08,712 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-23 18:18:08,712 [INFO] 目标域新类别: [4, 5]
2025-06-23 18:18:08,712 [INFO] Data allocation verification:
2025-06-23 18:18:08,712 [INFO]   Source data samples: 280
2025-06-23 18:18:08,712 [INFO]   Target data samples: 320
2025-06-23 18:18:08,712 [INFO]   Overlapping samples: 0
2025-06-23 18:18:08,712 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-23 18:18:08,714 [INFO] Model initialized with 5924 parameters
2025-06-23 18:18:08,714 [INFO] Previous best validation accuracy read from record.txt: 0.6429
2025-06-23 18:18:08,714 [INFO] Starting training...
2025-06-23 18:18:08,747 [INFO] Epoch 001 | Train Loss: 8.3722 | Val Loss: 2.6016 | Val Acc: 0.2500
2025-06-23 18:18:09,988 [INFO] New best model at epoch 1 (Val Acc: 0.2500)
2025-06-23 18:18:10,006 [INFO] Epoch 002 | Train Loss: 4.3300 | Val Loss: 2.1731 | Val Acc: 0.2500
2025-06-23 18:18:10,028 [INFO] Epoch 003 | Train Loss: 3.1074 | Val Loss: 1.6805 | Val Acc: 0.3929
2025-06-23 18:18:10,031 [INFO] New best model at epoch 3 (Val Acc: 0.3929)
2025-06-23 18:18:10,052 [INFO] Epoch 004 | Train Loss: 2.0600 | Val Loss: 1.7278 | Val Acc: 0.3750
2025-06-23 18:18:10,075 [INFO] Epoch 005 | Train Loss: 2.5259 | Val Loss: 1.6738 | Val Acc: 0.3393
2025-06-23 18:18:10,097 [INFO] Epoch 006 | Train Loss: 1.7138 | Val Loss: 1.3989 | Val Acc: 0.3214
2025-06-23 18:18:10,116 [INFO] Epoch 007 | Train Loss: 2.2929 | Val Loss: 1.6033 | Val Acc: 0.2857
2025-06-23 18:18:10,142 [INFO] Epoch 008 | Train Loss: 1.7042 | Val Loss: 1.6396 | Val Acc: 0.2500
2025-06-23 18:18:10,176 [INFO] Epoch 009 | Train Loss: 1.6763 | Val Loss: 1.3521 | Val Acc: 0.3571
2025-06-23 18:18:10,214 [INFO] Epoch 010 | Train Loss: 1.6228 | Val Loss: 1.4480 | Val Acc: 0.3750
2025-06-23 18:18:14,163 [INFO] Epoch 011 | Train Loss: 1.6568 | Val Loss: 1.5030 | Val Acc: 0.3393
2025-06-23 18:18:14,185 [INFO] Epoch 012 | Train Loss: 1.5973 | Val Loss: 1.5940 | Val Acc: 0.2857
2025-06-23 18:18:14,211 [INFO] Epoch 013 | Train Loss: 1.5824 | Val Loss: 1.9515 | Val Acc: 0.3214
2025-06-23 18:18:14,239 [INFO] Epoch 014 | Train Loss: 1.5620 | Val Loss: 1.8299 | Val Acc: 0.2500
2025-06-23 18:18:14,264 [INFO] Epoch 015 | Train Loss: 1.6334 | Val Loss: 1.7717 | Val Acc: 0.2143
2025-06-23 18:18:14,285 [INFO] Epoch 016 | Train Loss: 1.6136 | Val Loss: 1.6283 | Val Acc: 0.2679
2025-06-23 18:18:14,305 [INFO] Epoch 017 | Train Loss: 1.6244 | Val Loss: 1.4443 | Val Acc: 0.3393
2025-06-23 18:18:14,325 [INFO] Epoch 018 | Train Loss: 1.4440 | Val Loss: 1.5541 | Val Acc: 0.2679
2025-06-23 18:18:14,344 [INFO] Epoch 019 | Train Loss: 1.3524 | Val Loss: 1.4854 | Val Acc: 0.2500
2025-06-23 18:18:14,363 [INFO] Epoch 020 | Train Loss: 1.5171 | Val Loss: 1.5758 | Val Acc: 0.2321
2025-06-23 18:18:15,636 [INFO] Epoch 021 | Train Loss: 1.4448 | Val Loss: 1.6384 | Val Acc: 0.2857
2025-06-23 18:18:15,659 [INFO] Epoch 022 | Train Loss: 1.6270 | Val Loss: 1.4724 | Val Acc: 0.3036
2025-06-23 18:18:15,681 [INFO] Epoch 023 | Train Loss: 1.3794 | Val Loss: 1.4283 | Val Acc: 0.3393
2025-06-23 18:18:15,706 [INFO] Epoch 024 | Train Loss: 1.5528 | Val Loss: 1.5289 | Val Acc: 0.3214
2025-06-23 18:18:15,729 [INFO] Epoch 025 | Train Loss: 1.5896 | Val Loss: 1.6151 | Val Acc: 0.3929
2025-06-23 18:18:15,749 [INFO] Epoch 026 | Train Loss: 1.3448 | Val Loss: 1.6442 | Val Acc: 0.3571
2025-06-23 18:18:15,768 [INFO] Epoch 027 | Train Loss: 1.4859 | Val Loss: 1.7183 | Val Acc: 0.2679
2025-06-23 18:18:15,788 [INFO] Epoch 028 | Train Loss: 1.3821 | Val Loss: 1.6895 | Val Acc: 0.3393
2025-06-23 18:18:15,807 [INFO] Epoch 029 | Train Loss: 1.3651 | Val Loss: 1.4956 | Val Acc: 0.3036
2025-06-23 18:18:15,832 [INFO] Epoch 030 | Train Loss: 1.3785 | Val Loss: 1.8452 | Val Acc: 0.2321
2025-06-23 18:18:17,073 [INFO] Epoch 031 | Train Loss: 1.2824 | Val Loss: 1.4821 | Val Acc: 0.3393
2025-06-23 18:18:17,097 [INFO] Epoch 032 | Train Loss: 1.3328 | Val Loss: 1.4645 | Val Acc: 0.3571
2025-06-23 18:18:17,121 [INFO] Epoch 033 | Train Loss: 1.3005 | Val Loss: 1.7516 | Val Acc: 0.3929
2025-06-23 18:18:17,146 [INFO] Epoch 034 | Train Loss: 1.2985 | Val Loss: 1.6062 | Val Acc: 0.3036
2025-06-23 18:18:17,169 [INFO] Epoch 035 | Train Loss: 1.3086 | Val Loss: 1.6683 | Val Acc: 0.3214
2025-06-23 18:18:17,194 [INFO] Epoch 036 | Train Loss: 1.2792 | Val Loss: 1.6443 | Val Acc: 0.3393
2025-06-23 18:18:17,221 [INFO] Epoch 037 | Train Loss: 1.1749 | Val Loss: 1.6607 | Val Acc: 0.3036
2025-06-23 18:18:17,244 [INFO] Epoch 038 | Train Loss: 1.2755 | Val Loss: 1.5289 | Val Acc: 0.3393
2025-06-23 18:18:17,265 [INFO] Epoch 039 | Train Loss: 1.2016 | Val Loss: 1.5266 | Val Acc: 0.3214
2025-06-23 18:18:17,285 [INFO] Epoch 040 | Train Loss: 1.2042 | Val Loss: 1.5884 | Val Acc: 0.3393
2025-06-23 18:18:18,546 [INFO] Epoch 041 | Train Loss: 1.4251 | Val Loss: 1.8012 | Val Acc: 0.3571
2025-06-23 18:18:18,570 [INFO] Epoch 042 | Train Loss: 1.2996 | Val Loss: 1.7021 | Val Acc: 0.3571
2025-06-23 18:18:18,597 [INFO] Epoch 043 | Train Loss: 1.1675 | Val Loss: 1.5474 | Val Acc: 0.3929
2025-06-23 18:18:18,620 [INFO] Epoch 044 | Train Loss: 1.3737 | Val Loss: 1.6569 | Val Acc: 0.3393
2025-06-23 18:18:18,643 [INFO] Epoch 045 | Train Loss: 1.1877 | Val Loss: 1.6483 | Val Acc: 0.3929
2025-06-23 18:18:18,669 [INFO] Epoch 046 | Train Loss: 1.3132 | Val Loss: 1.6719 | Val Acc: 0.3571
2025-06-23 18:18:18,692 [INFO] Epoch 047 | Train Loss: 1.2408 | Val Loss: 1.4445 | Val Acc: 0.3750
2025-06-23 18:18:18,712 [INFO] Epoch 048 | Train Loss: 1.2272 | Val Loss: 1.4081 | Val Acc: 0.4107
2025-06-23 18:18:18,716 [INFO] New best model at epoch 48 (Val Acc: 0.4107)
2025-06-23 18:18:18,734 [INFO] Epoch 049 | Train Loss: 1.1507 | Val Loss: 1.5120 | Val Acc: 0.3393
2025-06-23 18:18:18,754 [INFO] Epoch 050 | Train Loss: 1.1349 | Val Loss: 1.4170 | Val Acc: 0.3036
2025-06-23 18:18:20,957 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.4107 at epoch 48)
2025-06-23 18:18:20,958 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.01/train_metrics.csv
2025-06-23 18:18:22,307 [INFO] Final training curves saved
2025-06-23 18:18:22,307 [INFO] Training completed!
2025-06-23 18:18:22,307 [INFO] Best validation accuracy: 0.4107
2025-06-23 18:18:22,307 [INFO] Best epoch: 48
2025-06-23 18:18:22,307 [INFO] Total epochs trained: 50
2025-06-23 18:18:22,308 [INFO] Starting training with parameters: (0.01, 0.4, 32, 3, 50, 0.0001)
