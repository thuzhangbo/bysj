2025-06-22 00:03:16,450 [INFO] Using device: cpu
2025-06-22 00:03:16,450 [INFO] 开始创建数据加载器...
2025-06-22 00:03:16,451 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 00:03:16,451 [INFO] Class allocation analysis:
2025-06-22 00:03:16,451 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 00:03:16,451 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 00:03:16,451 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 00:03:16,451 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 00:03:16,464 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 00:03:16,464 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 00:03:16,464 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 00:03:16,464 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 00:03:16,465 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 00:03:16,465 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 00:03:16,465 [INFO] Final allocation:
2025-06-22 00:03:16,465 [INFO]   Source domain: 280 samples
2025-06-22 00:03:16,465 [INFO]   Target domain: 320 samples
2025-06-22 00:03:16,466 [INFO] Source domain setup:
2025-06-22 00:03:16,466 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-22 00:03:16,466 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-22 00:03:16,466 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-22 00:03:16,466 [INFO]   Total data after allocation: 280
2025-06-22 00:03:16,466 [INFO]   Data split - Train: 224, Val: 56
2025-06-22 00:03:16,466 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-22 00:03:16,466 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-22 00:03:16,467 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 00:03:16,467 [INFO] Class allocation analysis:
2025-06-22 00:03:16,467 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 00:03:16,467 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 00:03:16,467 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 00:03:16,467 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 00:03:16,480 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 00:03:16,480 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 00:03:16,480 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 00:03:16,480 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 00:03:16,480 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 00:03:16,480 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 00:03:16,480 [INFO] Final allocation:
2025-06-22 00:03:16,480 [INFO]   Source domain: 280 samples
2025-06-22 00:03:16,480 [INFO]   Target domain: 320 samples
2025-06-22 00:03:16,482 [INFO] Target domain setup:
2025-06-22 00:03:16,482 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-22 00:03:16,482 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-22 00:03:16,482 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-22 00:03:16,482 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-22 00:03:16,482 [INFO]   Total data after allocation: 320
2025-06-22 00:03:16,482 [INFO]   Data split - Train: 256, Val: 64
2025-06-22 00:03:16,482 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-22 00:03:16,482 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-22 00:03:16,482 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-22 00:03:16,482 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-22 00:03:16,482 [INFO] 数据加载器创建完成!
2025-06-22 00:03:16,482 [INFO] 源域类别数: 4 (重叠类别)
2025-06-22 00:03:16,482 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-22 00:03:16,482 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-22 00:03:16,482 [INFO] 目标域新类别: [4, 5]
2025-06-22 00:03:16,482 [INFO] Data allocation verification:
2025-06-22 00:03:16,483 [INFO]   Source data samples: 280
2025-06-22 00:03:16,483 [INFO]   Target data samples: 320
2025-06-22 00:03:16,483 [INFO]   Overlapping samples: 0
2025-06-22 00:03:16,483 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-22 00:03:16,483 [INFO] Model initialized with 1444 parameters
2025-06-22 00:03:16,483 [INFO] Previous best validation accuracy read from record.txt: 0.6250
2025-06-22 00:03:16,483 [INFO] Starting training...
2025-06-22 00:03:16,492 [INFO] Epoch 001 | Train Loss: 9.1983 | Val Loss: 4.5287 | Val Acc: 0.2500
2025-06-22 00:03:16,847 [INFO] New best model at epoch 1 (Val Acc: 0.2500)
2025-06-22 00:03:16,856 [INFO] Epoch 002 | Train Loss: 5.6285 | Val Loss: 2.7744 | Val Acc: 0.1607
2025-06-22 00:03:16,868 [INFO] Epoch 003 | Train Loss: 4.1683 | Val Loss: 2.1183 | Val Acc: 0.3393
2025-06-22 00:03:16,869 [INFO] New best model at epoch 3 (Val Acc: 0.3393)
2025-06-22 00:03:16,877 [INFO] Epoch 004 | Train Loss: 3.4178 | Val Loss: 1.8265 | Val Acc: 0.3214
2025-06-22 00:03:16,886 [INFO] Epoch 005 | Train Loss: 3.4825 | Val Loss: 1.9030 | Val Acc: 0.3036
2025-06-22 00:03:16,894 [INFO] Epoch 006 | Train Loss: 2.8793 | Val Loss: 1.7805 | Val Acc: 0.2857
2025-06-22 00:03:16,904 [INFO] Epoch 007 | Train Loss: 2.9965 | Val Loss: 1.7995 | Val Acc: 0.2857
2025-06-22 00:03:16,912 [INFO] Epoch 008 | Train Loss: 2.7676 | Val Loss: 1.8376 | Val Acc: 0.3036
2025-06-22 00:03:16,921 [INFO] Epoch 009 | Train Loss: 2.6525 | Val Loss: 1.8000 | Val Acc: 0.3036
2025-06-22 00:03:16,929 [INFO] Epoch 010 | Train Loss: 2.5468 | Val Loss: 1.5582 | Val Acc: 0.3393
2025-06-22 00:03:17,304 [INFO] Epoch 011 | Train Loss: 2.3098 | Val Loss: 1.4776 | Val Acc: 0.4464
2025-06-22 00:03:17,305 [INFO] New best model at epoch 11 (Val Acc: 0.4464)
2025-06-22 00:03:17,313 [INFO] Epoch 012 | Train Loss: 2.4661 | Val Loss: 1.4743 | Val Acc: 0.3214
2025-06-22 00:03:17,322 [INFO] Epoch 013 | Train Loss: 2.5379 | Val Loss: 1.5537 | Val Acc: 0.3036
2025-06-22 00:03:17,331 [INFO] Epoch 014 | Train Loss: 2.0703 | Val Loss: 1.4893 | Val Acc: 0.3214
2025-06-22 00:03:17,340 [INFO] Epoch 015 | Train Loss: 2.2676 | Val Loss: 1.5525 | Val Acc: 0.3393
2025-06-22 00:03:17,348 [INFO] Epoch 016 | Train Loss: 2.2746 | Val Loss: 1.5870 | Val Acc: 0.3929
2025-06-22 00:03:17,357 [INFO] Epoch 017 | Train Loss: 2.1957 | Val Loss: 1.5436 | Val Acc: 0.3214
2025-06-22 00:03:17,365 [INFO] Epoch 018 | Train Loss: 2.0533 | Val Loss: 1.5520 | Val Acc: 0.2679
2025-06-22 00:03:17,374 [INFO] Epoch 019 | Train Loss: 2.2546 | Val Loss: 1.5463 | Val Acc: 0.2857
2025-06-22 00:03:17,382 [INFO] Epoch 020 | Train Loss: 2.0813 | Val Loss: 1.5646 | Val Acc: 0.3393
2025-06-22 00:03:17,757 [INFO] Epoch 021 | Train Loss: 2.1435 | Val Loss: 1.7632 | Val Acc: 0.2679
2025-06-22 00:03:17,766 [INFO] Epoch 022 | Train Loss: 1.7573 | Val Loss: 1.7327 | Val Acc: 0.2500
2025-06-22 00:03:17,774 [INFO] Epoch 023 | Train Loss: 1.9704 | Val Loss: 1.5921 | Val Acc: 0.2857
2025-06-22 00:03:17,783 [INFO] Epoch 024 | Train Loss: 2.5022 | Val Loss: 1.6248 | Val Acc: 0.3214
2025-06-22 00:03:17,791 [INFO] Epoch 025 | Train Loss: 2.2582 | Val Loss: 1.6590 | Val Acc: 0.3036
2025-06-22 00:03:17,800 [INFO] Epoch 026 | Train Loss: 1.9071 | Val Loss: 1.6032 | Val Acc: 0.3214
2025-06-22 00:03:17,808 [INFO] Epoch 027 | Train Loss: 2.3879 | Val Loss: 1.5159 | Val Acc: 0.3750
2025-06-22 00:03:17,816 [INFO] Epoch 028 | Train Loss: 1.8771 | Val Loss: 1.5951 | Val Acc: 0.3750
2025-06-22 00:03:17,825 [INFO] Epoch 029 | Train Loss: 1.8021 | Val Loss: 1.5026 | Val Acc: 0.3571
2025-06-22 00:03:17,833 [INFO] Epoch 030 | Train Loss: 2.0127 | Val Loss: 1.4914 | Val Acc: 0.3750
2025-06-22 00:03:18,194 [INFO] Epoch 031 | Train Loss: 1.9026 | Val Loss: 1.6008 | Val Acc: 0.3393
2025-06-22 00:03:18,209 [INFO] Epoch 032 | Train Loss: 1.8154 | Val Loss: 1.5679 | Val Acc: 0.3393
2025-06-22 00:03:18,219 [INFO] Epoch 033 | Train Loss: 1.9679 | Val Loss: 1.6476 | Val Acc: 0.3214
2025-06-22 00:03:18,228 [INFO] Epoch 034 | Train Loss: 1.9493 | Val Loss: 1.5162 | Val Acc: 0.3571
2025-06-22 00:03:18,237 [INFO] Epoch 035 | Train Loss: 2.2282 | Val Loss: 1.5751 | Val Acc: 0.3393
2025-06-22 00:03:18,246 [INFO] Epoch 036 | Train Loss: 1.6551 | Val Loss: 1.5429 | Val Acc: 0.3750
2025-06-22 00:03:18,254 [INFO] Epoch 037 | Train Loss: 1.8964 | Val Loss: 1.5988 | Val Acc: 0.3036
2025-06-22 00:03:18,263 [INFO] Epoch 038 | Train Loss: 1.9571 | Val Loss: 1.5747 | Val Acc: 0.3571
2025-06-22 00:03:18,272 [INFO] Epoch 039 | Train Loss: 2.0010 | Val Loss: 1.5176 | Val Acc: 0.3571
2025-06-22 00:03:18,281 [INFO] Epoch 040 | Train Loss: 1.6791 | Val Loss: 1.4349 | Val Acc: 0.3393
2025-06-22 00:03:18,628 [INFO] Epoch 041 | Train Loss: 1.4963 | Val Loss: 1.5193 | Val Acc: 0.3214
2025-06-22 00:03:18,637 [INFO] Epoch 042 | Train Loss: 1.5990 | Val Loss: 1.5428 | Val Acc: 0.3929
2025-06-22 00:03:18,646 [INFO] Epoch 043 | Train Loss: 1.7426 | Val Loss: 1.6524 | Val Acc: 0.4286
2025-06-22 00:03:18,654 [INFO] Epoch 044 | Train Loss: 1.7556 | Val Loss: 1.4968 | Val Acc: 0.3929
2025-06-22 00:03:18,663 [INFO] Epoch 045 | Train Loss: 1.7020 | Val Loss: 1.4282 | Val Acc: 0.3929
2025-06-22 00:03:18,673 [INFO] Epoch 046 | Train Loss: 1.5786 | Val Loss: 1.4148 | Val Acc: 0.3571
2025-06-22 00:03:18,682 [INFO] Epoch 047 | Train Loss: 1.5623 | Val Loss: 1.4331 | Val Acc: 0.3929
2025-06-22 00:03:18,692 [INFO] Epoch 048 | Train Loss: 1.6353 | Val Loss: 1.4513 | Val Acc: 0.4107
2025-06-22 00:03:18,702 [INFO] Epoch 049 | Train Loss: 1.5772 | Val Loss: 1.4890 | Val Acc: 0.3571
2025-06-22 00:03:18,714 [INFO] Epoch 050 | Train Loss: 1.8583 | Val Loss: 1.5353 | Val Acc: 0.3393
2025-06-22 00:03:19,066 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.4464 at epoch 11)
2025-06-22 00:03:19,066 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.001/train_metrics.csv
2025-06-22 00:03:19,681 [INFO] Final training curves saved
2025-06-22 00:03:19,681 [INFO] Training completed!
2025-06-22 00:03:19,681 [INFO] Best validation accuracy: 0.4464
2025-06-22 00:03:19,681 [INFO] Best epoch: 11
2025-06-22 00:03:19,681 [INFO] Total epochs trained: 50
2025-06-22 00:03:19,681 [INFO] Starting training with parameters: (0.001, 0.1, 32, 1, 50, 0.001)
