2025-06-23 14:12:09,948 [INFO] Using device: cpu
2025-06-23 14:12:09,948 [INFO] 开始创建数据加载器...
2025-06-23 14:12:09,951 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-23 14:12:09,951 [INFO] Class allocation analysis:
2025-06-23 14:12:09,951 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-23 14:12:09,951 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-23 14:12:09,951 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-23 14:12:09,951 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-23 14:12:09,965 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-23 14:12:09,965 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-23 14:12:09,965 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-23 14:12:09,965 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-23 14:12:09,965 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-23 14:12:09,965 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-23 14:12:09,965 [INFO] Final allocation:
2025-06-23 14:12:09,965 [INFO]   Source domain: 280 samples
2025-06-23 14:12:09,965 [INFO]   Target domain: 320 samples
2025-06-23 14:12:09,967 [INFO] Source domain setup:
2025-06-23 14:12:09,967 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-23 14:12:09,967 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-23 14:12:09,967 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-23 14:12:09,967 [INFO]   Total data after allocation: 280
2025-06-23 14:12:09,967 [INFO]   Data split - Train: 224, Val: 56
2025-06-23 14:12:09,967 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-23 14:12:09,967 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-23 14:12:09,969 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-23 14:12:09,969 [INFO] Class allocation analysis:
2025-06-23 14:12:09,969 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-23 14:12:09,969 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-23 14:12:09,969 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-23 14:12:09,969 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-23 14:12:09,982 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-23 14:12:09,983 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-23 14:12:09,983 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-23 14:12:09,983 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-23 14:12:09,983 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-23 14:12:09,983 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-23 14:12:09,983 [INFO] Final allocation:
2025-06-23 14:12:09,983 [INFO]   Source domain: 280 samples
2025-06-23 14:12:09,983 [INFO]   Target domain: 320 samples
2025-06-23 14:12:09,985 [INFO] Target domain setup:
2025-06-23 14:12:09,985 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-23 14:12:09,985 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-23 14:12:09,985 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-23 14:12:09,985 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-23 14:12:09,985 [INFO]   Total data after allocation: 320
2025-06-23 14:12:09,985 [INFO]   Data split - Train: 256, Val: 64
2025-06-23 14:12:09,985 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-23 14:12:09,985 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-23 14:12:09,985 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-23 14:12:09,985 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-23 14:12:09,986 [INFO] 数据加载器创建完成!
2025-06-23 14:12:09,986 [INFO] 源域类别数: 4 (重叠类别)
2025-06-23 14:12:09,986 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-23 14:12:09,986 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-23 14:12:09,986 [INFO] 目标域新类别: [4, 5]
2025-06-23 14:12:09,986 [INFO] Data allocation verification:
2025-06-23 14:12:09,986 [INFO]   Source data samples: 280
2025-06-23 14:12:09,986 [INFO]   Target data samples: 320
2025-06-23 14:12:09,986 [INFO]   Overlapping samples: 0
2025-06-23 14:12:09,986 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-23 14:12:09,988 [INFO] Model initialized with 10404 parameters
2025-06-23 14:12:09,988 [INFO] Previous best validation accuracy read from record.txt: 0.6429
2025-06-23 14:12:09,988 [INFO] Starting training...
2025-06-23 14:12:10,027 [INFO] Epoch 001 | Train Loss: 7.5387 | Val Loss: 1.5686 | Val Acc: 0.3393
2025-06-23 14:12:11,233 [INFO] New best model at epoch 1 (Val Acc: 0.3393)
2025-06-23 14:12:11,269 [INFO] Epoch 002 | Train Loss: 3.9115 | Val Loss: 1.5438 | Val Acc: 0.3750
2025-06-23 14:12:11,274 [INFO] New best model at epoch 2 (Val Acc: 0.3750)
2025-06-23 14:12:11,312 [INFO] Epoch 003 | Train Loss: 4.2793 | Val Loss: 1.6821 | Val Acc: 0.3393
2025-06-23 14:12:11,347 [INFO] Epoch 004 | Train Loss: 3.3475 | Val Loss: 1.4209 | Val Acc: 0.3214
2025-06-23 14:12:11,379 [INFO] Epoch 005 | Train Loss: 2.0287 | Val Loss: 1.3872 | Val Acc: 0.2857
2025-06-23 14:12:11,412 [INFO] Epoch 006 | Train Loss: 1.9694 | Val Loss: 1.8678 | Val Acc: 0.2857
2025-06-23 14:12:11,443 [INFO] Epoch 007 | Train Loss: 1.8312 | Val Loss: 1.5872 | Val Acc: 0.3214
2025-06-23 14:12:11,474 [INFO] Epoch 008 | Train Loss: 1.7816 | Val Loss: 1.6346 | Val Acc: 0.2857
2025-06-23 14:12:11,505 [INFO] Epoch 009 | Train Loss: 1.6690 | Val Loss: 1.7450 | Val Acc: 0.3214
2025-06-23 14:12:11,537 [INFO] Epoch 010 | Train Loss: 1.9621 | Val Loss: 1.4538 | Val Acc: 0.3214
2025-06-23 14:12:12,731 [INFO] Epoch 011 | Train Loss: 1.4448 | Val Loss: 1.4307 | Val Acc: 0.3571
2025-06-23 14:12:12,768 [INFO] Epoch 012 | Train Loss: 1.6747 | Val Loss: 1.6133 | Val Acc: 0.3571
2025-06-23 14:12:12,813 [INFO] Epoch 013 | Train Loss: 1.7834 | Val Loss: 1.4559 | Val Acc: 0.2857
2025-06-23 14:12:12,852 [INFO] Epoch 014 | Train Loss: 1.4172 | Val Loss: 1.7761 | Val Acc: 0.3393
2025-06-23 14:12:12,883 [INFO] Epoch 015 | Train Loss: 1.5790 | Val Loss: 1.4986 | Val Acc: 0.3214
2025-06-23 14:12:12,914 [INFO] Epoch 016 | Train Loss: 1.6137 | Val Loss: 1.4034 | Val Acc: 0.3571
2025-06-23 14:12:12,948 [INFO] Epoch 017 | Train Loss: 1.7266 | Val Loss: 1.3853 | Val Acc: 0.3571
2025-06-23 14:12:12,979 [INFO] Epoch 018 | Train Loss: 1.5101 | Val Loss: 1.5178 | Val Acc: 0.3750
2025-06-23 14:12:13,011 [INFO] Epoch 019 | Train Loss: 1.3502 | Val Loss: 1.4593 | Val Acc: 0.3750
2025-06-23 14:12:13,044 [INFO] Epoch 020 | Train Loss: 1.6437 | Val Loss: 1.4075 | Val Acc: 0.3214
2025-06-23 14:12:17,701 [INFO] Epoch 021 | Train Loss: 1.5719 | Val Loss: 1.3362 | Val Acc: 0.3393
2025-06-23 14:12:17,739 [INFO] Epoch 022 | Train Loss: 1.4672 | Val Loss: 1.6207 | Val Acc: 0.3393
2025-06-23 14:12:17,774 [INFO] Epoch 023 | Train Loss: 1.2977 | Val Loss: 1.6712 | Val Acc: 0.3393
2025-06-23 14:12:17,806 [INFO] Epoch 024 | Train Loss: 1.4565 | Val Loss: 1.5814 | Val Acc: 0.3393
2025-06-23 14:12:17,840 [INFO] Epoch 025 | Train Loss: 1.4305 | Val Loss: 1.5013 | Val Acc: 0.3393
2025-06-23 14:12:17,874 [INFO] Epoch 026 | Train Loss: 1.4584 | Val Loss: 1.4870 | Val Acc: 0.3393
2025-06-23 14:12:17,911 [INFO] Epoch 027 | Train Loss: 1.3199 | Val Loss: 1.6090 | Val Acc: 0.3393
2025-06-23 14:12:17,945 [INFO] Epoch 028 | Train Loss: 1.4900 | Val Loss: 1.8107 | Val Acc: 0.3393
2025-06-23 14:12:17,977 [INFO] Epoch 029 | Train Loss: 1.3951 | Val Loss: 1.8693 | Val Acc: 0.3571
2025-06-23 14:12:18,009 [INFO] Epoch 030 | Train Loss: 1.3332 | Val Loss: 1.7684 | Val Acc: 0.3214
2025-06-23 14:12:19,314 [INFO] Epoch 031 | Train Loss: 1.3493 | Val Loss: 1.5751 | Val Acc: 0.3214
2025-06-23 14:12:19,356 [INFO] Epoch 032 | Train Loss: 1.3147 | Val Loss: 1.4365 | Val Acc: 0.3571
2025-06-23 14:12:19,415 [INFO] Epoch 033 | Train Loss: 1.2368 | Val Loss: 1.5696 | Val Acc: 0.3214
2025-06-23 14:12:19,458 [INFO] Epoch 034 | Train Loss: 1.2398 | Val Loss: 1.3912 | Val Acc: 0.3393
2025-06-23 14:12:19,490 [INFO] Epoch 035 | Train Loss: 1.3962 | Val Loss: 1.3425 | Val Acc: 0.3750
2025-06-23 14:12:19,522 [INFO] Epoch 036 | Train Loss: 1.2663 | Val Loss: 1.4885 | Val Acc: 0.3214
2025-06-23 14:12:19,554 [INFO] Epoch 037 | Train Loss: 1.2409 | Val Loss: 1.5202 | Val Acc: 0.2857
2025-06-23 14:12:19,594 [INFO] Epoch 038 | Train Loss: 1.4548 | Val Loss: 1.4151 | Val Acc: 0.2857
2025-06-23 14:12:19,625 [INFO] Epoch 039 | Train Loss: 1.3656 | Val Loss: 1.8160 | Val Acc: 0.3214
2025-06-23 14:12:19,658 [INFO] Epoch 040 | Train Loss: 1.1630 | Val Loss: 1.4128 | Val Acc: 0.3571
2025-06-23 14:12:20,947 [INFO] Epoch 041 | Train Loss: 1.2384 | Val Loss: 1.5530 | Val Acc: 0.3571
2025-06-23 14:12:20,990 [INFO] Epoch 042 | Train Loss: 1.1569 | Val Loss: 1.8886 | Val Acc: 0.3929
2025-06-23 14:12:20,995 [INFO] New best model at epoch 42 (Val Acc: 0.3929)
2025-06-23 14:12:21,027 [INFO] Epoch 043 | Train Loss: 1.2927 | Val Loss: 1.5193 | Val Acc: 0.3393
2025-06-23 14:12:21,060 [INFO] Epoch 044 | Train Loss: 1.3780 | Val Loss: 1.4597 | Val Acc: 0.3750
2025-06-23 14:12:21,098 [INFO] Epoch 045 | Train Loss: 1.2120 | Val Loss: 1.6911 | Val Acc: 0.3393
2025-06-23 14:12:21,131 [INFO] Epoch 046 | Train Loss: 1.3550 | Val Loss: 1.6195 | Val Acc: 0.3750
2025-06-23 14:12:21,163 [INFO] Epoch 047 | Train Loss: 1.1887 | Val Loss: 1.3201 | Val Acc: 0.3571
2025-06-23 14:12:21,193 [INFO] Epoch 048 | Train Loss: 1.1909 | Val Loss: 1.5931 | Val Acc: 0.3571
2025-06-23 14:12:21,224 [INFO] Epoch 049 | Train Loss: 1.3199 | Val Loss: 1.4042 | Val Acc: 0.3571
2025-06-23 14:12:21,258 [INFO] Epoch 050 | Train Loss: 1.3050 | Val Loss: 1.3807 | Val Acc: 0.3393
2025-06-23 14:12:22,532 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.3929 at epoch 42)
2025-06-23 14:12:22,533 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.01/train_metrics.csv
2025-06-23 14:12:25,042 [INFO] Final training curves saved
2025-06-23 14:12:25,043 [INFO] Training completed!
2025-06-23 14:12:25,043 [INFO] Best validation accuracy: 0.3929
2025-06-23 14:12:25,043 [INFO] Best epoch: 42
2025-06-23 14:12:25,043 [INFO] Total epochs trained: 50
2025-06-23 14:12:25,044 [INFO] Starting training with parameters: (0.01, 0.3, 32, 5, 50, 0.001)
