2025-06-22 09:00:38,375 [INFO] Using device: cpu
2025-06-22 09:00:38,375 [INFO] 开始创建数据加载器...
2025-06-22 09:00:38,379 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 09:00:38,379 [INFO] Class allocation analysis:
2025-06-22 09:00:38,379 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 09:00:38,379 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 09:00:38,379 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 09:00:38,379 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 09:00:38,398 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 09:00:38,398 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 09:00:38,398 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 09:00:38,399 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 09:00:38,399 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 09:00:38,399 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 09:00:38,399 [INFO] Final allocation:
2025-06-22 09:00:38,399 [INFO]   Source domain: 280 samples
2025-06-22 09:00:38,399 [INFO]   Target domain: 320 samples
2025-06-22 09:00:38,400 [INFO] Source domain setup:
2025-06-22 09:00:38,400 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-22 09:00:38,400 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-22 09:00:38,400 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-22 09:00:38,400 [INFO]   Total data after allocation: 280
2025-06-22 09:00:38,400 [INFO]   Data split - Train: 224, Val: 56
2025-06-22 09:00:38,400 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-22 09:00:38,400 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-22 09:00:38,401 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 09:00:38,401 [INFO] Class allocation analysis:
2025-06-22 09:00:38,401 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 09:00:38,401 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 09:00:38,401 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 09:00:38,401 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 09:00:38,414 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 09:00:38,415 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 09:00:38,415 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 09:00:38,415 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 09:00:38,415 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 09:00:38,415 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 09:00:38,415 [INFO] Final allocation:
2025-06-22 09:00:38,415 [INFO]   Source domain: 280 samples
2025-06-22 09:00:38,415 [INFO]   Target domain: 320 samples
2025-06-22 09:00:38,416 [INFO] Target domain setup:
2025-06-22 09:00:38,417 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-22 09:00:38,417 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-22 09:00:38,417 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-22 09:00:38,417 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-22 09:00:38,417 [INFO]   Total data after allocation: 320
2025-06-22 09:00:38,417 [INFO]   Data split - Train: 256, Val: 64
2025-06-22 09:00:38,417 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-22 09:00:38,417 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-22 09:00:38,417 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-22 09:00:38,417 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-22 09:00:38,417 [INFO] 数据加载器创建完成!
2025-06-22 09:00:38,417 [INFO] 源域类别数: 4 (重叠类别)
2025-06-22 09:00:38,417 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-22 09:00:38,417 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-22 09:00:38,417 [INFO] 目标域新类别: [4, 5]
2025-06-22 09:00:38,417 [INFO] Data allocation verification:
2025-06-22 09:00:38,417 [INFO]   Source data samples: 280
2025-06-22 09:00:38,417 [INFO]   Target data samples: 320
2025-06-22 09:00:38,417 [INFO]   Overlapping samples: 0
2025-06-22 09:00:38,417 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-22 09:00:38,419 [INFO] Model initialized with 3684 parameters
2025-06-22 09:00:38,419 [INFO] Previous best validation accuracy read from record.txt: 0.6250
2025-06-22 09:00:38,419 [INFO] Starting training...
2025-06-22 09:00:38,433 [INFO] Epoch 001 | Train Loss: 9.2005 | Val Loss: 1.7969 | Val Acc: 0.3214
2025-06-22 09:00:39,149 [INFO] New best model at epoch 1 (Val Acc: 0.3214)
2025-06-22 09:00:39,165 [INFO] Epoch 002 | Train Loss: 7.7555 | Val Loss: 1.7288 | Val Acc: 0.3036
2025-06-22 09:00:39,180 [INFO] Epoch 003 | Train Loss: 6.4044 | Val Loss: 1.8241 | Val Acc: 0.3036
2025-06-22 09:00:39,194 [INFO] Epoch 004 | Train Loss: 7.8038 | Val Loss: 1.8313 | Val Acc: 0.2500
2025-06-22 09:00:39,214 [INFO] Epoch 005 | Train Loss: 6.7404 | Val Loss: 1.9173 | Val Acc: 0.2500
2025-06-22 09:00:39,230 [INFO] Epoch 006 | Train Loss: 5.5744 | Val Loss: 2.0830 | Val Acc: 0.2500
2025-06-22 09:00:39,246 [INFO] Epoch 007 | Train Loss: 5.7389 | Val Loss: 2.1079 | Val Acc: 0.2679
2025-06-22 09:00:39,260 [INFO] Epoch 008 | Train Loss: 6.2875 | Val Loss: 1.9677 | Val Acc: 0.3393
2025-06-22 09:00:39,262 [INFO] New best model at epoch 8 (Val Acc: 0.3393)
2025-06-22 09:00:39,274 [INFO] Epoch 009 | Train Loss: 4.9307 | Val Loss: 2.0135 | Val Acc: 0.3393
2025-06-22 09:00:39,288 [INFO] Epoch 010 | Train Loss: 5.5240 | Val Loss: 2.1080 | Val Acc: 0.3929
2025-06-22 09:00:40,045 [INFO] New best model at epoch 10 (Val Acc: 0.3929)
2025-06-22 09:00:40,060 [INFO] Epoch 011 | Train Loss: 5.7134 | Val Loss: 1.7925 | Val Acc: 0.3214
2025-06-22 09:00:40,075 [INFO] Epoch 012 | Train Loss: 3.7279 | Val Loss: 1.7373 | Val Acc: 0.3214
2025-06-22 09:00:40,089 [INFO] Epoch 013 | Train Loss: 5.3846 | Val Loss: 1.9184 | Val Acc: 0.3571
2025-06-22 09:00:40,107 [INFO] Epoch 014 | Train Loss: 4.8525 | Val Loss: 1.9826 | Val Acc: 0.2679
2025-06-22 09:00:40,123 [INFO] Epoch 015 | Train Loss: 3.7667 | Val Loss: 1.9615 | Val Acc: 0.2679
2025-06-22 09:00:40,138 [INFO] Epoch 016 | Train Loss: 4.4079 | Val Loss: 1.9939 | Val Acc: 0.2143
2025-06-22 09:00:40,151 [INFO] Epoch 017 | Train Loss: 3.9180 | Val Loss: 1.9935 | Val Acc: 0.2321
2025-06-22 09:00:40,165 [INFO] Epoch 018 | Train Loss: 2.3983 | Val Loss: 1.7973 | Val Acc: 0.2679
2025-06-22 09:00:40,179 [INFO] Epoch 019 | Train Loss: 4.0940 | Val Loss: 1.6499 | Val Acc: 0.3214
2025-06-22 09:00:40,192 [INFO] Epoch 020 | Train Loss: 3.6408 | Val Loss: 1.5659 | Val Acc: 0.3214
2025-06-22 09:00:41,195 [INFO] Epoch 021 | Train Loss: 3.4646 | Val Loss: 1.4518 | Val Acc: 0.3393
2025-06-22 09:00:41,211 [INFO] Epoch 022 | Train Loss: 2.9659 | Val Loss: 1.4145 | Val Acc: 0.2857
2025-06-22 09:00:41,231 [INFO] Epoch 023 | Train Loss: 3.8663 | Val Loss: 1.3762 | Val Acc: 0.3214
2025-06-22 09:00:41,256 [INFO] Epoch 024 | Train Loss: 2.2950 | Val Loss: 1.3580 | Val Acc: 0.3393
2025-06-22 09:00:41,280 [INFO] Epoch 025 | Train Loss: 3.3462 | Val Loss: 1.3537 | Val Acc: 0.3214
2025-06-22 09:00:41,298 [INFO] Epoch 026 | Train Loss: 2.1150 | Val Loss: 1.4542 | Val Acc: 0.2857
2025-06-22 09:00:41,316 [INFO] Epoch 027 | Train Loss: 3.3561 | Val Loss: 1.4916 | Val Acc: 0.2679
2025-06-22 09:00:41,330 [INFO] Epoch 028 | Train Loss: 2.2678 | Val Loss: 1.4858 | Val Acc: 0.2679
2025-06-22 09:00:41,364 [INFO] Epoch 029 | Train Loss: 2.5791 | Val Loss: 1.5010 | Val Acc: 0.2679
2025-06-22 09:00:41,378 [INFO] Epoch 030 | Train Loss: 3.4577 | Val Loss: 1.6217 | Val Acc: 0.2500
2025-06-22 09:00:42,433 [INFO] Epoch 031 | Train Loss: 2.1578 | Val Loss: 1.5369 | Val Acc: 0.2679
2025-06-22 09:00:42,450 [INFO] Epoch 032 | Train Loss: 3.1271 | Val Loss: 1.5128 | Val Acc: 0.2500
2025-06-22 09:00:42,492 [INFO] Epoch 033 | Train Loss: 2.9566 | Val Loss: 1.4640 | Val Acc: 0.2679
2025-06-22 09:00:42,508 [INFO] Epoch 034 | Train Loss: 1.9700 | Val Loss: 1.4244 | Val Acc: 0.2857
2025-06-22 09:00:42,524 [INFO] Epoch 035 | Train Loss: 2.8020 | Val Loss: 1.4245 | Val Acc: 0.2500
2025-06-22 09:00:42,538 [INFO] Epoch 036 | Train Loss: 2.9415 | Val Loss: 1.4222 | Val Acc: 0.2857
2025-06-22 09:00:42,552 [INFO] Epoch 037 | Train Loss: 2.7267 | Val Loss: 1.3932 | Val Acc: 0.2500
2025-06-22 09:00:42,565 [INFO] Epoch 038 | Train Loss: 2.0936 | Val Loss: 1.3769 | Val Acc: 0.2679
2025-06-22 09:00:42,579 [INFO] Epoch 039 | Train Loss: 2.8938 | Val Loss: 1.3807 | Val Acc: 0.2500
2025-06-22 09:00:42,592 [INFO] Epoch 040 | Train Loss: 2.1277 | Val Loss: 1.3295 | Val Acc: 0.2500
2025-06-22 09:00:43,328 [INFO] Epoch 041 | Train Loss: 1.8409 | Val Loss: 1.3357 | Val Acc: 0.2857
2025-06-22 09:00:43,341 [INFO] Epoch 042 | Train Loss: 2.4400 | Val Loss: 1.4021 | Val Acc: 0.2857
2025-06-22 09:00:43,379 [INFO] Epoch 043 | Train Loss: 2.9054 | Val Loss: 1.6375 | Val Acc: 0.2679
2025-06-22 09:00:43,396 [INFO] Epoch 044 | Train Loss: 2.7546 | Val Loss: 1.7471 | Val Acc: 0.2500
2025-06-22 09:00:43,411 [INFO] Epoch 045 | Train Loss: 2.0221 | Val Loss: 1.6372 | Val Acc: 0.2321
2025-06-22 09:00:43,428 [INFO] Epoch 046 | Train Loss: 1.9074 | Val Loss: 1.5669 | Val Acc: 0.2143
2025-06-22 09:00:43,441 [INFO] Epoch 047 | Train Loss: 2.1470 | Val Loss: 1.6163 | Val Acc: 0.2143
2025-06-22 09:00:43,455 [INFO] Epoch 048 | Train Loss: 2.3940 | Val Loss: 1.6370 | Val Acc: 0.2500
2025-06-22 09:00:43,468 [INFO] Epoch 049 | Train Loss: 2.5064 | Val Loss: 1.6084 | Val Acc: 0.2857
2025-06-22 09:00:43,482 [INFO] Epoch 050 | Train Loss: 2.4071 | Val Loss: 1.6771 | Val Acc: 0.2500
2025-06-22 09:00:44,349 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.3929 at epoch 10)
2025-06-22 09:00:44,350 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.001/train_metrics.csv
2025-06-22 09:00:45,083 [INFO] Final training curves saved
2025-06-22 09:00:45,083 [INFO] Training completed!
2025-06-22 09:00:45,083 [INFO] Best validation accuracy: 0.3929
2025-06-22 09:00:45,083 [INFO] Best epoch: 10
2025-06-22 09:00:45,083 [INFO] Total epochs trained: 50
2025-06-22 09:00:45,083 [INFO] Starting training with parameters: (0.001, 0.5, 32, 2, 50, 0.0001)
