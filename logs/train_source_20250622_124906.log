2025-06-22 12:49:06,234 [INFO] Using device: cpu
2025-06-22 12:49:06,234 [INFO] 开始创建数据加载器...
2025-06-22 12:49:06,237 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 12:49:06,237 [INFO] Class allocation analysis:
2025-06-22 12:49:06,237 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 12:49:06,237 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 12:49:06,237 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 12:49:06,237 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 12:49:06,251 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 12:49:06,251 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 12:49:06,251 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 12:49:06,251 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 12:49:06,251 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 12:49:06,251 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 12:49:06,251 [INFO] Final allocation:
2025-06-22 12:49:06,251 [INFO]   Source domain: 280 samples
2025-06-22 12:49:06,251 [INFO]   Target domain: 320 samples
2025-06-22 12:49:06,253 [INFO] Source domain setup:
2025-06-22 12:49:06,253 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-22 12:49:06,253 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-22 12:49:06,253 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-22 12:49:06,253 [INFO]   Total data after allocation: 280
2025-06-22 12:49:06,253 [INFO]   Data split - Train: 224, Val: 56
2025-06-22 12:49:06,253 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-22 12:49:06,253 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-22 12:49:06,254 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 12:49:06,254 [INFO] Class allocation analysis:
2025-06-22 12:49:06,254 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 12:49:06,254 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 12:49:06,254 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 12:49:06,254 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 12:49:06,267 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 12:49:06,267 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 12:49:06,267 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 12:49:06,268 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 12:49:06,268 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 12:49:06,268 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 12:49:06,268 [INFO] Final allocation:
2025-06-22 12:49:06,268 [INFO]   Source domain: 280 samples
2025-06-22 12:49:06,268 [INFO]   Target domain: 320 samples
2025-06-22 12:49:06,269 [INFO] Target domain setup:
2025-06-22 12:49:06,269 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-22 12:49:06,269 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-22 12:49:06,269 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-22 12:49:06,269 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-22 12:49:06,269 [INFO]   Total data after allocation: 320
2025-06-22 12:49:06,269 [INFO]   Data split - Train: 256, Val: 64
2025-06-22 12:49:06,269 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-22 12:49:06,269 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-22 12:49:06,269 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-22 12:49:06,269 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-22 12:49:06,270 [INFO] 数据加载器创建完成!
2025-06-22 12:49:06,270 [INFO] 源域类别数: 4 (重叠类别)
2025-06-22 12:49:06,270 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-22 12:49:06,270 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-22 12:49:06,270 [INFO] 目标域新类别: [4, 5]
2025-06-22 12:49:06,270 [INFO] Data allocation verification:
2025-06-22 12:49:06,270 [INFO]   Source data samples: 280
2025-06-22 12:49:06,270 [INFO]   Target data samples: 320
2025-06-22 12:49:06,270 [INFO]   Overlapping samples: 0
2025-06-22 12:49:06,270 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-22 12:49:06,271 [INFO] Model initialized with 18052 parameters
2025-06-22 12:49:06,271 [INFO] Previous best validation accuracy read from record.txt: 0.6250
2025-06-22 12:49:06,271 [INFO] Starting training...
2025-06-22 12:49:06,286 [INFO] Epoch 001 | Train Loss: 10.5213 | Val Loss: 8.6784 | Val Acc: 0.3929
2025-06-22 12:49:07,141 [INFO] New best model at epoch 1 (Val Acc: 0.3929)
2025-06-22 12:49:07,154 [INFO] Epoch 002 | Train Loss: 3.9691 | Val Loss: 5.1912 | Val Acc: 0.2143
2025-06-22 12:49:07,165 [INFO] Epoch 003 | Train Loss: 2.5178 | Val Loss: 5.4940 | Val Acc: 0.3214
2025-06-22 12:49:07,177 [INFO] Epoch 004 | Train Loss: 2.4100 | Val Loss: 3.3824 | Val Acc: 0.2857
2025-06-22 12:49:07,190 [INFO] Epoch 005 | Train Loss: 2.6409 | Val Loss: 2.2121 | Val Acc: 0.3571
2025-06-22 12:49:07,203 [INFO] Epoch 006 | Train Loss: 2.1727 | Val Loss: 1.6126 | Val Acc: 0.4107
2025-06-22 12:49:07,205 [INFO] New best model at epoch 6 (Val Acc: 0.4107)
2025-06-22 12:49:07,216 [INFO] Epoch 007 | Train Loss: 2.1844 | Val Loss: 2.7559 | Val Acc: 0.2857
2025-06-22 12:49:07,231 [INFO] Epoch 008 | Train Loss: 2.1979 | Val Loss: 3.5755 | Val Acc: 0.3214
2025-06-22 12:49:07,245 [INFO] Epoch 009 | Train Loss: 2.5178 | Val Loss: 2.9052 | Val Acc: 0.2500
2025-06-22 12:49:07,257 [INFO] Epoch 010 | Train Loss: 2.3911 | Val Loss: 3.1145 | Val Acc: 0.2321
2025-06-22 12:49:08,702 [INFO] Epoch 011 | Train Loss: 2.4015 | Val Loss: 2.3057 | Val Acc: 0.2857
2025-06-22 12:49:08,714 [INFO] Epoch 012 | Train Loss: 1.9468 | Val Loss: 2.9944 | Val Acc: 0.3214
2025-06-22 12:49:08,727 [INFO] Epoch 013 | Train Loss: 2.6663 | Val Loss: 2.8865 | Val Acc: 0.3750
2025-06-22 12:49:08,739 [INFO] Epoch 014 | Train Loss: 2.4801 | Val Loss: 2.1683 | Val Acc: 0.2857
2025-06-22 12:49:08,752 [INFO] Epoch 015 | Train Loss: 2.7257 | Val Loss: 2.5037 | Val Acc: 0.3929
2025-06-22 12:49:08,765 [INFO] Epoch 016 | Train Loss: 2.3361 | Val Loss: 3.1731 | Val Acc: 0.2143
2025-06-22 12:49:08,777 [INFO] Epoch 017 | Train Loss: 2.1237 | Val Loss: 2.4307 | Val Acc: 0.3036
2025-06-22 12:49:08,791 [INFO] Epoch 018 | Train Loss: 2.3805 | Val Loss: 2.1130 | Val Acc: 0.4107
2025-06-22 12:49:08,804 [INFO] Epoch 019 | Train Loss: 2.1220 | Val Loss: 2.2553 | Val Acc: 0.3929
2025-06-22 12:49:08,814 [INFO] Epoch 020 | Train Loss: 2.0611 | Val Loss: 1.6549 | Val Acc: 0.3750
2025-06-22 12:49:09,658 [INFO] Epoch 021 | Train Loss: 1.9519 | Val Loss: 2.6306 | Val Acc: 0.2679
2025-06-22 12:49:09,669 [INFO] Epoch 022 | Train Loss: 2.1443 | Val Loss: 2.0311 | Val Acc: 0.3393
2025-06-22 12:49:09,683 [INFO] Epoch 023 | Train Loss: 2.0052 | Val Loss: 2.9524 | Val Acc: 0.2321
2025-06-22 12:49:09,696 [INFO] Epoch 024 | Train Loss: 2.2979 | Val Loss: 3.7850 | Val Acc: 0.2679
2025-06-22 12:49:09,708 [INFO] Epoch 025 | Train Loss: 2.3478 | Val Loss: 2.1044 | Val Acc: 0.3929
2025-06-22 12:49:09,723 [INFO] Epoch 026 | Train Loss: 2.2407 | Val Loss: 2.2499 | Val Acc: 0.3929
2025-06-22 12:49:09,735 [INFO] Epoch 027 | Train Loss: 2.1450 | Val Loss: 2.4231 | Val Acc: 0.2679
2025-06-22 12:49:09,748 [INFO] Epoch 028 | Train Loss: 1.9127 | Val Loss: 3.0444 | Val Acc: 0.3929
2025-06-22 12:49:09,761 [INFO] Epoch 029 | Train Loss: 1.7633 | Val Loss: 2.0138 | Val Acc: 0.2857
2025-06-22 12:49:09,772 [INFO] Epoch 030 | Train Loss: 1.5086 | Val Loss: 1.8218 | Val Acc: 0.3393
2025-06-22 12:49:10,743 [INFO] Epoch 031 | Train Loss: 1.5223 | Val Loss: 1.8550 | Val Acc: 0.2857
2025-06-22 12:49:10,754 [INFO] Epoch 032 | Train Loss: 1.5243 | Val Loss: 2.5373 | Val Acc: 0.3036
2025-06-22 12:49:10,767 [INFO] Epoch 033 | Train Loss: 1.6997 | Val Loss: 1.6551 | Val Acc: 0.4107
2025-06-22 12:49:10,781 [INFO] Epoch 034 | Train Loss: 1.6147 | Val Loss: 2.1694 | Val Acc: 0.3214
2025-06-22 12:49:10,795 [INFO] Epoch 035 | Train Loss: 1.5775 | Val Loss: 1.9762 | Val Acc: 0.3214
2025-06-22 12:49:10,808 [INFO] Epoch 036 | Train Loss: 1.5469 | Val Loss: 1.6695 | Val Acc: 0.3036
2025-06-22 12:49:10,821 [INFO] Epoch 037 | Train Loss: 1.4927 | Val Loss: 2.0500 | Val Acc: 0.2500
2025-06-22 12:49:10,838 [INFO] Epoch 038 | Train Loss: 1.4465 | Val Loss: 1.4676 | Val Acc: 0.3571
2025-06-22 12:49:10,848 [INFO] Epoch 039 | Train Loss: 1.3088 | Val Loss: 1.5329 | Val Acc: 0.3929
2025-06-22 12:49:10,859 [INFO] Epoch 040 | Train Loss: 1.2936 | Val Loss: 1.5105 | Val Acc: 0.4643
2025-06-22 12:49:11,706 [INFO] New best model at epoch 40 (Val Acc: 0.4643)
2025-06-22 12:49:11,718 [INFO] Epoch 041 | Train Loss: 1.4996 | Val Loss: 1.9271 | Val Acc: 0.2679
2025-06-22 12:49:11,729 [INFO] Epoch 042 | Train Loss: 1.3759 | Val Loss: 2.5245 | Val Acc: 0.2679
2025-06-22 12:49:11,741 [INFO] Epoch 043 | Train Loss: 2.0632 | Val Loss: 1.7646 | Val Acc: 0.3036
2025-06-22 12:49:11,757 [INFO] Epoch 044 | Train Loss: 1.7330 | Val Loss: 2.5839 | Val Acc: 0.3393
2025-06-22 12:49:11,770 [INFO] Epoch 045 | Train Loss: 1.5866 | Val Loss: 1.9379 | Val Acc: 0.4107
2025-06-22 12:49:11,783 [INFO] Epoch 046 | Train Loss: 1.5770 | Val Loss: 2.7068 | Val Acc: 0.2857
2025-06-22 12:49:11,799 [INFO] Epoch 047 | Train Loss: 1.5400 | Val Loss: 1.9264 | Val Acc: 0.3036
2025-06-22 12:49:11,816 [INFO] Epoch 048 | Train Loss: 1.5543 | Val Loss: 2.1987 | Val Acc: 0.3929
2025-06-22 12:49:11,826 [INFO] Epoch 049 | Train Loss: 1.6505 | Val Loss: 1.5182 | Val Acc: 0.3929
2025-06-22 12:49:11,836 [INFO] Epoch 050 | Train Loss: 1.4462 | Val Loss: 1.9324 | Val Acc: 0.3571
2025-06-22 12:49:12,693 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.4643 at epoch 40)
2025-06-22 12:49:12,693 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.01/train_metrics.csv
2025-06-22 12:49:13,555 [INFO] Final training curves saved
2025-06-22 12:49:13,555 [INFO] Training completed!
2025-06-22 12:49:13,555 [INFO] Best validation accuracy: 0.4643
2025-06-22 12:49:13,555 [INFO] Best epoch: 40
2025-06-22 12:49:13,555 [INFO] Total epochs trained: 50
2025-06-22 12:49:13,556 [INFO] Starting training with parameters: (0.01, 0.0, 128, 1, 50, 0.001)
