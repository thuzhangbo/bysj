2025-06-22 11:44:40,742 [INFO] Using device: cpu
2025-06-22 11:44:40,742 [INFO] 开始创建数据加载器...
2025-06-22 11:44:40,745 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 11:44:40,745 [INFO] Class allocation analysis:
2025-06-22 11:44:40,745 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 11:44:40,745 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 11:44:40,745 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 11:44:40,745 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 11:44:40,885 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 11:44:40,885 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 11:44:40,885 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 11:44:40,885 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 11:44:40,885 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 11:44:40,885 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 11:44:40,885 [INFO] Final allocation:
2025-06-22 11:44:40,885 [INFO]   Source domain: 280 samples
2025-06-22 11:44:40,886 [INFO]   Target domain: 320 samples
2025-06-22 11:44:40,887 [INFO] Source domain setup:
2025-06-22 11:44:40,887 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-22 11:44:40,887 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-22 11:44:40,887 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-22 11:44:40,887 [INFO]   Total data after allocation: 280
2025-06-22 11:44:40,887 [INFO]   Data split - Train: 224, Val: 56
2025-06-22 11:44:40,887 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-22 11:44:40,887 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-22 11:44:40,888 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 11:44:40,888 [INFO] Class allocation analysis:
2025-06-22 11:44:40,888 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 11:44:40,888 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 11:44:40,888 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 11:44:40,888 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 11:44:40,901 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 11:44:40,901 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 11:44:40,901 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 11:44:40,901 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 11:44:40,901 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 11:44:40,901 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 11:44:40,901 [INFO] Final allocation:
2025-06-22 11:44:40,901 [INFO]   Source domain: 280 samples
2025-06-22 11:44:40,902 [INFO]   Target domain: 320 samples
2025-06-22 11:44:40,903 [INFO] Target domain setup:
2025-06-22 11:44:40,903 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-22 11:44:40,903 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-22 11:44:40,903 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-22 11:44:40,903 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-22 11:44:40,903 [INFO]   Total data after allocation: 320
2025-06-22 11:44:40,903 [INFO]   Data split - Train: 256, Val: 64
2025-06-22 11:44:40,903 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-22 11:44:40,903 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-22 11:44:40,903 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-22 11:44:40,903 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-22 11:44:40,903 [INFO] 数据加载器创建完成!
2025-06-22 11:44:40,903 [INFO] 源域类别数: 4 (重叠类别)
2025-06-22 11:44:40,903 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-22 11:44:40,903 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-22 11:44:40,903 [INFO] 目标域新类别: [4, 5]
2025-06-22 11:44:40,904 [INFO] Data allocation verification:
2025-06-22 11:44:40,904 [INFO]   Source data samples: 280
2025-06-22 11:44:40,904 [INFO]   Target data samples: 320
2025-06-22 11:44:40,904 [INFO]   Overlapping samples: 0
2025-06-22 11:44:40,904 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-22 11:44:40,905 [INFO] Model initialized with 1444 parameters
2025-06-22 11:44:40,905 [INFO] Previous best validation accuracy read from record.txt: 0.6250
2025-06-22 11:44:40,905 [INFO] Starting training...
2025-06-22 11:44:40,923 [INFO] Epoch 001 | Train Loss: 6.0961 | Val Loss: 5.2307 | Val Acc: 0.3571
2025-06-22 11:44:41,816 [INFO] New best model at epoch 1 (Val Acc: 0.3571)
2025-06-22 11:44:41,829 [INFO] Epoch 002 | Train Loss: 2.9245 | Val Loss: 3.3774 | Val Acc: 0.3571
2025-06-22 11:44:41,839 [INFO] Epoch 003 | Train Loss: 2.0436 | Val Loss: 2.7133 | Val Acc: 0.2857
2025-06-22 11:44:41,848 [INFO] Epoch 004 | Train Loss: 1.8657 | Val Loss: 1.5098 | Val Acc: 0.4107
2025-06-22 11:44:41,850 [INFO] New best model at epoch 4 (Val Acc: 0.4107)
2025-06-22 11:44:41,858 [INFO] Epoch 005 | Train Loss: 1.4869 | Val Loss: 2.1127 | Val Acc: 0.3036
2025-06-22 11:44:41,867 [INFO] Epoch 006 | Train Loss: 1.4607 | Val Loss: 2.1855 | Val Acc: 0.2321
2025-06-22 11:44:41,875 [INFO] Epoch 007 | Train Loss: 1.4277 | Val Loss: 1.7474 | Val Acc: 0.1786
2025-06-22 11:44:41,885 [INFO] Epoch 008 | Train Loss: 1.3232 | Val Loss: 1.7677 | Val Acc: 0.2679
2025-06-22 11:44:41,893 [INFO] Epoch 009 | Train Loss: 1.2912 | Val Loss: 1.4411 | Val Acc: 0.3750
2025-06-22 11:44:41,903 [INFO] Epoch 010 | Train Loss: 1.3597 | Val Loss: 1.4583 | Val Acc: 0.3393
2025-06-22 11:44:42,807 [INFO] Epoch 011 | Train Loss: 1.3378 | Val Loss: 1.7199 | Val Acc: 0.2679
2025-06-22 11:44:42,816 [INFO] Epoch 012 | Train Loss: 1.2658 | Val Loss: 1.4879 | Val Acc: 0.3750
2025-06-22 11:44:42,824 [INFO] Epoch 013 | Train Loss: 1.3309 | Val Loss: 1.7460 | Val Acc: 0.3571
2025-06-22 11:44:42,833 [INFO] Epoch 014 | Train Loss: 1.6218 | Val Loss: 1.8845 | Val Acc: 0.1786
2025-06-22 11:44:42,842 [INFO] Epoch 015 | Train Loss: 1.7285 | Val Loss: 2.2108 | Val Acc: 0.3571
2025-06-22 11:44:42,851 [INFO] Epoch 016 | Train Loss: 1.7996 | Val Loss: 2.8326 | Val Acc: 0.2143
2025-06-22 11:44:42,863 [INFO] Epoch 017 | Train Loss: 1.6328 | Val Loss: 1.6749 | Val Acc: 0.3214
2025-06-22 11:44:42,872 [INFO] Epoch 018 | Train Loss: 1.5813 | Val Loss: 2.1904 | Val Acc: 0.3571
2025-06-22 11:44:42,880 [INFO] Epoch 019 | Train Loss: 1.7029 | Val Loss: 1.9284 | Val Acc: 0.3393
2025-06-22 11:44:42,889 [INFO] Epoch 020 | Train Loss: 1.6046 | Val Loss: 1.6557 | Val Acc: 0.3571
2025-06-22 11:44:43,713 [INFO] Epoch 021 | Train Loss: 1.3496 | Val Loss: 1.5264 | Val Acc: 0.2679
2025-06-22 11:44:43,723 [INFO] Epoch 022 | Train Loss: 1.3319 | Val Loss: 1.6276 | Val Acc: 0.2679
2025-06-22 11:44:43,732 [INFO] Epoch 023 | Train Loss: 1.2676 | Val Loss: 1.5909 | Val Acc: 0.3214
2025-06-22 11:44:43,742 [INFO] Epoch 024 | Train Loss: 1.2271 | Val Loss: 1.5585 | Val Acc: 0.3571
2025-06-22 11:44:43,752 [INFO] Epoch 025 | Train Loss: 1.2594 | Val Loss: 1.4196 | Val Acc: 0.3750
2025-06-22 11:44:43,764 [INFO] Epoch 026 | Train Loss: 1.1881 | Val Loss: 1.4202 | Val Acc: 0.4107
2025-06-22 11:44:43,776 [INFO] Epoch 027 | Train Loss: 1.2479 | Val Loss: 1.6996 | Val Acc: 0.3393
2025-06-22 11:44:43,789 [INFO] Epoch 028 | Train Loss: 1.3287 | Val Loss: 1.4254 | Val Acc: 0.3750
2025-06-22 11:44:43,801 [INFO] Epoch 029 | Train Loss: 1.2589 | Val Loss: 1.8041 | Val Acc: 0.2857
2025-06-22 11:44:43,810 [INFO] Epoch 030 | Train Loss: 1.2509 | Val Loss: 1.5873 | Val Acc: 0.3214
2025-06-22 11:44:44,635 [INFO] Epoch 031 | Train Loss: 1.2744 | Val Loss: 1.6607 | Val Acc: 0.3036
2025-06-22 11:44:44,643 [INFO] Epoch 032 | Train Loss: 1.3342 | Val Loss: 1.4737 | Val Acc: 0.4107
2025-06-22 11:44:44,652 [INFO] Epoch 033 | Train Loss: 1.2616 | Val Loss: 1.4304 | Val Acc: 0.3750
2025-06-22 11:44:44,660 [INFO] Epoch 034 | Train Loss: 1.2098 | Val Loss: 1.9105 | Val Acc: 0.3214
2025-06-22 11:44:44,669 [INFO] Epoch 035 | Train Loss: 1.3622 | Val Loss: 1.4860 | Val Acc: 0.3929
2025-06-22 11:44:44,679 [INFO] Epoch 036 | Train Loss: 1.2789 | Val Loss: 1.6150 | Val Acc: 0.2679
2025-06-22 11:44:44,690 [INFO] Epoch 037 | Train Loss: 1.2956 | Val Loss: 1.6391 | Val Acc: 0.3929
2025-06-22 11:44:44,699 [INFO] Epoch 038 | Train Loss: 1.2671 | Val Loss: 1.8178 | Val Acc: 0.3214
2025-06-22 11:44:44,708 [INFO] Epoch 039 | Train Loss: 1.2620 | Val Loss: 1.4066 | Val Acc: 0.3750
2025-06-22 11:44:44,727 [INFO] Epoch 040 | Train Loss: 1.2260 | Val Loss: 1.4394 | Val Acc: 0.3750
2025-06-22 11:44:46,004 [INFO] Epoch 041 | Train Loss: 1.1374 | Val Loss: 1.6210 | Val Acc: 0.3393
2025-06-22 11:44:46,015 [INFO] Epoch 042 | Train Loss: 1.2115 | Val Loss: 1.5632 | Val Acc: 0.2857
2025-06-22 11:44:46,025 [INFO] Epoch 043 | Train Loss: 1.1922 | Val Loss: 1.4001 | Val Acc: 0.4107
2025-06-22 11:44:46,038 [INFO] Epoch 044 | Train Loss: 1.1686 | Val Loss: 1.5217 | Val Acc: 0.2857
2025-06-22 11:44:46,050 [INFO] Epoch 045 | Train Loss: 1.2039 | Val Loss: 1.3546 | Val Acc: 0.4464
2025-06-22 11:44:46,052 [INFO] New best model at epoch 45 (Val Acc: 0.4464)
2025-06-22 11:44:46,061 [INFO] Epoch 046 | Train Loss: 1.1881 | Val Loss: 1.4596 | Val Acc: 0.3214
2025-06-22 11:44:46,077 [INFO] Epoch 047 | Train Loss: 1.1450 | Val Loss: 1.4826 | Val Acc: 0.3393
2025-06-22 11:44:46,088 [INFO] Epoch 048 | Train Loss: 1.2196 | Val Loss: 1.5187 | Val Acc: 0.3750
2025-06-22 11:44:46,099 [INFO] Epoch 049 | Train Loss: 1.1599 | Val Loss: 1.5872 | Val Acc: 0.4107
2025-06-22 11:44:46,111 [INFO] Epoch 050 | Train Loss: 1.1943 | Val Loss: 1.5939 | Val Acc: 0.3036
2025-06-22 11:44:48,956 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.4464 at epoch 45)
2025-06-22 11:44:48,957 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.01/train_metrics.csv
2025-06-22 11:44:50,059 [INFO] Final training curves saved
2025-06-22 11:44:50,059 [INFO] Training completed!
2025-06-22 11:44:50,059 [INFO] Best validation accuracy: 0.4464
2025-06-22 11:44:50,059 [INFO] Best epoch: 45
2025-06-22 11:44:50,059 [INFO] Total epochs trained: 50
2025-06-22 11:44:50,060 [INFO] Starting training with parameters: (0.01, 0.0, 32, 1, 50, 0.001)
