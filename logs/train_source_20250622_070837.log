2025-06-22 07:08:37,103 [INFO] Using device: cpu
2025-06-22 07:08:37,103 [INFO] 开始创建数据加载器...
2025-06-22 07:08:37,104 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 07:08:37,105 [INFO] Class allocation analysis:
2025-06-22 07:08:37,105 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 07:08:37,105 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 07:08:37,105 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 07:08:37,105 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 07:08:37,118 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 07:08:37,118 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 07:08:37,118 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 07:08:37,119 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 07:08:37,119 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 07:08:37,119 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 07:08:37,119 [INFO] Final allocation:
2025-06-22 07:08:37,119 [INFO]   Source domain: 280 samples
2025-06-22 07:08:37,119 [INFO]   Target domain: 320 samples
2025-06-22 07:08:37,120 [INFO] Source domain setup:
2025-06-22 07:08:37,120 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-22 07:08:37,120 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-22 07:08:37,120 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-22 07:08:37,120 [INFO]   Total data after allocation: 280
2025-06-22 07:08:37,120 [INFO]   Data split - Train: 224, Val: 56
2025-06-22 07:08:37,120 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-22 07:08:37,120 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-22 07:08:37,121 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 07:08:37,121 [INFO] Class allocation analysis:
2025-06-22 07:08:37,121 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 07:08:37,121 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 07:08:37,121 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 07:08:37,121 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 07:08:37,134 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 07:08:37,135 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 07:08:37,135 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 07:08:37,135 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 07:08:37,135 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 07:08:37,135 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 07:08:37,135 [INFO] Final allocation:
2025-06-22 07:08:37,135 [INFO]   Source domain: 280 samples
2025-06-22 07:08:37,135 [INFO]   Target domain: 320 samples
2025-06-22 07:08:37,137 [INFO] Target domain setup:
2025-06-22 07:08:37,137 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-22 07:08:37,137 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-22 07:08:37,137 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-22 07:08:37,137 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-22 07:08:37,137 [INFO]   Total data after allocation: 320
2025-06-22 07:08:37,137 [INFO]   Data split - Train: 256, Val: 64
2025-06-22 07:08:37,137 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-22 07:08:37,137 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-22 07:08:37,137 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-22 07:08:37,137 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-22 07:08:37,137 [INFO] 数据加载器创建完成!
2025-06-22 07:08:37,137 [INFO] 源域类别数: 4 (重叠类别)
2025-06-22 07:08:37,137 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-22 07:08:37,137 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-22 07:08:37,137 [INFO] 目标域新类别: [4, 5]
2025-06-22 07:08:37,137 [INFO] Data allocation verification:
2025-06-22 07:08:37,137 [INFO]   Source data samples: 280
2025-06-22 07:08:37,137 [INFO]   Target data samples: 320
2025-06-22 07:08:37,137 [INFO]   Overlapping samples: 0
2025-06-22 07:08:37,137 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-22 07:08:37,138 [INFO] Model initialized with 18052 parameters
2025-06-22 07:08:37,138 [INFO] Previous best validation accuracy read from record.txt: 0.6250
2025-06-22 07:08:37,138 [INFO] Starting training...
2025-06-22 07:08:37,152 [INFO] Epoch 001 | Train Loss: 11.4215 | Val Loss: 4.2487 | Val Acc: 0.3393
2025-06-22 07:08:39,525 [INFO] New best model at epoch 1 (Val Acc: 0.3393)
2025-06-22 07:08:39,545 [INFO] Epoch 002 | Train Loss: 6.9424 | Val Loss: 2.6143 | Val Acc: 0.3393
2025-06-22 07:08:39,563 [INFO] Epoch 003 | Train Loss: 7.4810 | Val Loss: 2.3960 | Val Acc: 0.2857
2025-06-22 07:08:39,578 [INFO] Epoch 004 | Train Loss: 6.6887 | Val Loss: 2.2046 | Val Acc: 0.4464
2025-06-22 07:08:39,580 [INFO] New best model at epoch 4 (Val Acc: 0.4464)
2025-06-22 07:08:39,593 [INFO] Epoch 005 | Train Loss: 5.8578 | Val Loss: 2.3061 | Val Acc: 0.3571
2025-06-22 07:08:39,620 [INFO] Epoch 006 | Train Loss: 5.2726 | Val Loss: 2.7204 | Val Acc: 0.3036
2025-06-22 07:08:39,655 [INFO] Epoch 007 | Train Loss: 6.0012 | Val Loss: 3.3611 | Val Acc: 0.3393
2025-06-22 07:08:39,667 [INFO] Epoch 008 | Train Loss: 5.7693 | Val Loss: 2.7027 | Val Acc: 0.4107
2025-06-22 07:08:39,678 [INFO] Epoch 009 | Train Loss: 5.3255 | Val Loss: 2.3055 | Val Acc: 0.3929
2025-06-22 07:08:39,689 [INFO] Epoch 010 | Train Loss: 5.1174 | Val Loss: 2.6463 | Val Acc: 0.3393
2025-06-22 07:08:40,642 [INFO] Epoch 011 | Train Loss: 5.2133 | Val Loss: 2.6030 | Val Acc: 0.3929
2025-06-22 07:08:40,655 [INFO] Epoch 012 | Train Loss: 4.7324 | Val Loss: 2.4216 | Val Acc: 0.3214
2025-06-22 07:08:40,671 [INFO] Epoch 013 | Train Loss: 5.3638 | Val Loss: 3.0718 | Val Acc: 0.3571
2025-06-22 07:08:40,685 [INFO] Epoch 014 | Train Loss: 5.3297 | Val Loss: 3.5189 | Val Acc: 0.3571
2025-06-22 07:08:40,700 [INFO] Epoch 015 | Train Loss: 4.1334 | Val Loss: 2.1689 | Val Acc: 0.3750
2025-06-22 07:08:40,719 [INFO] Epoch 016 | Train Loss: 4.5954 | Val Loss: 2.2939 | Val Acc: 0.3750
2025-06-22 07:08:40,734 [INFO] Epoch 017 | Train Loss: 4.2557 | Val Loss: 2.2914 | Val Acc: 0.4286
2025-06-22 07:08:40,749 [INFO] Epoch 018 | Train Loss: 3.4781 | Val Loss: 2.3774 | Val Acc: 0.3929
2025-06-22 07:08:40,759 [INFO] Epoch 019 | Train Loss: 3.3398 | Val Loss: 2.1578 | Val Acc: 0.4107
2025-06-22 07:08:40,771 [INFO] Epoch 020 | Train Loss: 3.2515 | Val Loss: 2.2990 | Val Acc: 0.3393
2025-06-22 07:08:42,657 [INFO] Epoch 021 | Train Loss: 3.7905 | Val Loss: 2.5182 | Val Acc: 0.3393
2025-06-22 07:08:42,674 [INFO] Epoch 022 | Train Loss: 3.4237 | Val Loss: 2.4707 | Val Acc: 0.3214
2025-06-22 07:08:42,687 [INFO] Epoch 023 | Train Loss: 3.3958 | Val Loss: 2.3506 | Val Acc: 0.3036
2025-06-22 07:08:42,729 [INFO] Epoch 024 | Train Loss: 3.8570 | Val Loss: 2.2207 | Val Acc: 0.3571
2025-06-22 07:08:42,746 [INFO] Epoch 025 | Train Loss: 3.2075 | Val Loss: 2.2748 | Val Acc: 0.3929
2025-06-22 07:08:42,760 [INFO] Epoch 026 | Train Loss: 3.3524 | Val Loss: 2.3884 | Val Acc: 0.3393
2025-06-22 07:08:42,771 [INFO] Epoch 027 | Train Loss: 2.9357 | Val Loss: 2.1326 | Val Acc: 0.3571
2025-06-22 07:08:42,782 [INFO] Epoch 028 | Train Loss: 2.9426 | Val Loss: 1.9431 | Val Acc: 0.4107
2025-06-22 07:08:42,793 [INFO] Epoch 029 | Train Loss: 3.2464 | Val Loss: 1.9529 | Val Acc: 0.3571
2025-06-22 07:08:42,803 [INFO] Epoch 030 | Train Loss: 2.6074 | Val Loss: 1.7568 | Val Acc: 0.3750
2025-06-22 07:08:43,535 [INFO] Epoch 031 | Train Loss: 2.6880 | Val Loss: 1.7146 | Val Acc: 0.3571
2025-06-22 07:08:43,547 [INFO] Epoch 032 | Train Loss: 2.7397 | Val Loss: 1.5546 | Val Acc: 0.4464
2025-06-22 07:08:43,558 [INFO] Epoch 033 | Train Loss: 2.7728 | Val Loss: 1.9283 | Val Acc: 0.2857
2025-06-22 07:08:43,569 [INFO] Epoch 034 | Train Loss: 2.4852 | Val Loss: 1.9200 | Val Acc: 0.3750
2025-06-22 07:08:43,590 [INFO] Epoch 035 | Train Loss: 2.0906 | Val Loss: 2.0459 | Val Acc: 0.3214
2025-06-22 07:08:43,601 [INFO] Epoch 036 | Train Loss: 2.4258 | Val Loss: 1.7573 | Val Acc: 0.3929
2025-06-22 07:08:43,623 [INFO] Epoch 037 | Train Loss: 2.4823 | Val Loss: 1.7268 | Val Acc: 0.3571
2025-06-22 07:08:43,637 [INFO] Epoch 038 | Train Loss: 2.4722 | Val Loss: 1.7710 | Val Acc: 0.3393
2025-06-22 07:08:43,648 [INFO] Epoch 039 | Train Loss: 2.4074 | Val Loss: 1.5758 | Val Acc: 0.4107
2025-06-22 07:08:43,659 [INFO] Epoch 040 | Train Loss: 2.1645 | Val Loss: 1.7359 | Val Acc: 0.3393
2025-06-22 07:08:44,417 [INFO] Epoch 041 | Train Loss: 1.9056 | Val Loss: 1.7862 | Val Acc: 0.3571
2025-06-22 07:08:44,431 [INFO] Epoch 042 | Train Loss: 2.1785 | Val Loss: 1.7975 | Val Acc: 0.3571
2025-06-22 07:08:44,441 [INFO] Epoch 043 | Train Loss: 2.0509 | Val Loss: 1.6055 | Val Acc: 0.3929
2025-06-22 07:08:44,464 [INFO] Epoch 044 | Train Loss: 1.9135 | Val Loss: 1.6142 | Val Acc: 0.4107
2025-06-22 07:08:44,475 [INFO] Epoch 045 | Train Loss: 1.8262 | Val Loss: 1.4554 | Val Acc: 0.5000
2025-06-22 07:08:44,476 [INFO] New best model at epoch 45 (Val Acc: 0.5000)
2025-06-22 07:08:44,492 [INFO] Epoch 046 | Train Loss: 1.8868 | Val Loss: 1.5302 | Val Acc: 0.3214
2025-06-22 07:08:44,503 [INFO] Epoch 047 | Train Loss: 1.8903 | Val Loss: 1.4873 | Val Acc: 0.3750
2025-06-22 07:08:44,513 [INFO] Epoch 048 | Train Loss: 1.5950 | Val Loss: 1.4099 | Val Acc: 0.4464
2025-06-22 07:08:44,524 [INFO] Epoch 049 | Train Loss: 1.6503 | Val Loss: 1.4372 | Val Acc: 0.3929
2025-06-22 07:08:44,534 [INFO] Epoch 050 | Train Loss: 1.6399 | Val Loss: 1.4748 | Val Acc: 0.4107
2025-06-22 07:08:45,212 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.5000 at epoch 45)
2025-06-22 07:08:45,212 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.001/train_metrics.csv
2025-06-22 07:08:45,879 [INFO] Final training curves saved
2025-06-22 07:08:45,879 [INFO] Training completed!
2025-06-22 07:08:45,879 [INFO] Best validation accuracy: 0.5000
2025-06-22 07:08:45,879 [INFO] Best epoch: 45
2025-06-22 07:08:45,879 [INFO] Total epochs trained: 50
2025-06-22 07:08:45,880 [INFO] Starting training with parameters: (0.001, 0.4, 128, 1, 50, 0.001)
