2025-06-22 02:32:50,535 [INFO] Using device: cpu
2025-06-22 02:32:50,535 [INFO] 开始创建数据加载器...
2025-06-22 02:32:50,537 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 02:32:50,537 [INFO] Class allocation analysis:
2025-06-22 02:32:50,537 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 02:32:50,537 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 02:32:50,537 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 02:32:50,537 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 02:32:50,550 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 02:32:50,550 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 02:32:50,550 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 02:32:50,550 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 02:32:50,550 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 02:32:50,550 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 02:32:50,551 [INFO] Final allocation:
2025-06-22 02:32:50,551 [INFO]   Source domain: 280 samples
2025-06-22 02:32:50,551 [INFO]   Target domain: 320 samples
2025-06-22 02:32:50,552 [INFO] Source domain setup:
2025-06-22 02:32:50,552 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-22 02:32:50,552 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-22 02:32:50,552 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-22 02:32:50,552 [INFO]   Total data after allocation: 280
2025-06-22 02:32:50,552 [INFO]   Data split - Train: 224, Val: 56
2025-06-22 02:32:50,552 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-22 02:32:50,552 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-22 02:32:50,553 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 02:32:50,553 [INFO] Class allocation analysis:
2025-06-22 02:32:50,553 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 02:32:50,553 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 02:32:50,553 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 02:32:50,553 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 02:32:50,566 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 02:32:50,566 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 02:32:50,566 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 02:32:50,566 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 02:32:50,566 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 02:32:50,566 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 02:32:50,567 [INFO] Final allocation:
2025-06-22 02:32:50,567 [INFO]   Source domain: 280 samples
2025-06-22 02:32:50,567 [INFO]   Target domain: 320 samples
2025-06-22 02:32:50,568 [INFO] Target domain setup:
2025-06-22 02:32:50,568 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-22 02:32:50,568 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-22 02:32:50,568 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-22 02:32:50,568 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-22 02:32:50,568 [INFO]   Total data after allocation: 320
2025-06-22 02:32:50,568 [INFO]   Data split - Train: 256, Val: 64
2025-06-22 02:32:50,568 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-22 02:32:50,568 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-22 02:32:50,568 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-22 02:32:50,568 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-22 02:32:50,568 [INFO] 数据加载器创建完成!
2025-06-22 02:32:50,568 [INFO] 源域类别数: 4 (重叠类别)
2025-06-22 02:32:50,568 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-22 02:32:50,568 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-22 02:32:50,569 [INFO] 目标域新类别: [4, 5]
2025-06-22 02:32:50,569 [INFO] Data allocation verification:
2025-06-22 02:32:50,569 [INFO]   Source data samples: 280
2025-06-22 02:32:50,569 [INFO]   Target data samples: 320
2025-06-22 02:32:50,569 [INFO]   Overlapping samples: 0
2025-06-22 02:32:50,569 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-22 02:32:50,569 [INFO] Model initialized with 18052 parameters
2025-06-22 02:32:50,570 [INFO] Previous best validation accuracy read from record.txt: 0.6250
2025-06-22 02:32:50,570 [INFO] Starting training...
2025-06-22 02:32:50,580 [INFO] Epoch 001 | Train Loss: 9.0054 | Val Loss: 4.3288 | Val Acc: 0.3393
2025-06-22 02:32:51,096 [INFO] New best model at epoch 1 (Val Acc: 0.3393)
2025-06-22 02:32:51,108 [INFO] Epoch 002 | Train Loss: 5.1341 | Val Loss: 2.2523 | Val Acc: 0.2500
2025-06-22 02:32:51,119 [INFO] Epoch 003 | Train Loss: 5.8181 | Val Loss: 2.9984 | Val Acc: 0.1964
2025-06-22 02:32:51,129 [INFO] Epoch 004 | Train Loss: 4.5964 | Val Loss: 2.2632 | Val Acc: 0.3929
2025-06-22 02:32:51,131 [INFO] New best model at epoch 4 (Val Acc: 0.3929)
2025-06-22 02:32:51,155 [INFO] Epoch 005 | Train Loss: 4.0677 | Val Loss: 2.0367 | Val Acc: 0.3393
2025-06-22 02:32:51,166 [INFO] Epoch 006 | Train Loss: 4.0699 | Val Loss: 2.1676 | Val Acc: 0.3393
2025-06-22 02:32:51,176 [INFO] Epoch 007 | Train Loss: 4.4269 | Val Loss: 2.6289 | Val Acc: 0.2679
2025-06-22 02:32:51,187 [INFO] Epoch 008 | Train Loss: 4.3314 | Val Loss: 2.1589 | Val Acc: 0.3393
2025-06-22 02:32:51,203 [INFO] Epoch 009 | Train Loss: 3.9653 | Val Loss: 2.0667 | Val Acc: 0.3571
2025-06-22 02:32:51,214 [INFO] Epoch 010 | Train Loss: 3.2565 | Val Loss: 1.8820 | Val Acc: 0.3571
2025-06-22 02:32:51,810 [INFO] Epoch 011 | Train Loss: 3.8614 | Val Loss: 2.3574 | Val Acc: 0.4643
2025-06-22 02:32:51,812 [INFO] New best model at epoch 11 (Val Acc: 0.4643)
2025-06-22 02:32:51,830 [INFO] Epoch 012 | Train Loss: 3.5687 | Val Loss: 2.1078 | Val Acc: 0.3214
2025-06-22 02:32:51,843 [INFO] Epoch 013 | Train Loss: 3.5316 | Val Loss: 2.9207 | Val Acc: 0.3393
2025-06-22 02:32:51,857 [INFO] Epoch 014 | Train Loss: 3.9880 | Val Loss: 1.9966 | Val Acc: 0.3750
2025-06-22 02:32:51,867 [INFO] Epoch 015 | Train Loss: 3.1518 | Val Loss: 1.9064 | Val Acc: 0.4107
2025-06-22 02:32:51,881 [INFO] Epoch 016 | Train Loss: 3.3138 | Val Loss: 1.8490 | Val Acc: 0.3750
2025-06-22 02:32:51,894 [INFO] Epoch 017 | Train Loss: 3.0480 | Val Loss: 2.0025 | Val Acc: 0.3214
2025-06-22 02:32:51,905 [INFO] Epoch 018 | Train Loss: 2.5857 | Val Loss: 2.3528 | Val Acc: 0.2143
2025-06-22 02:32:51,915 [INFO] Epoch 019 | Train Loss: 2.8144 | Val Loss: 2.1982 | Val Acc: 0.2679
2025-06-22 02:32:51,925 [INFO] Epoch 020 | Train Loss: 2.7722 | Val Loss: 1.9151 | Val Acc: 0.3571
2025-06-22 02:32:52,464 [INFO] Epoch 021 | Train Loss: 2.6465 | Val Loss: 2.1659 | Val Acc: 0.3750
2025-06-22 02:32:52,476 [INFO] Epoch 022 | Train Loss: 2.6012 | Val Loss: 2.4756 | Val Acc: 0.2857
2025-06-22 02:32:52,488 [INFO] Epoch 023 | Train Loss: 2.5329 | Val Loss: 2.0142 | Val Acc: 0.3571
2025-06-22 02:32:52,499 [INFO] Epoch 024 | Train Loss: 2.8672 | Val Loss: 1.9514 | Val Acc: 0.3929
2025-06-22 02:32:52,511 [INFO] Epoch 025 | Train Loss: 2.1782 | Val Loss: 2.0887 | Val Acc: 0.3214
2025-06-22 02:32:52,523 [INFO] Epoch 026 | Train Loss: 2.7216 | Val Loss: 2.2041 | Val Acc: 0.3393
2025-06-22 02:32:52,537 [INFO] Epoch 027 | Train Loss: 2.3115 | Val Loss: 2.1728 | Val Acc: 0.3929
2025-06-22 02:32:52,550 [INFO] Epoch 028 | Train Loss: 2.5742 | Val Loss: 2.1755 | Val Acc: 0.4286
2025-06-22 02:32:52,561 [INFO] Epoch 029 | Train Loss: 2.6314 | Val Loss: 2.6476 | Val Acc: 0.2679
2025-06-22 02:32:52,582 [INFO] Epoch 030 | Train Loss: 2.2565 | Val Loss: 2.0821 | Val Acc: 0.3393
2025-06-22 02:32:53,269 [INFO] Epoch 031 | Train Loss: 2.7203 | Val Loss: 1.8712 | Val Acc: 0.3750
2025-06-22 02:32:53,279 [INFO] Epoch 032 | Train Loss: 2.3445 | Val Loss: 2.3488 | Val Acc: 0.3571
2025-06-22 02:32:53,290 [INFO] Epoch 033 | Train Loss: 2.4220 | Val Loss: 2.4709 | Val Acc: 0.2321
2025-06-22 02:32:53,301 [INFO] Epoch 034 | Train Loss: 2.2611 | Val Loss: 1.9073 | Val Acc: 0.4286
2025-06-22 02:32:53,311 [INFO] Epoch 035 | Train Loss: 2.0528 | Val Loss: 1.8883 | Val Acc: 0.3929
2025-06-22 02:32:53,322 [INFO] Epoch 036 | Train Loss: 2.1118 | Val Loss: 1.8452 | Val Acc: 0.4464
2025-06-22 02:32:53,334 [INFO] Epoch 037 | Train Loss: 2.2439 | Val Loss: 1.8118 | Val Acc: 0.3571
2025-06-22 02:32:53,349 [INFO] Epoch 038 | Train Loss: 2.1125 | Val Loss: 2.2973 | Val Acc: 0.3036
2025-06-22 02:32:53,360 [INFO] Epoch 039 | Train Loss: 2.1141 | Val Loss: 1.9052 | Val Acc: 0.3214
2025-06-22 02:32:53,370 [INFO] Epoch 040 | Train Loss: 1.9526 | Val Loss: 1.8093 | Val Acc: 0.3393
2025-06-22 02:32:53,909 [INFO] Epoch 041 | Train Loss: 1.8891 | Val Loss: 1.6160 | Val Acc: 0.3750
2025-06-22 02:32:53,920 [INFO] Epoch 042 | Train Loss: 1.9248 | Val Loss: 1.7544 | Val Acc: 0.3393
2025-06-22 02:32:53,931 [INFO] Epoch 043 | Train Loss: 1.9907 | Val Loss: 1.6598 | Val Acc: 0.3929
2025-06-22 02:32:53,941 [INFO] Epoch 044 | Train Loss: 2.0377 | Val Loss: 1.7922 | Val Acc: 0.4286
2025-06-22 02:32:53,952 [INFO] Epoch 045 | Train Loss: 1.8187 | Val Loss: 1.5696 | Val Acc: 0.3750
2025-06-22 02:32:53,963 [INFO] Epoch 046 | Train Loss: 1.7437 | Val Loss: 1.6243 | Val Acc: 0.4286
2025-06-22 02:32:53,974 [INFO] Epoch 047 | Train Loss: 1.7709 | Val Loss: 1.7697 | Val Acc: 0.3929
2025-06-22 02:32:53,984 [INFO] Epoch 048 | Train Loss: 1.7359 | Val Loss: 1.7844 | Val Acc: 0.3214
2025-06-22 02:32:53,994 [INFO] Epoch 049 | Train Loss: 1.7263 | Val Loss: 1.6413 | Val Acc: 0.4464
2025-06-22 02:32:54,004 [INFO] Epoch 050 | Train Loss: 1.8254 | Val Loss: 1.5992 | Val Acc: 0.4286
2025-06-22 02:32:54,497 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.4643 at epoch 11)
2025-06-22 02:32:54,498 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.001/train_metrics.csv
2025-06-22 02:32:55,001 [INFO] Final training curves saved
2025-06-22 02:32:55,001 [INFO] Training completed!
2025-06-22 02:32:55,001 [INFO] Best validation accuracy: 0.4643
2025-06-22 02:32:55,001 [INFO] Best epoch: 11
2025-06-22 02:32:55,001 [INFO] Total epochs trained: 50
2025-06-22 02:32:55,001 [INFO] Starting training with parameters: (0.001, 0.2, 128, 1, 50, 0.001)
