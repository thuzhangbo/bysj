2025-06-22 10:40:13,849 [INFO] Using device: cpu
2025-06-22 10:40:13,849 [INFO] 开始创建数据加载器...
2025-06-22 10:40:13,852 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 10:40:13,852 [INFO] Class allocation analysis:
2025-06-22 10:40:13,852 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 10:40:13,852 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 10:40:13,852 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 10:40:13,852 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 10:40:13,865 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 10:40:13,866 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 10:40:13,866 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 10:40:13,866 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 10:40:13,866 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 10:40:13,866 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 10:40:13,866 [INFO] Final allocation:
2025-06-22 10:40:13,866 [INFO]   Source domain: 280 samples
2025-06-22 10:40:13,866 [INFO]   Target domain: 320 samples
2025-06-22 10:40:13,867 [INFO] Source domain setup:
2025-06-22 10:40:13,867 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-22 10:40:13,867 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-22 10:40:13,867 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-22 10:40:13,867 [INFO]   Total data after allocation: 280
2025-06-22 10:40:13,867 [INFO]   Data split - Train: 224, Val: 56
2025-06-22 10:40:13,867 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-22 10:40:13,867 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-22 10:40:13,869 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 10:40:13,869 [INFO] Class allocation analysis:
2025-06-22 10:40:13,869 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 10:40:13,869 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 10:40:13,869 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 10:40:13,869 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 10:40:13,882 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 10:40:13,882 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 10:40:13,882 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 10:40:13,882 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 10:40:13,882 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 10:40:13,882 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 10:40:13,883 [INFO] Final allocation:
2025-06-22 10:40:13,883 [INFO]   Source domain: 280 samples
2025-06-22 10:40:13,883 [INFO]   Target domain: 320 samples
2025-06-22 10:40:13,884 [INFO] Target domain setup:
2025-06-22 10:40:13,884 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-22 10:40:13,884 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-22 10:40:13,884 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-22 10:40:13,884 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-22 10:40:13,884 [INFO]   Total data after allocation: 320
2025-06-22 10:40:13,884 [INFO]   Data split - Train: 256, Val: 64
2025-06-22 10:40:13,884 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-22 10:40:13,884 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-22 10:40:13,884 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-22 10:40:13,884 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-22 10:40:13,885 [INFO] 数据加载器创建完成!
2025-06-22 10:40:13,885 [INFO] 源域类别数: 4 (重叠类别)
2025-06-22 10:40:13,885 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-22 10:40:13,885 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-22 10:40:13,885 [INFO] 目标域新类别: [4, 5]
2025-06-22 10:40:13,885 [INFO] Data allocation verification:
2025-06-22 10:40:13,885 [INFO]   Source data samples: 280
2025-06-22 10:40:13,885 [INFO]   Target data samples: 320
2025-06-22 10:40:13,885 [INFO]   Overlapping samples: 0
2025-06-22 10:40:13,885 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-22 10:40:13,888 [INFO] Model initialized with 466692 parameters
2025-06-22 10:40:13,888 [INFO] Previous best validation accuracy read from record.txt: 0.6250
2025-06-22 10:40:13,888 [INFO] Starting training...
2025-06-22 10:40:13,970 [INFO] Epoch 001 | Train Loss: 12.8291 | Val Loss: 1.5148 | Val Acc: 0.3036
2025-06-22 10:40:14,747 [INFO] New best model at epoch 1 (Val Acc: 0.3036)
2025-06-22 10:40:14,844 [INFO] Epoch 002 | Train Loss: 7.6715 | Val Loss: 1.6959 | Val Acc: 0.2857
2025-06-22 10:40:14,910 [INFO] Epoch 003 | Train Loss: 7.8431 | Val Loss: 2.5711 | Val Acc: 0.2857
2025-06-22 10:40:14,969 [INFO] Epoch 004 | Train Loss: 8.3594 | Val Loss: 5.3498 | Val Acc: 0.3750
2025-06-22 10:40:15,041 [INFO] New best model at epoch 4 (Val Acc: 0.3750)
2025-06-22 10:40:15,093 [INFO] Epoch 005 | Train Loss: 5.6048 | Val Loss: 4.0593 | Val Acc: 0.3214
2025-06-22 10:40:15,153 [INFO] Epoch 006 | Train Loss: 5.0842 | Val Loss: 3.2260 | Val Acc: 0.3571
2025-06-22 10:40:15,231 [INFO] Epoch 007 | Train Loss: 4.9341 | Val Loss: 3.5102 | Val Acc: 0.3214
2025-06-22 10:40:15,309 [INFO] Epoch 008 | Train Loss: 5.1999 | Val Loss: 3.4068 | Val Acc: 0.4464
2025-06-22 10:40:15,320 [INFO] New best model at epoch 8 (Val Acc: 0.4464)
2025-06-22 10:40:15,374 [INFO] Epoch 009 | Train Loss: 5.9232 | Val Loss: 2.5088 | Val Acc: 0.3750
2025-06-22 10:40:15,436 [INFO] Epoch 010 | Train Loss: 4.7733 | Val Loss: 3.5744 | Val Acc: 0.3036
2025-06-22 10:40:16,322 [INFO] Epoch 011 | Train Loss: 4.5114 | Val Loss: 4.9146 | Val Acc: 0.3214
2025-06-22 10:40:16,397 [INFO] Epoch 012 | Train Loss: 6.6402 | Val Loss: 3.2604 | Val Acc: 0.3214
2025-06-22 10:40:16,457 [INFO] Epoch 013 | Train Loss: 3.8212 | Val Loss: 3.8765 | Val Acc: 0.4464
2025-06-22 10:40:16,520 [INFO] Epoch 014 | Train Loss: 4.5316 | Val Loss: 3.0545 | Val Acc: 0.3571
2025-06-22 10:40:16,580 [INFO] Epoch 015 | Train Loss: 4.5480 | Val Loss: 2.3937 | Val Acc: 0.3214
2025-06-22 10:40:16,643 [INFO] Epoch 016 | Train Loss: 3.5357 | Val Loss: 3.7944 | Val Acc: 0.3750
2025-06-22 10:40:16,704 [INFO] Epoch 017 | Train Loss: 3.9083 | Val Loss: 3.8929 | Val Acc: 0.3214
2025-06-22 10:40:16,765 [INFO] Epoch 018 | Train Loss: 3.0776 | Val Loss: 2.6752 | Val Acc: 0.3214
2025-06-22 10:40:16,831 [INFO] Epoch 019 | Train Loss: 3.4916 | Val Loss: 2.6945 | Val Acc: 0.4107
2025-06-22 10:40:16,904 [INFO] Epoch 020 | Train Loss: 3.9682 | Val Loss: 2.4071 | Val Acc: 0.3750
2025-06-22 10:40:18,226 [INFO] Epoch 021 | Train Loss: 3.9931 | Val Loss: 2.7745 | Val Acc: 0.3750
2025-06-22 10:40:18,289 [INFO] Epoch 022 | Train Loss: 2.8402 | Val Loss: 2.6776 | Val Acc: 0.3393
2025-06-22 10:40:18,349 [INFO] Epoch 023 | Train Loss: 3.3214 | Val Loss: 3.5987 | Val Acc: 0.2857
2025-06-22 10:40:18,429 [INFO] Epoch 024 | Train Loss: 2.5059 | Val Loss: 4.7258 | Val Acc: 0.3036
2025-06-22 10:40:18,506 [INFO] Epoch 025 | Train Loss: 2.5922 | Val Loss: 3.1014 | Val Acc: 0.3571
2025-06-22 10:40:18,566 [INFO] Epoch 026 | Train Loss: 2.5108 | Val Loss: 3.1339 | Val Acc: 0.3036
2025-06-22 10:40:18,629 [INFO] Epoch 027 | Train Loss: 3.0688 | Val Loss: 2.4527 | Val Acc: 0.2857
2025-06-22 10:40:18,693 [INFO] Epoch 028 | Train Loss: 2.8181 | Val Loss: 1.8956 | Val Acc: 0.3036
2025-06-22 10:40:18,766 [INFO] Epoch 029 | Train Loss: 1.5646 | Val Loss: 1.8720 | Val Acc: 0.3571
2025-06-22 10:40:18,827 [INFO] Epoch 030 | Train Loss: 2.0314 | Val Loss: 1.9240 | Val Acc: 0.3393
2025-06-22 10:40:19,690 [INFO] Epoch 031 | Train Loss: 2.1145 | Val Loss: 1.8451 | Val Acc: 0.3214
2025-06-22 10:40:19,759 [INFO] Epoch 032 | Train Loss: 3.4543 | Val Loss: 2.0330 | Val Acc: 0.3571
2025-06-22 10:40:19,819 [INFO] Epoch 033 | Train Loss: 2.1412 | Val Loss: 1.9736 | Val Acc: 0.4107
2025-06-22 10:40:19,879 [INFO] Epoch 034 | Train Loss: 2.2576 | Val Loss: 2.7885 | Val Acc: 0.3929
2025-06-22 10:40:19,939 [INFO] Epoch 035 | Train Loss: 1.7971 | Val Loss: 2.1094 | Val Acc: 0.4107
2025-06-22 10:40:20,001 [INFO] Epoch 036 | Train Loss: 2.2652 | Val Loss: 2.2736 | Val Acc: 0.3929
2025-06-22 10:40:20,063 [INFO] Epoch 037 | Train Loss: 1.4034 | Val Loss: 2.0894 | Val Acc: 0.3929
2025-06-22 10:40:20,128 [INFO] Epoch 038 | Train Loss: 2.2115 | Val Loss: 2.6969 | Val Acc: 0.3750
2025-06-22 10:40:20,200 [INFO] Epoch 039 | Train Loss: 1.7895 | Val Loss: 2.8949 | Val Acc: 0.2679
2025-06-22 10:40:20,260 [INFO] Epoch 040 | Train Loss: 2.8625 | Val Loss: 2.2771 | Val Acc: 0.3571
2025-06-22 10:40:21,131 [INFO] Epoch 041 | Train Loss: 1.7321 | Val Loss: 2.1025 | Val Acc: 0.4107
2025-06-22 10:40:21,196 [INFO] Epoch 042 | Train Loss: 1.5155 | Val Loss: 2.2692 | Val Acc: 0.3929
2025-06-22 10:40:21,255 [INFO] Epoch 043 | Train Loss: 1.7537 | Val Loss: 2.3818 | Val Acc: 0.3571
2025-06-22 10:40:21,317 [INFO] Epoch 044 | Train Loss: 1.6306 | Val Loss: 1.9239 | Val Acc: 0.3393
2025-06-22 10:40:21,378 [INFO] Epoch 045 | Train Loss: 1.4584 | Val Loss: 1.6828 | Val Acc: 0.3929
2025-06-22 10:40:21,439 [INFO] Epoch 046 | Train Loss: 1.4292 | Val Loss: 1.7316 | Val Acc: 0.4107
2025-06-22 10:40:21,499 [INFO] Epoch 047 | Train Loss: 1.5961 | Val Loss: 2.0657 | Val Acc: 0.3929
2025-06-22 10:40:21,561 [INFO] Epoch 048 | Train Loss: 1.6374 | Val Loss: 1.8040 | Val Acc: 0.4107
2025-06-22 10:40:21,644 [INFO] Epoch 049 | Train Loss: 2.2370 | Val Loss: 2.5559 | Val Acc: 0.3036
2025-06-22 10:40:21,705 [INFO] Epoch 050 | Train Loss: 1.8601 | Val Loss: 4.8582 | Val Acc: 0.3036
2025-06-22 10:40:22,507 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.4464 at epoch 8)
2025-06-22 10:40:22,508 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.001/train_metrics.csv
2025-06-22 10:40:25,525 [INFO] Final training curves saved
2025-06-22 10:40:25,525 [INFO] Training completed!
2025-06-22 10:40:25,525 [INFO] Best validation accuracy: 0.4464
2025-06-22 10:40:25,525 [INFO] Best epoch: 8
2025-06-22 10:40:25,525 [INFO] Total epochs trained: 50
2025-06-22 10:40:25,528 [INFO] Starting training with parameters: (0.001, 0.5, 256, 4, 50, 0.0001)
