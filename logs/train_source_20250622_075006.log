2025-06-22 07:50:06,255 [INFO] Using device: cpu
2025-06-22 07:50:06,255 [INFO] 开始创建数据加载器...
2025-06-22 07:50:06,257 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 07:50:06,257 [INFO] Class allocation analysis:
2025-06-22 07:50:06,257 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 07:50:06,257 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 07:50:06,257 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 07:50:06,257 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 07:50:06,272 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 07:50:06,272 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 07:50:06,272 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 07:50:06,272 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 07:50:06,272 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 07:50:06,272 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 07:50:06,273 [INFO] Final allocation:
2025-06-22 07:50:06,273 [INFO]   Source domain: 280 samples
2025-06-22 07:50:06,273 [INFO]   Target domain: 320 samples
2025-06-22 07:50:06,274 [INFO] Source domain setup:
2025-06-22 07:50:06,274 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-22 07:50:06,274 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-22 07:50:06,274 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-22 07:50:06,274 [INFO]   Total data after allocation: 280
2025-06-22 07:50:06,274 [INFO]   Data split - Train: 224, Val: 56
2025-06-22 07:50:06,274 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-22 07:50:06,274 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-22 07:50:06,276 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 07:50:06,276 [INFO] Class allocation analysis:
2025-06-22 07:50:06,276 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 07:50:06,276 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 07:50:06,276 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 07:50:06,276 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 07:50:06,290 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 07:50:06,290 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 07:50:06,291 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 07:50:06,291 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 07:50:06,291 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 07:50:06,291 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 07:50:06,291 [INFO] Final allocation:
2025-06-22 07:50:06,291 [INFO]   Source domain: 280 samples
2025-06-22 07:50:06,291 [INFO]   Target domain: 320 samples
2025-06-22 07:50:06,293 [INFO] Target domain setup:
2025-06-22 07:50:06,293 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-22 07:50:06,293 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-22 07:50:06,293 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-22 07:50:06,293 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-22 07:50:06,293 [INFO]   Total data after allocation: 320
2025-06-22 07:50:06,293 [INFO]   Data split - Train: 256, Val: 64
2025-06-22 07:50:06,293 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-22 07:50:06,293 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-22 07:50:06,293 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-22 07:50:06,293 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-22 07:50:06,293 [INFO] 数据加载器创建完成!
2025-06-22 07:50:06,293 [INFO] 源域类别数: 4 (重叠类别)
2025-06-22 07:50:06,293 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-22 07:50:06,293 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-22 07:50:06,293 [INFO] 目标域新类别: [4, 5]
2025-06-22 07:50:06,293 [INFO] Data allocation verification:
2025-06-22 07:50:06,293 [INFO]   Source data samples: 280
2025-06-22 07:50:06,293 [INFO]   Target data samples: 320
2025-06-22 07:50:06,293 [INFO]   Overlapping samples: 0
2025-06-22 07:50:06,293 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-22 07:50:06,300 [INFO] Model initialized with 334084 parameters
2025-06-22 07:50:06,300 [INFO] Previous best validation accuracy read from record.txt: 0.6250
2025-06-22 07:50:06,300 [INFO] Starting training...
2025-06-22 07:50:06,387 [INFO] Epoch 001 | Train Loss: 11.0052 | Val Loss: 1.5512 | Val Acc: 0.3750
2025-06-22 07:50:07,110 [INFO] New best model at epoch 1 (Val Acc: 0.3750)
2025-06-22 07:50:07,150 [INFO] Epoch 002 | Train Loss: 8.5835 | Val Loss: 1.6955 | Val Acc: 0.4286
2025-06-22 07:50:07,158 [INFO] New best model at epoch 2 (Val Acc: 0.4286)
2025-06-22 07:50:07,230 [INFO] Epoch 003 | Train Loss: 9.3031 | Val Loss: 5.8977 | Val Acc: 0.3214
2025-06-22 07:50:07,275 [INFO] Epoch 004 | Train Loss: 6.3576 | Val Loss: 5.1445 | Val Acc: 0.2500
2025-06-22 07:50:07,322 [INFO] Epoch 005 | Train Loss: 6.1614 | Val Loss: 4.5329 | Val Acc: 0.4107
2025-06-22 07:50:07,368 [INFO] Epoch 006 | Train Loss: 5.7642 | Val Loss: 4.3803 | Val Acc: 0.3571
2025-06-22 07:50:07,415 [INFO] Epoch 007 | Train Loss: 5.0040 | Val Loss: 3.8784 | Val Acc: 0.3929
2025-06-22 07:50:07,459 [INFO] Epoch 008 | Train Loss: 4.8177 | Val Loss: 2.5271 | Val Acc: 0.4821
2025-06-22 07:50:07,468 [INFO] New best model at epoch 8 (Val Acc: 0.4821)
2025-06-22 07:50:07,519 [INFO] Epoch 009 | Train Loss: 4.3977 | Val Loss: 3.0808 | Val Acc: 0.4286
2025-06-22 07:50:07,564 [INFO] Epoch 010 | Train Loss: 5.3166 | Val Loss: 3.2253 | Val Acc: 0.2857
2025-06-22 07:50:08,280 [INFO] Epoch 011 | Train Loss: 4.1150 | Val Loss: 3.8881 | Val Acc: 0.3036
2025-06-22 07:50:08,360 [INFO] Epoch 012 | Train Loss: 4.2507 | Val Loss: 2.6663 | Val Acc: 0.3393
2025-06-22 07:50:08,442 [INFO] Epoch 013 | Train Loss: 3.7579 | Val Loss: 2.4523 | Val Acc: 0.3750
2025-06-22 07:50:08,527 [INFO] Epoch 014 | Train Loss: 3.9460 | Val Loss: 2.2027 | Val Acc: 0.4464
2025-06-22 07:50:08,613 [INFO] Epoch 015 | Train Loss: 3.5018 | Val Loss: 2.1134 | Val Acc: 0.3750
2025-06-22 07:50:08,694 [INFO] Epoch 016 | Train Loss: 4.4502 | Val Loss: 2.7111 | Val Acc: 0.2679
2025-06-22 07:50:08,759 [INFO] Epoch 017 | Train Loss: 3.3770 | Val Loss: 2.7504 | Val Acc: 0.3036
2025-06-22 07:50:08,804 [INFO] Epoch 018 | Train Loss: 3.1607 | Val Loss: 2.7270 | Val Acc: 0.3393
2025-06-22 07:50:08,851 [INFO] Epoch 019 | Train Loss: 3.1322 | Val Loss: 2.1560 | Val Acc: 0.2857
2025-06-22 07:50:08,897 [INFO] Epoch 020 | Train Loss: 2.6752 | Val Loss: 4.8758 | Val Acc: 0.3393
2025-06-22 07:50:09,656 [INFO] Epoch 021 | Train Loss: 3.3811 | Val Loss: 2.1058 | Val Acc: 0.3214
2025-06-22 07:50:09,719 [INFO] Epoch 022 | Train Loss: 2.5469 | Val Loss: 2.0136 | Val Acc: 0.3929
2025-06-22 07:50:09,764 [INFO] Epoch 023 | Train Loss: 4.1779 | Val Loss: 1.9135 | Val Acc: 0.4107
2025-06-22 07:50:09,810 [INFO] Epoch 024 | Train Loss: 3.2355 | Val Loss: 2.3266 | Val Acc: 0.2679
2025-06-22 07:50:09,855 [INFO] Epoch 025 | Train Loss: 2.7934 | Val Loss: 2.9899 | Val Acc: 0.3036
2025-06-22 07:50:09,902 [INFO] Epoch 026 | Train Loss: 2.8475 | Val Loss: 3.8105 | Val Acc: 0.3571
2025-06-22 07:50:09,949 [INFO] Epoch 027 | Train Loss: 3.9632 | Val Loss: 2.1565 | Val Acc: 0.3393
2025-06-22 07:50:09,995 [INFO] Epoch 028 | Train Loss: 2.9541 | Val Loss: 2.4632 | Val Acc: 0.2679
2025-06-22 07:50:10,041 [INFO] Epoch 029 | Train Loss: 2.9038 | Val Loss: 3.2243 | Val Acc: 0.3214
2025-06-22 07:50:10,088 [INFO] Epoch 030 | Train Loss: 3.9087 | Val Loss: 3.1635 | Val Acc: 0.3393
2025-06-22 07:50:10,779 [INFO] Epoch 031 | Train Loss: 3.7336 | Val Loss: 3.7294 | Val Acc: 0.3929
2025-06-22 07:50:10,843 [INFO] Epoch 032 | Train Loss: 2.8206 | Val Loss: 2.5527 | Val Acc: 0.3214
2025-06-22 07:50:10,886 [INFO] Epoch 033 | Train Loss: 1.9407 | Val Loss: 1.9206 | Val Acc: 0.3929
2025-06-22 07:50:10,931 [INFO] Epoch 034 | Train Loss: 1.5366 | Val Loss: 2.1821 | Val Acc: 0.3393
2025-06-22 07:50:10,976 [INFO] Epoch 035 | Train Loss: 1.7825 | Val Loss: 2.9650 | Val Acc: 0.2857
2025-06-22 07:50:11,022 [INFO] Epoch 036 | Train Loss: 2.9285 | Val Loss: 3.6085 | Val Acc: 0.2857
2025-06-22 07:50:11,069 [INFO] Epoch 037 | Train Loss: 2.0707 | Val Loss: 2.4487 | Val Acc: 0.3393
2025-06-22 07:50:11,114 [INFO] Epoch 038 | Train Loss: 2.1160 | Val Loss: 1.7808 | Val Acc: 0.4464
2025-06-22 07:50:11,160 [INFO] Epoch 039 | Train Loss: 2.7709 | Val Loss: 2.5097 | Val Acc: 0.3929
2025-06-22 07:50:11,206 [INFO] Epoch 040 | Train Loss: 2.4117 | Val Loss: 2.1534 | Val Acc: 0.3750
2025-06-22 07:50:13,519 [INFO] Epoch 041 | Train Loss: 2.4292 | Val Loss: 1.8269 | Val Acc: 0.4107
2025-06-22 07:50:13,580 [INFO] Epoch 042 | Train Loss: 2.1076 | Val Loss: 1.8692 | Val Acc: 0.3571
2025-06-22 07:50:13,633 [INFO] Epoch 043 | Train Loss: 2.4231 | Val Loss: 2.4787 | Val Acc: 0.3393
2025-06-22 07:50:13,681 [INFO] Epoch 044 | Train Loss: 1.8410 | Val Loss: 1.8594 | Val Acc: 0.4286
2025-06-22 07:50:13,729 [INFO] Epoch 045 | Train Loss: 2.1690 | Val Loss: 2.3044 | Val Acc: 0.3571
2025-06-22 07:50:13,775 [INFO] Epoch 046 | Train Loss: 1.6257 | Val Loss: 2.3812 | Val Acc: 0.3750
2025-06-22 07:50:13,822 [INFO] Epoch 047 | Train Loss: 1.4879 | Val Loss: 1.9271 | Val Acc: 0.3036
2025-06-22 07:50:13,870 [INFO] Epoch 048 | Train Loss: 1.6502 | Val Loss: 2.2912 | Val Acc: 0.3393
2025-06-22 07:50:13,925 [INFO] Epoch 049 | Train Loss: 1.4381 | Val Loss: 2.0661 | Val Acc: 0.3393
2025-06-22 07:50:13,994 [INFO] Epoch 050 | Train Loss: 1.4788 | Val Loss: 2.5078 | Val Acc: 0.2857
2025-06-22 07:50:14,677 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.4821 at epoch 8)
2025-06-22 07:50:14,677 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.001/train_metrics.csv
2025-06-22 07:50:15,666 [INFO] Final training curves saved
2025-06-22 07:50:15,666 [INFO] Training completed!
2025-06-22 07:50:15,666 [INFO] Best validation accuracy: 0.4821
2025-06-22 07:50:15,666 [INFO] Best epoch: 8
2025-06-22 07:50:15,666 [INFO] Total epochs trained: 50
2025-06-22 07:50:15,667 [INFO] Starting training with parameters: (0.001, 0.4, 256, 3, 50, 0.001)
