2025-06-22 08:25:40,236 [INFO] Using device: cpu
2025-06-22 08:25:40,236 [INFO] 开始创建数据加载器...
2025-06-22 08:25:40,239 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 08:25:40,239 [INFO] Class allocation analysis:
2025-06-22 08:25:40,239 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 08:25:40,239 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 08:25:40,239 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 08:25:40,239 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 08:25:40,253 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 08:25:40,253 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 08:25:40,253 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 08:25:40,253 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 08:25:40,253 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 08:25:40,253 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 08:25:40,253 [INFO] Final allocation:
2025-06-22 08:25:40,253 [INFO]   Source domain: 280 samples
2025-06-22 08:25:40,253 [INFO]   Target domain: 320 samples
2025-06-22 08:25:40,254 [INFO] Source domain setup:
2025-06-22 08:25:40,254 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-22 08:25:40,254 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-22 08:25:40,255 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-22 08:25:40,255 [INFO]   Total data after allocation: 280
2025-06-22 08:25:40,255 [INFO]   Data split - Train: 224, Val: 56
2025-06-22 08:25:40,255 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-22 08:25:40,255 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-22 08:25:40,256 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 08:25:40,256 [INFO] Class allocation analysis:
2025-06-22 08:25:40,256 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 08:25:40,256 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 08:25:40,256 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 08:25:40,256 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 08:25:40,269 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 08:25:40,270 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 08:25:40,270 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 08:25:40,270 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 08:25:40,270 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 08:25:40,270 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 08:25:40,270 [INFO] Final allocation:
2025-06-22 08:25:40,270 [INFO]   Source domain: 280 samples
2025-06-22 08:25:40,270 [INFO]   Target domain: 320 samples
2025-06-22 08:25:40,272 [INFO] Target domain setup:
2025-06-22 08:25:40,272 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-22 08:25:40,272 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-22 08:25:40,272 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-22 08:25:40,272 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-22 08:25:40,272 [INFO]   Total data after allocation: 320
2025-06-22 08:25:40,272 [INFO]   Data split - Train: 256, Val: 64
2025-06-22 08:25:40,272 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-22 08:25:40,272 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-22 08:25:40,272 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-22 08:25:40,272 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-22 08:25:40,272 [INFO] 数据加载器创建完成!
2025-06-22 08:25:40,272 [INFO] 源域类别数: 4 (重叠类别)
2025-06-22 08:25:40,272 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-22 08:25:40,272 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-22 08:25:40,272 [INFO] 目标域新类别: [4, 5]
2025-06-22 08:25:40,273 [INFO] Data allocation verification:
2025-06-22 08:25:40,273 [INFO]   Source data samples: 280
2025-06-22 08:25:40,273 [INFO]   Target data samples: 320
2025-06-22 08:25:40,273 [INFO]   Overlapping samples: 0
2025-06-22 08:25:40,273 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-22 08:25:40,277 [INFO] Model initialized with 1323524 parameters
2025-06-22 08:25:40,277 [INFO] Previous best validation accuracy read from record.txt: 0.6250
2025-06-22 08:25:40,278 [INFO] Starting training...
2025-06-22 08:25:40,391 [INFO] Epoch 001 | Train Loss: 17.3279 | Val Loss: 3.9221 | Val Acc: 0.2857
2025-06-22 08:25:41,171 [INFO] New best model at epoch 1 (Val Acc: 0.2857)
2025-06-22 08:25:41,308 [INFO] Epoch 002 | Train Loss: 10.2098 | Val Loss: 8.4676 | Val Acc: 0.3214
2025-06-22 08:25:41,331 [INFO] New best model at epoch 2 (Val Acc: 0.3214)
2025-06-22 08:25:41,430 [INFO] Epoch 003 | Train Loss: 7.1067 | Val Loss: 4.7450 | Val Acc: 0.4643
2025-06-22 08:25:41,451 [INFO] New best model at epoch 3 (Val Acc: 0.4643)
2025-06-22 08:25:41,547 [INFO] Epoch 004 | Train Loss: 6.5185 | Val Loss: 5.1749 | Val Acc: 0.4286
2025-06-22 08:25:41,645 [INFO] Epoch 005 | Train Loss: 7.1619 | Val Loss: 3.2251 | Val Acc: 0.4464
2025-06-22 08:25:41,759 [INFO] Epoch 006 | Train Loss: 5.4857 | Val Loss: 5.2862 | Val Acc: 0.2500
2025-06-22 08:25:41,856 [INFO] Epoch 007 | Train Loss: 5.2125 | Val Loss: 4.5175 | Val Acc: 0.4286
2025-06-22 08:25:41,969 [INFO] Epoch 008 | Train Loss: 4.4770 | Val Loss: 4.0678 | Val Acc: 0.3571
2025-06-22 08:25:42,083 [INFO] Epoch 009 | Train Loss: 4.9492 | Val Loss: 3.2356 | Val Acc: 0.3929
2025-06-22 08:25:42,190 [INFO] Epoch 010 | Train Loss: 5.5868 | Val Loss: 4.1366 | Val Acc: 0.3036
2025-06-22 08:25:43,005 [INFO] Epoch 011 | Train Loss: 5.7942 | Val Loss: 2.7765 | Val Acc: 0.3929
2025-06-22 08:25:43,105 [INFO] Epoch 012 | Train Loss: 5.1687 | Val Loss: 3.6875 | Val Acc: 0.3393
2025-06-22 08:25:43,203 [INFO] Epoch 013 | Train Loss: 4.6141 | Val Loss: 4.0658 | Val Acc: 0.3393
2025-06-22 08:25:43,306 [INFO] Epoch 014 | Train Loss: 4.9698 | Val Loss: 3.7658 | Val Acc: 0.3214
2025-06-22 08:25:43,424 [INFO] Epoch 015 | Train Loss: 3.6612 | Val Loss: 4.2302 | Val Acc: 0.3393
2025-06-22 08:25:43,535 [INFO] Epoch 016 | Train Loss: 3.7041 | Val Loss: 3.4365 | Val Acc: 0.3214
2025-06-22 08:25:43,636 [INFO] Epoch 017 | Train Loss: 3.1613 | Val Loss: 4.7243 | Val Acc: 0.2321
2025-06-22 08:25:43,746 [INFO] Epoch 018 | Train Loss: 5.0662 | Val Loss: 2.3490 | Val Acc: 0.3571
2025-06-22 08:25:43,843 [INFO] Epoch 019 | Train Loss: 3.8170 | Val Loss: 2.7592 | Val Acc: 0.3571
2025-06-22 08:25:43,945 [INFO] Epoch 020 | Train Loss: 4.6746 | Val Loss: 2.6980 | Val Acc: 0.3214
2025-06-22 08:25:46,942 [INFO] Epoch 021 | Train Loss: 3.8009 | Val Loss: 2.3502 | Val Acc: 0.4286
2025-06-22 08:25:47,067 [INFO] Epoch 022 | Train Loss: 4.4560 | Val Loss: 2.8102 | Val Acc: 0.4107
2025-06-22 08:25:47,178 [INFO] Epoch 023 | Train Loss: 3.4248 | Val Loss: 3.7228 | Val Acc: 0.3750
2025-06-22 08:25:47,321 [INFO] Epoch 024 | Train Loss: 3.6137 | Val Loss: 3.1821 | Val Acc: 0.3036
2025-06-22 08:25:47,430 [INFO] Epoch 025 | Train Loss: 2.5598 | Val Loss: 2.7116 | Val Acc: 0.3393
2025-06-22 08:25:47,534 [INFO] Epoch 026 | Train Loss: 2.9602 | Val Loss: 2.3117 | Val Acc: 0.4643
2025-06-22 08:25:47,637 [INFO] Epoch 027 | Train Loss: 3.6728 | Val Loss: 2.6025 | Val Acc: 0.3750
2025-06-22 08:25:47,785 [INFO] Epoch 028 | Train Loss: 2.3257 | Val Loss: 2.7376 | Val Acc: 0.3393
2025-06-22 08:25:47,902 [INFO] Epoch 029 | Train Loss: 3.3266 | Val Loss: 2.5365 | Val Acc: 0.3750
2025-06-22 08:25:48,010 [INFO] Epoch 030 | Train Loss: 2.6094 | Val Loss: 2.4812 | Val Acc: 0.3929
2025-06-22 08:25:50,394 [INFO] Epoch 031 | Train Loss: 2.1127 | Val Loss: 2.5603 | Val Acc: 0.3929
2025-06-22 08:25:50,513 [INFO] Epoch 032 | Train Loss: 2.9161 | Val Loss: 2.3737 | Val Acc: 0.4107
2025-06-22 08:25:50,620 [INFO] Epoch 033 | Train Loss: 2.4020 | Val Loss: 1.9235 | Val Acc: 0.4107
2025-06-22 08:25:50,746 [INFO] Epoch 034 | Train Loss: 1.6917 | Val Loss: 2.6095 | Val Acc: 0.3750
2025-06-22 08:25:50,848 [INFO] Epoch 035 | Train Loss: 2.7321 | Val Loss: 3.8892 | Val Acc: 0.3214
2025-06-22 08:25:50,946 [INFO] Epoch 036 | Train Loss: 3.2683 | Val Loss: 2.6977 | Val Acc: 0.4286
2025-06-22 08:25:51,076 [INFO] Epoch 037 | Train Loss: 3.0628 | Val Loss: 2.3242 | Val Acc: 0.3929
2025-06-22 08:25:51,176 [INFO] Epoch 038 | Train Loss: 2.1258 | Val Loss: 2.9590 | Val Acc: 0.3571
2025-06-22 08:25:51,282 [INFO] Epoch 039 | Train Loss: 2.1346 | Val Loss: 2.8493 | Val Acc: 0.3750
2025-06-22 08:25:51,381 [INFO] Epoch 040 | Train Loss: 2.5376 | Val Loss: 2.5364 | Val Acc: 0.4464
2025-06-22 08:25:52,284 [INFO] Epoch 041 | Train Loss: 2.3383 | Val Loss: 3.3463 | Val Acc: 0.2857
2025-06-22 08:25:52,383 [INFO] Epoch 042 | Train Loss: 3.1553 | Val Loss: 2.1607 | Val Acc: 0.4286
2025-06-22 08:25:52,499 [INFO] Epoch 043 | Train Loss: 2.7054 | Val Loss: 1.8556 | Val Acc: 0.4286
2025-06-22 08:25:52,610 [INFO] Epoch 044 | Train Loss: 1.6855 | Val Loss: 3.7112 | Val Acc: 0.3750
2025-06-22 08:25:52,726 [INFO] Epoch 045 | Train Loss: 2.2645 | Val Loss: 3.5839 | Val Acc: 0.2679
2025-06-22 08:25:52,849 [INFO] Epoch 046 | Train Loss: 2.1547 | Val Loss: 2.8391 | Val Acc: 0.3571
2025-06-22 08:25:52,947 [INFO] Epoch 047 | Train Loss: 2.0549 | Val Loss: 2.1214 | Val Acc: 0.3214
2025-06-22 08:25:53,057 [INFO] Epoch 048 | Train Loss: 2.0897 | Val Loss: 2.3326 | Val Acc: 0.3929
2025-06-22 08:25:53,165 [INFO] Epoch 049 | Train Loss: 1.7846 | Val Loss: 2.4233 | Val Acc: 0.3393
2025-06-22 08:25:53,271 [INFO] Epoch 050 | Train Loss: 1.6944 | Val Loss: 2.1452 | Val Acc: 0.3750
2025-06-22 08:25:54,091 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.4643 at epoch 3)
2025-06-22 08:25:54,091 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.001/train_metrics.csv
2025-06-22 08:25:55,240 [INFO] Final training curves saved
2025-06-22 08:25:55,241 [INFO] Training completed!
2025-06-22 08:25:55,241 [INFO] Best validation accuracy: 0.4643
2025-06-22 08:25:55,241 [INFO] Best epoch: 3
2025-06-22 08:25:55,241 [INFO] Total epochs trained: 50
2025-06-22 08:25:55,241 [INFO] Starting training with parameters: (0.001, 0.4, 512, 3, 50, 0.001)
