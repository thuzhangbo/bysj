2025-06-23 09:49:12,551 [INFO] Using device: cpu
2025-06-23 09:49:12,551 [INFO] 开始创建数据加载器...
2025-06-23 09:49:12,554 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-23 09:49:12,555 [INFO] Class allocation analysis:
2025-06-23 09:49:12,555 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-23 09:49:12,555 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-23 09:49:12,555 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-23 09:49:12,555 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-23 09:49:12,569 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-23 09:49:12,569 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-23 09:49:12,569 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-23 09:49:12,569 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-23 09:49:12,569 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-23 09:49:12,569 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-23 09:49:12,569 [INFO] Final allocation:
2025-06-23 09:49:12,569 [INFO]   Source domain: 280 samples
2025-06-23 09:49:12,569 [INFO]   Target domain: 320 samples
2025-06-23 09:49:12,571 [INFO] Source domain setup:
2025-06-23 09:49:12,571 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-23 09:49:12,571 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-23 09:49:12,571 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-23 09:49:12,571 [INFO]   Total data after allocation: 280
2025-06-23 09:49:12,571 [INFO]   Data split - Train: 224, Val: 56
2025-06-23 09:49:12,571 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-23 09:49:12,571 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-23 09:49:12,572 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-23 09:49:12,572 [INFO] Class allocation analysis:
2025-06-23 09:49:12,573 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-23 09:49:12,573 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-23 09:49:12,573 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-23 09:49:12,573 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-23 09:49:12,586 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-23 09:49:12,586 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-23 09:49:12,587 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-23 09:49:12,587 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-23 09:49:12,587 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-23 09:49:12,587 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-23 09:49:12,587 [INFO] Final allocation:
2025-06-23 09:49:12,587 [INFO]   Source domain: 280 samples
2025-06-23 09:49:12,587 [INFO]   Target domain: 320 samples
2025-06-23 09:49:12,588 [INFO] Target domain setup:
2025-06-23 09:49:12,589 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-23 09:49:12,589 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-23 09:49:12,589 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-23 09:49:12,589 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-23 09:49:12,589 [INFO]   Total data after allocation: 320
2025-06-23 09:49:12,589 [INFO]   Data split - Train: 256, Val: 64
2025-06-23 09:49:12,589 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-23 09:49:12,589 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-23 09:49:12,589 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-23 09:49:12,589 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-23 09:49:12,589 [INFO] 数据加载器创建完成!
2025-06-23 09:49:12,589 [INFO] 源域类别数: 4 (重叠类别)
2025-06-23 09:49:12,589 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-23 09:49:12,589 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-23 09:49:12,589 [INFO] 目标域新类别: [4, 5]
2025-06-23 09:49:12,589 [INFO] Data allocation verification:
2025-06-23 09:49:12,589 [INFO]   Source data samples: 280
2025-06-23 09:49:12,589 [INFO]   Target data samples: 320
2025-06-23 09:49:12,589 [INFO]   Overlapping samples: 0
2025-06-23 09:49:12,589 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-23 09:49:12,592 [INFO] Model initialized with 5924 parameters
2025-06-23 09:49:12,593 [INFO] Previous best validation accuracy read from record.txt: 0.6429
2025-06-23 09:49:12,593 [INFO] Starting training...
2025-06-23 09:49:12,619 [INFO] Epoch 001 | Train Loss: 7.4129 | Val Loss: 2.3476 | Val Acc: 0.3571
2025-06-23 09:49:16,095 [INFO] New best model at epoch 1 (Val Acc: 0.3571)
2025-06-23 09:49:16,170 [INFO] Epoch 002 | Train Loss: 4.1254 | Val Loss: 1.8469 | Val Acc: 0.2143
2025-06-23 09:49:16,202 [INFO] Epoch 003 | Train Loss: 3.1769 | Val Loss: 3.2064 | Val Acc: 0.1964
2025-06-23 09:49:16,230 [INFO] Epoch 004 | Train Loss: 2.6893 | Val Loss: 2.4941 | Val Acc: 0.3036
2025-06-23 09:49:16,260 [INFO] Epoch 005 | Train Loss: 2.1694 | Val Loss: 1.8787 | Val Acc: 0.2679
2025-06-23 09:49:16,286 [INFO] Epoch 006 | Train Loss: 1.7258 | Val Loss: 1.4358 | Val Acc: 0.3214
2025-06-23 09:49:16,311 [INFO] Epoch 007 | Train Loss: 1.8369 | Val Loss: 1.4973 | Val Acc: 0.2500
2025-06-23 09:49:16,349 [INFO] Epoch 008 | Train Loss: 1.6835 | Val Loss: 2.5534 | Val Acc: 0.2679
2025-06-23 09:49:16,382 [INFO] Epoch 009 | Train Loss: 1.6630 | Val Loss: 1.5245 | Val Acc: 0.3214
2025-06-23 09:49:16,414 [INFO] Epoch 010 | Train Loss: 1.4969 | Val Loss: 1.3232 | Val Acc: 0.3214
2025-06-23 09:49:17,568 [INFO] Epoch 011 | Train Loss: 1.4202 | Val Loss: 1.3816 | Val Acc: 0.3214
2025-06-23 09:49:17,593 [INFO] Epoch 012 | Train Loss: 1.3298 | Val Loss: 1.5487 | Val Acc: 0.2857
2025-06-23 09:49:17,624 [INFO] Epoch 013 | Train Loss: 1.4556 | Val Loss: 1.5148 | Val Acc: 0.2679
2025-06-23 09:49:17,652 [INFO] Epoch 014 | Train Loss: 1.3667 | Val Loss: 1.3532 | Val Acc: 0.4286
2025-06-23 09:49:17,655 [INFO] New best model at epoch 14 (Val Acc: 0.4286)
2025-06-23 09:49:17,674 [INFO] Epoch 015 | Train Loss: 1.5015 | Val Loss: 1.3264 | Val Acc: 0.3571
2025-06-23 09:49:17,696 [INFO] Epoch 016 | Train Loss: 1.4333 | Val Loss: 1.4541 | Val Acc: 0.3036
2025-06-23 09:49:17,717 [INFO] Epoch 017 | Train Loss: 1.4255 | Val Loss: 1.3558 | Val Acc: 0.3750
2025-06-23 09:49:17,737 [INFO] Epoch 018 | Train Loss: 1.3455 | Val Loss: 1.5204 | Val Acc: 0.3393
2025-06-23 09:49:17,765 [INFO] Epoch 019 | Train Loss: 1.3362 | Val Loss: 1.3503 | Val Acc: 0.3750
2025-06-23 09:49:17,789 [INFO] Epoch 020 | Train Loss: 1.2544 | Val Loss: 1.3982 | Val Acc: 0.4107
2025-06-23 09:49:19,541 [INFO] Epoch 021 | Train Loss: 1.3573 | Val Loss: 1.4025 | Val Acc: 0.4107
2025-06-23 09:49:19,583 [INFO] Epoch 022 | Train Loss: 1.2372 | Val Loss: 1.6934 | Val Acc: 0.5357
2025-06-23 09:49:19,586 [INFO] New best model at epoch 22 (Val Acc: 0.5357)
2025-06-23 09:49:19,614 [INFO] Epoch 023 | Train Loss: 1.2500 | Val Loss: 1.4513 | Val Acc: 0.4643
2025-06-23 09:49:19,649 [INFO] Epoch 024 | Train Loss: 1.2154 | Val Loss: 1.4340 | Val Acc: 0.4107
2025-06-23 09:49:19,681 [INFO] Epoch 025 | Train Loss: 1.1695 | Val Loss: 1.3397 | Val Acc: 0.4464
2025-06-23 09:49:19,726 [INFO] Epoch 026 | Train Loss: 1.2031 | Val Loss: 1.2679 | Val Acc: 0.3929
2025-06-23 09:49:19,778 [INFO] Epoch 027 | Train Loss: 1.1807 | Val Loss: 1.3129 | Val Acc: 0.4286
2025-06-23 09:49:19,804 [INFO] Epoch 028 | Train Loss: 1.1564 | Val Loss: 1.5899 | Val Acc: 0.3393
2025-06-23 09:49:19,874 [INFO] Epoch 029 | Train Loss: 1.2310 | Val Loss: 1.5275 | Val Acc: 0.5179
2025-06-23 09:49:19,908 [INFO] Epoch 030 | Train Loss: 1.3179 | Val Loss: 1.6857 | Val Acc: 0.3214
2025-06-23 09:49:21,173 [INFO] Epoch 031 | Train Loss: 1.1685 | Val Loss: 1.4581 | Val Acc: 0.4821
2025-06-23 09:49:21,210 [INFO] Epoch 032 | Train Loss: 1.1847 | Val Loss: 1.7255 | Val Acc: 0.4107
2025-06-23 09:49:21,244 [INFO] Epoch 033 | Train Loss: 1.1600 | Val Loss: 1.6187 | Val Acc: 0.3750
2025-06-23 09:49:21,306 [INFO] Epoch 034 | Train Loss: 1.1753 | Val Loss: 1.4252 | Val Acc: 0.4107
2025-06-23 09:49:21,333 [INFO] Epoch 035 | Train Loss: 1.1304 | Val Loss: 1.4970 | Val Acc: 0.3571
2025-06-23 09:49:21,366 [INFO] Epoch 036 | Train Loss: 1.1391 | Val Loss: 1.6420 | Val Acc: 0.4107
2025-06-23 09:49:21,392 [INFO] Epoch 037 | Train Loss: 1.0657 | Val Loss: 1.5242 | Val Acc: 0.4286
2025-06-23 09:49:21,466 [INFO] Epoch 038 | Train Loss: 1.1278 | Val Loss: 1.5954 | Val Acc: 0.3393
2025-06-23 09:49:21,578 [INFO] Epoch 039 | Train Loss: 1.0547 | Val Loss: 1.6094 | Val Acc: 0.3036
2025-06-23 09:49:21,611 [INFO] Epoch 040 | Train Loss: 1.0701 | Val Loss: 1.9607 | Val Acc: 0.3571
2025-06-23 09:49:22,920 [INFO] Epoch 041 | Train Loss: 1.1116 | Val Loss: 1.8216 | Val Acc: 0.3750
2025-06-23 09:49:22,951 [INFO] Epoch 042 | Train Loss: 1.0297 | Val Loss: 1.6355 | Val Acc: 0.3036
2025-06-23 09:49:22,979 [INFO] Epoch 043 | Train Loss: 0.9900 | Val Loss: 2.2880 | Val Acc: 0.3214
2025-06-23 09:49:23,004 [INFO] Epoch 044 | Train Loss: 1.1169 | Val Loss: 1.8286 | Val Acc: 0.3571
2025-06-23 09:49:23,027 [INFO] Epoch 045 | Train Loss: 1.1511 | Val Loss: 1.6691 | Val Acc: 0.3214
2025-06-23 09:49:23,050 [INFO] Epoch 046 | Train Loss: 1.2245 | Val Loss: 1.9378 | Val Acc: 0.3571
2025-06-23 09:49:23,170 [INFO] Epoch 047 | Train Loss: 1.1328 | Val Loss: 1.4150 | Val Acc: 0.3750
2025-06-23 09:49:23,210 [INFO] Epoch 048 | Train Loss: 1.1134 | Val Loss: 1.3146 | Val Acc: 0.3750
2025-06-23 09:49:23,239 [INFO] Epoch 049 | Train Loss: 1.1230 | Val Loss: 1.4124 | Val Acc: 0.4286
2025-06-23 09:49:23,268 [INFO] Epoch 050 | Train Loss: 1.0480 | Val Loss: 1.4829 | Val Acc: 0.4107
2025-06-23 09:49:24,411 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.5357 at epoch 22)
2025-06-23 09:49:24,412 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.01/train_metrics.csv
2025-06-23 09:49:28,928 [INFO] Final training curves saved
2025-06-23 09:49:28,928 [INFO] Training completed!
2025-06-23 09:49:28,928 [INFO] Best validation accuracy: 0.5357
2025-06-23 09:49:28,928 [INFO] Best epoch: 22
2025-06-23 09:49:28,928 [INFO] Total epochs trained: 50
2025-06-23 09:49:28,929 [INFO] Starting training with parameters: (0.01, 0.2, 32, 3, 50, 0.0001)
