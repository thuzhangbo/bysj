2025-06-23 17:59:45,366 [INFO] Using device: cpu
2025-06-23 17:59:45,366 [INFO] 开始创建数据加载器...
2025-06-23 17:59:45,376 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-23 17:59:45,376 [INFO] Class allocation analysis:
2025-06-23 17:59:45,376 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-23 17:59:45,376 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-23 17:59:45,376 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-23 17:59:45,376 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-23 17:59:45,399 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-23 17:59:45,399 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-23 17:59:45,400 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-23 17:59:45,400 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-23 17:59:45,400 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-23 17:59:45,400 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-23 17:59:45,400 [INFO] Final allocation:
2025-06-23 17:59:45,400 [INFO]   Source domain: 280 samples
2025-06-23 17:59:45,400 [INFO]   Target domain: 320 samples
2025-06-23 17:59:45,404 [INFO] Source domain setup:
2025-06-23 17:59:45,404 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-23 17:59:45,404 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-23 17:59:45,404 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-23 17:59:45,404 [INFO]   Total data after allocation: 280
2025-06-23 17:59:45,404 [INFO]   Data split - Train: 224, Val: 56
2025-06-23 17:59:45,404 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-23 17:59:45,404 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-23 17:59:45,408 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-23 17:59:45,409 [INFO] Class allocation analysis:
2025-06-23 17:59:45,409 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-23 17:59:45,409 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-23 17:59:45,409 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-23 17:59:45,409 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-23 17:59:45,426 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-23 17:59:45,426 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-23 17:59:45,426 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-23 17:59:45,427 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-23 17:59:45,427 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-23 17:59:45,427 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-23 17:59:45,427 [INFO] Final allocation:
2025-06-23 17:59:45,427 [INFO]   Source domain: 280 samples
2025-06-23 17:59:45,427 [INFO]   Target domain: 320 samples
2025-06-23 17:59:45,430 [INFO] Target domain setup:
2025-06-23 17:59:45,430 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-23 17:59:45,430 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-23 17:59:45,430 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-23 17:59:45,430 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-23 17:59:45,430 [INFO]   Total data after allocation: 320
2025-06-23 17:59:45,430 [INFO]   Data split - Train: 256, Val: 64
2025-06-23 17:59:45,430 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-23 17:59:45,430 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-23 17:59:45,430 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-23 17:59:45,430 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-23 17:59:45,432 [INFO] 数据加载器创建完成!
2025-06-23 17:59:45,432 [INFO] 源域类别数: 4 (重叠类别)
2025-06-23 17:59:45,432 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-23 17:59:45,432 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-23 17:59:45,432 [INFO] 目标域新类别: [4, 5]
2025-06-23 17:59:45,432 [INFO] Data allocation verification:
2025-06-23 17:59:45,432 [INFO]   Source data samples: 280
2025-06-23 17:59:45,432 [INFO]   Target data samples: 320
2025-06-23 17:59:45,432 [INFO]   Overlapping samples: 0
2025-06-23 17:59:45,432 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-23 17:59:45,458 [INFO] Model initialized with 1444 parameters
2025-06-23 17:59:45,458 [INFO] Previous best validation accuracy read from record.txt: 0.6429
2025-06-23 17:59:45,458 [INFO] Starting training...
2025-06-23 17:59:45,480 [INFO] Epoch 001 | Train Loss: 8.4027 | Val Loss: 3.6750 | Val Acc: 0.3214
2025-06-23 17:59:46,940 [INFO] New best model at epoch 1 (Val Acc: 0.3214)
2025-06-23 17:59:46,972 [INFO] Epoch 002 | Train Loss: 4.9096 | Val Loss: 1.6193 | Val Acc: 0.3750
2025-06-23 17:59:46,974 [INFO] New best model at epoch 2 (Val Acc: 0.3750)
2025-06-23 17:59:46,989 [INFO] Epoch 003 | Train Loss: 3.7159 | Val Loss: 1.5503 | Val Acc: 0.3571
2025-06-23 17:59:47,007 [INFO] Epoch 004 | Train Loss: 2.8419 | Val Loss: 1.6167 | Val Acc: 0.3214
2025-06-23 17:59:47,030 [INFO] Epoch 005 | Train Loss: 2.8785 | Val Loss: 1.6245 | Val Acc: 0.3393
2025-06-23 17:59:47,045 [INFO] Epoch 006 | Train Loss: 2.1175 | Val Loss: 1.4158 | Val Acc: 0.3393
2025-06-23 17:59:47,057 [INFO] Epoch 007 | Train Loss: 1.9045 | Val Loss: 1.4270 | Val Acc: 0.3571
2025-06-23 17:59:47,071 [INFO] Epoch 008 | Train Loss: 1.7296 | Val Loss: 1.4663 | Val Acc: 0.2321
2025-06-23 17:59:47,084 [INFO] Epoch 009 | Train Loss: 1.5869 | Val Loss: 1.3499 | Val Acc: 0.2857
2025-06-23 17:59:47,098 [INFO] Epoch 010 | Train Loss: 1.6797 | Val Loss: 1.2623 | Val Acc: 0.4821
2025-06-23 17:59:48,392 [INFO] New best model at epoch 10 (Val Acc: 0.4821)
2025-06-23 17:59:48,402 [INFO] Epoch 011 | Train Loss: 1.5428 | Val Loss: 1.3401 | Val Acc: 0.3929
2025-06-23 17:59:48,412 [INFO] Epoch 012 | Train Loss: 1.5113 | Val Loss: 1.4188 | Val Acc: 0.3750
2025-06-23 17:59:48,426 [INFO] Epoch 013 | Train Loss: 1.5007 | Val Loss: 1.5024 | Val Acc: 0.3393
2025-06-23 17:59:48,439 [INFO] Epoch 014 | Train Loss: 1.4314 | Val Loss: 1.3690 | Val Acc: 0.3393
2025-06-23 17:59:48,452 [INFO] Epoch 015 | Train Loss: 1.4441 | Val Loss: 1.3674 | Val Acc: 0.3214
2025-06-23 17:59:48,467 [INFO] Epoch 016 | Train Loss: 1.4653 | Val Loss: 1.3529 | Val Acc: 0.4107
2025-06-23 17:59:48,478 [INFO] Epoch 017 | Train Loss: 1.3922 | Val Loss: 1.2929 | Val Acc: 0.3571
2025-06-23 17:59:48,496 [INFO] Epoch 018 | Train Loss: 1.5146 | Val Loss: 1.3207 | Val Acc: 0.3036
2025-06-23 17:59:48,505 [INFO] Epoch 019 | Train Loss: 1.3964 | Val Loss: 1.4118 | Val Acc: 0.2321
2025-06-23 17:59:48,514 [INFO] Epoch 020 | Train Loss: 1.4649 | Val Loss: 1.3258 | Val Acc: 0.2857
2025-06-23 17:59:53,097 [INFO] Epoch 021 | Train Loss: 1.3883 | Val Loss: 1.3286 | Val Acc: 0.3393
2025-06-23 17:59:53,111 [INFO] Epoch 022 | Train Loss: 1.4467 | Val Loss: 1.2723 | Val Acc: 0.3214
2025-06-23 17:59:53,145 [INFO] Epoch 023 | Train Loss: 1.4916 | Val Loss: 1.3156 | Val Acc: 0.3571
2025-06-23 17:59:53,173 [INFO] Epoch 024 | Train Loss: 1.5118 | Val Loss: 1.2900 | Val Acc: 0.4107
2025-06-23 17:59:53,186 [INFO] Epoch 025 | Train Loss: 1.4116 | Val Loss: 1.3005 | Val Acc: 0.2857
2025-06-23 17:59:53,198 [INFO] Epoch 026 | Train Loss: 1.4264 | Val Loss: 1.3417 | Val Acc: 0.3393
2025-06-23 17:59:53,210 [INFO] Epoch 027 | Train Loss: 1.4054 | Val Loss: 1.2887 | Val Acc: 0.4107
2025-06-23 17:59:53,220 [INFO] Epoch 028 | Train Loss: 1.4980 | Val Loss: 1.3060 | Val Acc: 0.3750
2025-06-23 17:59:53,230 [INFO] Epoch 029 | Train Loss: 1.4157 | Val Loss: 1.3276 | Val Acc: 0.3571
2025-06-23 17:59:53,240 [INFO] Epoch 030 | Train Loss: 1.3395 | Val Loss: 1.3405 | Val Acc: 0.2857
2025-06-23 17:59:54,591 [INFO] Epoch 031 | Train Loss: 1.3440 | Val Loss: 1.2959 | Val Acc: 0.4286
2025-06-23 17:59:54,614 [INFO] Epoch 032 | Train Loss: 1.3721 | Val Loss: 1.3176 | Val Acc: 0.2857
2025-06-23 17:59:54,626 [INFO] Epoch 033 | Train Loss: 1.3710 | Val Loss: 1.3673 | Val Acc: 0.2500
2025-06-23 17:59:54,639 [INFO] Epoch 034 | Train Loss: 1.3496 | Val Loss: 1.2815 | Val Acc: 0.4107
2025-06-23 17:59:54,650 [INFO] Epoch 035 | Train Loss: 1.3212 | Val Loss: 1.3223 | Val Acc: 0.2857
2025-06-23 17:59:54,662 [INFO] Epoch 036 | Train Loss: 1.2829 | Val Loss: 1.2678 | Val Acc: 0.3929
2025-06-23 17:59:54,672 [INFO] Epoch 037 | Train Loss: 1.3229 | Val Loss: 1.2810 | Val Acc: 0.3571
2025-06-23 17:59:54,684 [INFO] Epoch 038 | Train Loss: 1.3069 | Val Loss: 1.2843 | Val Acc: 0.3750
2025-06-23 17:59:54,693 [INFO] Epoch 039 | Train Loss: 1.3460 | Val Loss: 1.3151 | Val Acc: 0.3393
2025-06-23 17:59:54,703 [INFO] Epoch 040 | Train Loss: 1.2877 | Val Loss: 1.2949 | Val Acc: 0.3750
2025-06-23 17:59:55,941 [INFO] Epoch 041 | Train Loss: 1.3152 | Val Loss: 1.3044 | Val Acc: 0.2857
2025-06-23 17:59:55,952 [INFO] Epoch 042 | Train Loss: 1.3128 | Val Loss: 1.2664 | Val Acc: 0.3750
2025-06-23 17:59:55,964 [INFO] Epoch 043 | Train Loss: 1.2861 | Val Loss: 1.2908 | Val Acc: 0.3750
2025-06-23 17:59:55,974 [INFO] Epoch 044 | Train Loss: 1.2849 | Val Loss: 1.2582 | Val Acc: 0.3750
2025-06-23 17:59:55,985 [INFO] Epoch 045 | Train Loss: 1.2726 | Val Loss: 1.2492 | Val Acc: 0.3929
2025-06-23 17:59:55,997 [INFO] Epoch 046 | Train Loss: 1.2804 | Val Loss: 1.2693 | Val Acc: 0.3750
2025-06-23 17:59:56,008 [INFO] Epoch 047 | Train Loss: 1.2996 | Val Loss: 1.3020 | Val Acc: 0.3393
2025-06-23 17:59:56,019 [INFO] Epoch 048 | Train Loss: 1.2956 | Val Loss: 1.2749 | Val Acc: 0.3750
2025-06-23 17:59:56,029 [INFO] Epoch 049 | Train Loss: 1.2905 | Val Loss: 1.2993 | Val Acc: 0.3393
2025-06-23 17:59:56,040 [INFO] Epoch 050 | Train Loss: 1.2931 | Val Loss: 1.2719 | Val Acc: 0.3929
2025-06-23 17:59:57,225 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.4821 at epoch 10)
2025-06-23 17:59:57,226 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.01/train_metrics.csv
2025-06-23 17:59:58,416 [INFO] Final training curves saved
2025-06-23 17:59:58,416 [INFO] Training completed!
2025-06-23 17:59:58,416 [INFO] Best validation accuracy: 0.4821
2025-06-23 17:59:58,416 [INFO] Best epoch: 10
2025-06-23 17:59:58,416 [INFO] Total epochs trained: 50
2025-06-23 17:59:58,417 [INFO] Starting training with parameters: (0.01, 0.4, 32, 1, 50, 0.0001)
