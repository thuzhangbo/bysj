2025-06-22 16:55:52,109 [INFO] Using device: cpu
2025-06-22 16:55:52,109 [INFO] 开始创建数据加载器...
2025-06-22 16:55:52,112 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 16:55:52,112 [INFO] Class allocation analysis:
2025-06-22 16:55:52,112 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 16:55:52,112 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 16:55:52,112 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 16:55:52,112 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 16:55:52,129 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 16:55:52,129 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 16:55:52,130 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 16:55:52,130 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 16:55:52,130 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 16:55:52,130 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 16:55:52,130 [INFO] Final allocation:
2025-06-22 16:55:52,130 [INFO]   Source domain: 280 samples
2025-06-22 16:55:52,130 [INFO]   Target domain: 320 samples
2025-06-22 16:55:52,131 [INFO] Source domain setup:
2025-06-22 16:55:52,132 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-22 16:55:52,132 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-22 16:55:52,132 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-22 16:55:52,132 [INFO]   Total data after allocation: 280
2025-06-22 16:55:52,132 [INFO]   Data split - Train: 224, Val: 56
2025-06-22 16:55:52,132 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-22 16:55:52,132 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-22 16:55:52,139 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 16:55:52,139 [INFO] Class allocation analysis:
2025-06-22 16:55:52,139 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 16:55:52,139 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 16:55:52,139 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 16:55:52,139 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 16:55:52,154 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 16:55:52,154 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 16:55:52,154 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 16:55:52,154 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 16:55:52,154 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 16:55:52,154 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 16:55:52,155 [INFO] Final allocation:
2025-06-22 16:55:52,155 [INFO]   Source domain: 280 samples
2025-06-22 16:55:52,155 [INFO]   Target domain: 320 samples
2025-06-22 16:55:52,156 [INFO] Target domain setup:
2025-06-22 16:55:52,156 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-22 16:55:52,156 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-22 16:55:52,156 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-22 16:55:52,156 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-22 16:55:52,156 [INFO]   Total data after allocation: 320
2025-06-22 16:55:52,156 [INFO]   Data split - Train: 256, Val: 64
2025-06-22 16:55:52,156 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-22 16:55:52,156 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-22 16:55:52,156 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-22 16:55:52,156 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-22 16:55:52,157 [INFO] 数据加载器创建完成!
2025-06-22 16:55:52,157 [INFO] 源域类别数: 4 (重叠类别)
2025-06-22 16:55:52,157 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-22 16:55:52,157 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-22 16:55:52,157 [INFO] 目标域新类别: [4, 5]
2025-06-22 16:55:52,157 [INFO] Data allocation verification:
2025-06-22 16:55:52,157 [INFO]   Source data samples: 280
2025-06-22 16:55:52,157 [INFO]   Target data samples: 320
2025-06-22 16:55:52,157 [INFO]   Overlapping samples: 0
2025-06-22 16:55:52,157 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-22 16:55:52,158 [INFO] Model initialized with 68868 parameters
2025-06-22 16:55:52,158 [INFO] Previous best validation accuracy read from record.txt: 0.6429
2025-06-22 16:55:52,158 [INFO] Starting training...
2025-06-22 16:55:52,181 [INFO] Epoch 001 | Train Loss: 21.7290 | Val Loss: 32.4731 | Val Acc: 0.3036
2025-06-22 16:55:53,777 [INFO] New best model at epoch 1 (Val Acc: 0.3036)
2025-06-22 16:55:53,794 [INFO] Epoch 002 | Train Loss: 12.2194 | Val Loss: 23.2708 | Val Acc: 0.2500
2025-06-22 16:55:53,814 [INFO] Epoch 003 | Train Loss: 7.9774 | Val Loss: 9.9544 | Val Acc: 0.2857
2025-06-22 16:55:53,835 [INFO] Epoch 004 | Train Loss: 7.2539 | Val Loss: 8.2220 | Val Acc: 0.3571
2025-06-22 16:55:53,837 [INFO] New best model at epoch 4 (Val Acc: 0.3571)
2025-06-22 16:55:53,855 [INFO] Epoch 005 | Train Loss: 6.6552 | Val Loss: 4.0472 | Val Acc: 0.4286
2025-06-22 16:55:53,858 [INFO] New best model at epoch 5 (Val Acc: 0.4286)
2025-06-22 16:55:53,875 [INFO] Epoch 006 | Train Loss: 4.2778 | Val Loss: 5.8053 | Val Acc: 0.2321
2025-06-22 16:55:53,892 [INFO] Epoch 007 | Train Loss: 3.6725 | Val Loss: 4.6195 | Val Acc: 0.3929
2025-06-22 16:55:53,907 [INFO] Epoch 008 | Train Loss: 3.2536 | Val Loss: 2.3617 | Val Acc: 0.2500
2025-06-22 16:55:53,923 [INFO] Epoch 009 | Train Loss: 3.2438 | Val Loss: 6.5425 | Val Acc: 0.2143
2025-06-22 16:55:53,938 [INFO] Epoch 010 | Train Loss: 3.6163 | Val Loss: 3.2238 | Val Acc: 0.3750
2025-06-22 16:55:54,879 [INFO] Epoch 011 | Train Loss: 3.5344 | Val Loss: 3.3483 | Val Acc: 0.3214
2025-06-22 16:55:54,899 [INFO] Epoch 012 | Train Loss: 3.6155 | Val Loss: 2.9469 | Val Acc: 0.2857
2025-06-22 16:55:54,921 [INFO] Epoch 013 | Train Loss: 3.1314 | Val Loss: 2.6994 | Val Acc: 0.3750
2025-06-22 16:55:54,941 [INFO] Epoch 014 | Train Loss: 4.1241 | Val Loss: 3.0121 | Val Acc: 0.3571
2025-06-22 16:55:54,961 [INFO] Epoch 015 | Train Loss: 3.6839 | Val Loss: 3.3625 | Val Acc: 0.3929
2025-06-22 16:55:54,976 [INFO] Epoch 016 | Train Loss: 3.8267 | Val Loss: 3.9940 | Val Acc: 0.3571
2025-06-22 16:55:54,991 [INFO] Epoch 017 | Train Loss: 3.7502 | Val Loss: 3.8952 | Val Acc: 0.2321
2025-06-22 16:55:55,006 [INFO] Epoch 018 | Train Loss: 3.2260 | Val Loss: 2.6375 | Val Acc: 0.3571
2025-06-22 16:55:55,022 [INFO] Epoch 019 | Train Loss: 2.2945 | Val Loss: 3.3992 | Val Acc: 0.2857
2025-06-22 16:55:55,037 [INFO] Epoch 020 | Train Loss: 1.9243 | Val Loss: 2.9839 | Val Acc: 0.3393
2025-06-22 16:55:56,021 [INFO] Epoch 021 | Train Loss: 2.2096 | Val Loss: 2.0338 | Val Acc: 0.2679
2025-06-22 16:55:56,040 [INFO] Epoch 022 | Train Loss: 1.9463 | Val Loss: 2.4402 | Val Acc: 0.3571
2025-06-22 16:55:56,059 [INFO] Epoch 023 | Train Loss: 2.4571 | Val Loss: 3.8508 | Val Acc: 0.2321
2025-06-22 16:55:56,079 [INFO] Epoch 024 | Train Loss: 3.6678 | Val Loss: 3.5906 | Val Acc: 0.3036
2025-06-22 16:55:56,099 [INFO] Epoch 025 | Train Loss: 3.1994 | Val Loss: 3.0322 | Val Acc: 0.2321
2025-06-22 16:55:56,117 [INFO] Epoch 026 | Train Loss: 2.7185 | Val Loss: 2.7712 | Val Acc: 0.2857
2025-06-22 16:55:56,132 [INFO] Epoch 027 | Train Loss: 2.4985 | Val Loss: 2.4012 | Val Acc: 0.2857
2025-06-22 16:55:56,148 [INFO] Epoch 028 | Train Loss: 1.9228 | Val Loss: 2.3754 | Val Acc: 0.3214
2025-06-22 16:55:56,163 [INFO] Epoch 029 | Train Loss: 2.0393 | Val Loss: 3.3814 | Val Acc: 0.2857
2025-06-22 16:55:56,178 [INFO] Epoch 030 | Train Loss: 2.2903 | Val Loss: 3.5371 | Val Acc: 0.2679
2025-06-22 16:55:57,134 [INFO] Epoch 031 | Train Loss: 2.6974 | Val Loss: 2.3627 | Val Acc: 0.2321
2025-06-22 16:55:57,151 [INFO] Epoch 032 | Train Loss: 2.6653 | Val Loss: 2.6168 | Val Acc: 0.2857
2025-06-22 16:55:57,170 [INFO] Epoch 033 | Train Loss: 2.0288 | Val Loss: 2.2710 | Val Acc: 0.2679
2025-06-22 16:55:57,196 [INFO] Epoch 034 | Train Loss: 1.9102 | Val Loss: 1.9300 | Val Acc: 0.3750
2025-06-22 16:55:57,216 [INFO] Epoch 035 | Train Loss: 2.0819 | Val Loss: 2.3374 | Val Acc: 0.2143
2025-06-22 16:55:57,233 [INFO] Epoch 036 | Train Loss: 2.0174 | Val Loss: 3.0217 | Val Acc: 0.3214
2025-06-22 16:55:57,248 [INFO] Epoch 037 | Train Loss: 1.8805 | Val Loss: 1.7908 | Val Acc: 0.3393
2025-06-22 16:55:57,263 [INFO] Epoch 038 | Train Loss: 2.0668 | Val Loss: 2.4425 | Val Acc: 0.3036
2025-06-22 16:55:57,278 [INFO] Epoch 039 | Train Loss: 1.9142 | Val Loss: 1.8137 | Val Acc: 0.3214
2025-06-22 16:55:57,292 [INFO] Epoch 040 | Train Loss: 1.7407 | Val Loss: 2.3181 | Val Acc: 0.2321
2025-06-22 16:55:58,229 [INFO] Epoch 041 | Train Loss: 1.9238 | Val Loss: 2.4739 | Val Acc: 0.3929
2025-06-22 16:55:58,248 [INFO] Epoch 042 | Train Loss: 1.9396 | Val Loss: 2.1968 | Val Acc: 0.2321
2025-06-22 16:55:58,267 [INFO] Epoch 043 | Train Loss: 2.0936 | Val Loss: 2.1008 | Val Acc: 0.3214
2025-06-22 16:55:58,288 [INFO] Epoch 044 | Train Loss: 1.8412 | Val Loss: 1.9233 | Val Acc: 0.2857
2025-06-22 16:55:58,309 [INFO] Epoch 045 | Train Loss: 1.7489 | Val Loss: 1.6672 | Val Acc: 0.4107
2025-06-22 16:55:58,326 [INFO] Epoch 046 | Train Loss: 1.4626 | Val Loss: 1.7890 | Val Acc: 0.3214
2025-06-22 16:55:58,342 [INFO] Epoch 047 | Train Loss: 1.5432 | Val Loss: 2.0547 | Val Acc: 0.3571
2025-06-22 16:55:58,358 [INFO] Epoch 048 | Train Loss: 1.6162 | Val Loss: 1.6096 | Val Acc: 0.3750
2025-06-22 16:55:58,373 [INFO] Epoch 049 | Train Loss: 1.5769 | Val Loss: 2.2921 | Val Acc: 0.3571
2025-06-22 16:55:58,388 [INFO] Epoch 050 | Train Loss: 1.5537 | Val Loss: 2.3290 | Val Acc: 0.2679
2025-06-22 16:56:01,878 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.4286 at epoch 5)
2025-06-22 16:56:01,879 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.01/train_metrics.csv
2025-06-22 16:56:02,890 [INFO] Final training curves saved
2025-06-22 16:56:02,890 [INFO] Training completed!
2025-06-22 16:56:02,890 [INFO] Best validation accuracy: 0.4286
2025-06-22 16:56:02,890 [INFO] Best epoch: 5
2025-06-22 16:56:02,890 [INFO] Total epochs trained: 50
2025-06-22 16:56:02,891 [INFO] Starting training with parameters: (0.01, 0.1, 256, 1, 50, 0.001)
