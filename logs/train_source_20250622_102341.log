2025-06-22 10:23:41,661 [INFO] Using device: cpu
2025-06-22 10:23:41,661 [INFO] 开始创建数据加载器...
2025-06-22 10:23:41,663 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 10:23:41,663 [INFO] Class allocation analysis:
2025-06-22 10:23:41,663 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 10:23:41,663 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 10:23:41,663 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 10:23:41,663 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 10:23:41,676 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 10:23:41,676 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 10:23:41,676 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 10:23:41,676 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 10:23:41,676 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 10:23:41,676 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 10:23:41,677 [INFO] Final allocation:
2025-06-22 10:23:41,677 [INFO]   Source domain: 280 samples
2025-06-22 10:23:41,677 [INFO]   Target domain: 320 samples
2025-06-22 10:23:41,678 [INFO] Source domain setup:
2025-06-22 10:23:41,678 [INFO]   Original classes: [0, 1, 2, 3]
2025-06-22 10:23:41,678 [INFO]   Overlap classes used: [0, 1, 2, 3]
2025-06-22 10:23:41,678 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3}
2025-06-22 10:23:41,678 [INFO]   Total data after allocation: 280
2025-06-22 10:23:41,678 [INFO]   Data split - Train: 224, Val: 56
2025-06-22 10:23:41,678 [INFO]   Train label distribution: {0: 56, 1: 56, 3: 56, 2: 56}
2025-06-22 10:23:41,678 [INFO]   Val label distribution: {1: 14, 2: 14, 0: 14, 3: 14}
2025-06-22 10:23:41,679 [INFO] Successfully loaded dataset ENZYMES from ./data, total graphs: 600
2025-06-22 10:23:41,679 [INFO] Class allocation analysis:
2025-06-22 10:23:41,679 [INFO]   Source classes: [0, 1, 2, 3]
2025-06-22 10:23:41,679 [INFO]   Target classes: [0, 1, 2, 3, 4, 5]
2025-06-22 10:23:41,679 [INFO]   Overlap classes (to be split): [0, 1, 2, 3]
2025-06-22 10:23:41,679 [INFO]   Target novel classes (unknown): [4, 5]
2025-06-22 10:23:41,692 [INFO]   Class 0: 100 total -> Source: 70, Target: 30
2025-06-22 10:23:41,692 [INFO]   Class 1: 100 total -> Source: 70, Target: 30
2025-06-22 10:23:41,692 [INFO]   Class 2: 100 total -> Source: 70, Target: 30
2025-06-22 10:23:41,692 [INFO]   Class 3: 100 total -> Source: 70, Target: 30
2025-06-22 10:23:41,692 [INFO]   Class 4 (novel/unknown): 100 samples -> Target
2025-06-22 10:23:41,692 [INFO]   Class 5 (novel/unknown): 100 samples -> Target
2025-06-22 10:23:41,693 [INFO] Final allocation:
2025-06-22 10:23:41,693 [INFO]   Source domain: 280 samples
2025-06-22 10:23:41,693 [INFO]   Target domain: 320 samples
2025-06-22 10:23:41,694 [INFO] Target domain setup:
2025-06-22 10:23:41,694 [INFO]   Original classes: [0, 1, 2, 3, 4, 5]
2025-06-22 10:23:41,694 [INFO]   Overlap classes: [0, 1, 2, 3]
2025-06-22 10:23:41,694 [INFO]   Novel classes: [4, 5] -> mapped to unknown label 4
2025-06-22 10:23:41,694 [INFO]   Label mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 4}
2025-06-22 10:23:41,694 [INFO]   Total data after allocation: 320
2025-06-22 10:23:41,694 [INFO]   Data split - Train: 256, Val: 64
2025-06-22 10:23:41,694 [INFO]   Total count: 320 (known: 120, unknown: 200)
2025-06-22 10:23:41,694 [INFO]   Total label distribution: {4: 200, 3: 30, 0: 30, 1: 30, 2: 30}
2025-06-22 10:23:41,694 [INFO]   Train label distribution: {4: 160, 0: 24, 2: 24, 3: 24, 1: 24}
2025-06-22 10:23:41,694 [INFO]   Val label distribution: {1: 6, 4: 40, 3: 6, 0: 6, 2: 6}
2025-06-22 10:23:41,695 [INFO] 数据加载器创建完成!
2025-06-22 10:23:41,695 [INFO] 源域类别数: 4 (重叠类别)
2025-06-22 10:23:41,695 [INFO] 目标域类别数: 5 (4个重叠类别 + 1个未知类别)
2025-06-22 10:23:41,695 [INFO] 重叠类别: [0, 1, 2, 3]
2025-06-22 10:23:41,695 [INFO] 目标域新类别: [4, 5]
2025-06-22 10:23:41,695 [INFO] Data allocation verification:
2025-06-22 10:23:41,695 [INFO]   Source data samples: 280
2025-06-22 10:23:41,695 [INFO]   Target data samples: 320
2025-06-22 10:23:41,695 [INFO]   Overlapping samples: 0
2025-06-22 10:23:41,695 [INFO]   ✓ Data allocation is correct - no overlapping samples
2025-06-22 10:23:41,696 [INFO] Model initialized with 68868 parameters
2025-06-22 10:23:41,696 [INFO] Previous best validation accuracy read from record.txt: 0.6250
2025-06-22 10:23:41,696 [INFO] Starting training...
2025-06-22 10:23:41,716 [INFO] Epoch 001 | Train Loss: 10.0793 | Val Loss: 3.6691 | Val Acc: 0.3036
2025-06-22 10:23:42,459 [INFO] New best model at epoch 1 (Val Acc: 0.3036)
2025-06-22 10:23:42,473 [INFO] Epoch 002 | Train Loss: 7.3872 | Val Loss: 3.8242 | Val Acc: 0.3393
2025-06-22 10:23:42,476 [INFO] New best model at epoch 2 (Val Acc: 0.3393)
2025-06-22 10:23:42,492 [INFO] Epoch 003 | Train Loss: 8.7337 | Val Loss: 2.8958 | Val Acc: 0.5000
2025-06-22 10:23:42,495 [INFO] New best model at epoch 3 (Val Acc: 0.5000)
2025-06-22 10:23:42,512 [INFO] Epoch 004 | Train Loss: 6.4105 | Val Loss: 2.9598 | Val Acc: 0.3393
2025-06-22 10:23:42,535 [INFO] Epoch 005 | Train Loss: 6.7188 | Val Loss: 2.8145 | Val Acc: 0.3750
2025-06-22 10:23:42,554 [INFO] Epoch 006 | Train Loss: 6.9909 | Val Loss: 2.8671 | Val Acc: 0.3929
2025-06-22 10:23:42,571 [INFO] Epoch 007 | Train Loss: 6.5978 | Val Loss: 2.8733 | Val Acc: 0.3571
2025-06-22 10:23:42,585 [INFO] Epoch 008 | Train Loss: 5.1794 | Val Loss: 3.7297 | Val Acc: 0.2679
2025-06-22 10:23:42,599 [INFO] Epoch 009 | Train Loss: 6.2562 | Val Loss: 3.1233 | Val Acc: 0.3036
2025-06-22 10:23:42,613 [INFO] Epoch 010 | Train Loss: 6.4579 | Val Loss: 2.5437 | Val Acc: 0.3750
2025-06-22 10:23:44,390 [INFO] Epoch 011 | Train Loss: 6.2582 | Val Loss: 3.7975 | Val Acc: 0.3571
2025-06-22 10:23:44,408 [INFO] Epoch 012 | Train Loss: 5.2474 | Val Loss: 3.5020 | Val Acc: 0.3214
2025-06-22 10:23:44,426 [INFO] Epoch 013 | Train Loss: 5.2621 | Val Loss: 2.2550 | Val Acc: 0.3750
2025-06-22 10:23:44,444 [INFO] Epoch 014 | Train Loss: 5.0665 | Val Loss: 2.4634 | Val Acc: 0.3929
2025-06-22 10:23:44,463 [INFO] Epoch 015 | Train Loss: 4.0091 | Val Loss: 2.9635 | Val Acc: 0.3393
2025-06-22 10:23:44,480 [INFO] Epoch 016 | Train Loss: 4.6507 | Val Loss: 2.9719 | Val Acc: 0.2500
2025-06-22 10:23:44,494 [INFO] Epoch 017 | Train Loss: 4.6343 | Val Loss: 3.3083 | Val Acc: 0.3036
2025-06-22 10:23:44,508 [INFO] Epoch 018 | Train Loss: 4.7030 | Val Loss: 2.4039 | Val Acc: 0.3750
2025-06-22 10:23:44,522 [INFO] Epoch 019 | Train Loss: 4.7077 | Val Loss: 2.8726 | Val Acc: 0.2857
2025-06-22 10:23:44,536 [INFO] Epoch 020 | Train Loss: 4.7262 | Val Loss: 3.5879 | Val Acc: 0.3036
2025-06-22 10:23:45,284 [INFO] Epoch 021 | Train Loss: 3.7489 | Val Loss: 2.4576 | Val Acc: 0.3571
2025-06-22 10:23:45,302 [INFO] Epoch 022 | Train Loss: 3.8883 | Val Loss: 2.2046 | Val Acc: 0.3750
2025-06-22 10:23:45,320 [INFO] Epoch 023 | Train Loss: 3.5086 | Val Loss: 2.9505 | Val Acc: 0.3393
2025-06-22 10:23:45,339 [INFO] Epoch 024 | Train Loss: 3.2895 | Val Loss: 2.6735 | Val Acc: 0.3214
2025-06-22 10:23:45,358 [INFO] Epoch 025 | Train Loss: 3.4809 | Val Loss: 2.5350 | Val Acc: 0.3929
2025-06-22 10:23:45,376 [INFO] Epoch 026 | Train Loss: 3.1558 | Val Loss: 2.7485 | Val Acc: 0.3036
2025-06-22 10:23:45,390 [INFO] Epoch 027 | Train Loss: 3.5957 | Val Loss: 2.0777 | Val Acc: 0.3571
2025-06-22 10:23:45,403 [INFO] Epoch 028 | Train Loss: 3.0994 | Val Loss: 1.8853 | Val Acc: 0.3929
2025-06-22 10:23:45,417 [INFO] Epoch 029 | Train Loss: 3.3015 | Val Loss: 2.4931 | Val Acc: 0.3214
2025-06-22 10:23:45,431 [INFO] Epoch 030 | Train Loss: 2.8005 | Val Loss: 2.2920 | Val Acc: 0.3571
2025-06-22 10:23:46,173 [INFO] Epoch 031 | Train Loss: 3.0363 | Val Loss: 2.0222 | Val Acc: 0.4107
2025-06-22 10:23:46,190 [INFO] Epoch 032 | Train Loss: 2.5457 | Val Loss: 1.8208 | Val Acc: 0.3571
2025-06-22 10:23:46,204 [INFO] Epoch 033 | Train Loss: 2.4029 | Val Loss: 1.6271 | Val Acc: 0.4464
2025-06-22 10:23:46,222 [INFO] Epoch 034 | Train Loss: 2.4018 | Val Loss: 1.6178 | Val Acc: 0.4107
2025-06-22 10:23:46,244 [INFO] Epoch 035 | Train Loss: 2.4600 | Val Loss: 1.5984 | Val Acc: 0.3571
2025-06-22 10:23:46,261 [INFO] Epoch 036 | Train Loss: 2.3919 | Val Loss: 1.5874 | Val Acc: 0.4107
2025-06-22 10:23:46,280 [INFO] Epoch 037 | Train Loss: 2.4978 | Val Loss: 1.7687 | Val Acc: 0.3214
2025-06-22 10:23:46,296 [INFO] Epoch 038 | Train Loss: 2.1194 | Val Loss: 1.9494 | Val Acc: 0.2679
2025-06-22 10:23:46,310 [INFO] Epoch 039 | Train Loss: 1.9400 | Val Loss: 1.8542 | Val Acc: 0.3393
2025-06-22 10:23:46,323 [INFO] Epoch 040 | Train Loss: 2.6492 | Val Loss: 1.9885 | Val Acc: 0.3393
2025-06-22 10:23:47,074 [INFO] Epoch 041 | Train Loss: 2.4213 | Val Loss: 1.9260 | Val Acc: 0.2679
2025-06-22 10:23:47,090 [INFO] Epoch 042 | Train Loss: 1.9473 | Val Loss: 1.6054 | Val Acc: 0.3571
2025-06-22 10:23:47,110 [INFO] Epoch 043 | Train Loss: 1.8331 | Val Loss: 1.9019 | Val Acc: 0.2679
2025-06-22 10:23:47,132 [INFO] Epoch 044 | Train Loss: 2.0176 | Val Loss: 2.0847 | Val Acc: 0.2679
2025-06-22 10:23:47,154 [INFO] Epoch 045 | Train Loss: 1.8897 | Val Loss: 1.5246 | Val Acc: 0.3929
2025-06-22 10:23:47,172 [INFO] Epoch 046 | Train Loss: 1.8596 | Val Loss: 1.7845 | Val Acc: 0.2500
2025-06-22 10:23:47,186 [INFO] Epoch 047 | Train Loss: 1.9743 | Val Loss: 1.5536 | Val Acc: 0.4107
2025-06-22 10:23:47,200 [INFO] Epoch 048 | Train Loss: 2.0894 | Val Loss: 1.8808 | Val Acc: 0.2857
2025-06-22 10:23:47,213 [INFO] Epoch 049 | Train Loss: 2.1071 | Val Loss: 2.1215 | Val Acc: 0.2321
2025-06-22 10:23:47,227 [INFO] Epoch 050 | Train Loss: 1.6210 | Val Loss: 1.7733 | Val Acc: 0.3393
2025-06-22 10:23:48,357 [INFO] Best model saved to <built-in function time>/ENZYMES/best/best_source_gin.pth (Val Acc: 0.5000 at epoch 3)
2025-06-22 10:23:48,357 [INFO] Training/validation metrics saved to <built-in function time>/ENZYMES/GIN_0.001/train_metrics.csv
2025-06-22 10:23:49,131 [INFO] Final training curves saved
2025-06-22 10:23:49,131 [INFO] Training completed!
2025-06-22 10:23:49,131 [INFO] Best validation accuracy: 0.5000
2025-06-22 10:23:49,131 [INFO] Best epoch: 3
2025-06-22 10:23:49,131 [INFO] Total epochs trained: 50
2025-06-22 10:23:49,132 [INFO] Starting training with parameters: (0.001, 0.5, 256, 1, 50, 0.001)
